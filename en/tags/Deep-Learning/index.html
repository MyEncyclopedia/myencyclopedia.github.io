<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>Tag: Deep Learning - MyEncyclopedia</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">


<link href="/tags/Deep-Learning/" rel="alternate" hreflang="zh" />
    


<meta name="description" content="">





    <meta property="og:type" content="website">
<meta property="og:title" content="MyEncyclopedia">
<meta property="og:url" content="https://myencyclopedia.github.io/en/tags/Deep-Learning/">
<meta property="og:site_name" content="MyEncyclopedia">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="MyEncyclopedia">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/en">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/en/archives">Archives</a>
            
            <a class="navbar-item "
               href="/en/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#Deep Learning</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/en/2020/vlog-paper-mine/" itemprop="url">Paper Explained: MINE - Mutual Information Neural Estimation (2018)</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-06-14T18:45:01.000Z" itemprop="datePublished">Jun 15 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            a few seconds read (About 15 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><h2 id="youtube">YouTube</h2>
<style>.embed-container {
    position: relative;
    padding-bottom: 56.25%;
    height: 0;
    overflow: hidden;
    max-width: 100%;
  }
  .embed-container iframe, .embed-container object, .embed-container embed {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
  </style>

<div class="embed-container"><iframe src="https://www.youtube.com/embed/jEu_S8Og7T0" allowfullscreen="" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"></iframe></div>
<h2 id="bilibili">BiliBili</h2>
<div class="bili_video"><iframe src="https://player.bilibili.com/player.html?aid=NaN&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" width="544" height="452" allowfullscreen="true"> </iframe></div>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/en/2020/tsp-5-rl/" itemprop="url">TSP From DP to Deep Learning. Episode 5: Reinforcement Learning</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-06-12T18:45:01.000Z" itemprop="datePublished">Jun 13 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 minutes read (About 1952 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>This is fifth episode of series: TSP From DP to Deep Learning. In
this episode, we turn to Reinforcement Learning technology, in
particular, a model-free policy gradient method that embeds pointer
network to learn minimal tour without supervised best tour label in
dataset. Full list of this series is listed below.</p>
<ul>
<li><p>Episode 1: <a href="/en/2020/tsp-5-rl/!--swig￼3--">AC TSP on AIZU with recursive
DP</a></p></li>
<li><p>Episode 2: <a href="/en/2020/tsp-5-rl/!--swig￼4--">TSP DP on a Euclidean
Dataset</a></p></li>
<li><p>Episode 3: <a href="/en/2020/tsp-5-rl/!--swig￼5--">Pointer Networks in
PyTorch</a></p></li>
<li><p>Episode 4: <a href="/en/2020/tsp-5-rl/!--swig￼6--">Search for Most Likely
Sequence</a></p></li>
<li><p><strong>Episode 5: <a href="/en/2020/tsp-5-rl/!--swig￼7--">Reinforcement Learning
PyTorch Implementation</a></strong></p></li>
</ul>
<h2 id="pointer-network-refresher">Pointer Network Refresher</h2>
<p>In previous episode <a href="/en/2020/tsp-5-rl/!--swig￼8--">Pointer Networks in
PyTorch</a>, we implemented <em>Pointer Networks </em> in PyTorch with a
2D Euclidean dataset.</p>
Recall that the input is a graph as a sequence of <span class="math inline">\(n\)</span> cities in a two dimensional space
<div>
<p><span class="math display">\[
s=\{\mathbf{x_i}\}_{i=1}^n,   \mathbf{x}_{i} \in \mathbb{R}^{2}
\]</span></p>
</div>
<p>The output is a permutation of the points <span class="math inline">\(\pi\)</span>, that visits each city exactly once
and returns to starting point with minimal distance.</p>
<p>Let us define the total distance of a <span class="math inline">\(\pi\)</span> with respect to <span class="math inline">\(s\)</span> as <span class="math inline">\(L\)</span></p>
<div>
<p><span class="math display">\[
L(\pi |
s)=\left\|\mathbf{x}_{\pi(n)}-\mathbf{x}_{\pi(1)}\right\|_{2}+\sum_{i=1}^{n-1}\left\|\mathbf{x}_{\pi(i)}-\mathbf{x}_{\pi(i+1)}\right\|_{2}
\]</span></p>
</div>
<p>The stochastic policy <span class="math inline">\(p(\pi | s;
\theta)\)</span>, parameterized by <span class="math inline">\(\theta\)</span>, is aiming to assign high
probabilities to short tours and low probabilities to long tours. The
joint probability assumes independency to allow factorization.</p>
<p><span class="math display">\[
p(\pi | s; \theta) =
\prod_{i=1}^{n} p\left({\pi(i)} | {\pi(1)}, \ldots, {\pi(i-1)} , s;
\theta\right)
\]</span></p>
<p>The loss of the model is cross entropy between the network’s output
probabilities <span class="math inline">\(\pi\)</span> and the best tour
<span class="math inline">\(\hat{\pi}\)</span> generated by a TSP
solver.</p>
<p>Contribution made by Pointer networks is that it addressed the
constraint in that it allows for dynamic index value given by the
particular test case, instead of from a fixed-size vocabulary.</p>
<h2 id="reinforcement-learning">Reinforcement Learning</h2>
<p><em>Neural Combinatorial Optimization with Reinforcement Learning
</em> combines the power of Reinforcement Learning (RL) and Deep
Learning to further eliminate the constraint required by Pointer
Networks that the training dataset has to have supervised labels of best
tour. With deep RL, test cases do not need to have a solution which is
common pattern in deep RL. In the paper, a model-free policy-based RL
method is adopted.</p>
<h3 id="model-free-policy-gradient-methods">Model-Free Policy Gradient
Methods</h3>
<p>In the authoritative RL book, <em>chapter 8 Planning and Learning
with Tabular Methods</em>, there are two major approaches in RL. One is
model-based RL and the other is model-free RL. Distinction between the
two relies on concept of model, which is stated as follows:</p>
<blockquote>
<p>By a model of the environment we mean anything that an agent can use
to predict how the environment will respond to its actions.</p>
</blockquote>
<p>So model-based methods demand a model of the environment, and hence
dynamic programming and heuristic search fall into this category. With
model in mind, utility of the state can be computed in various ways and
planning stage that essentially builds policy is needed before agent can
take any action. In contrast, model-free methods, without building a
model, are more direct, ignoring irrelevant information and just
focusing on the policy which is ultimately needed. Typical examples of
model-free methods are Monte Carlo Control and Temporal-Difference
Learning. &gt;Model-based methods rely on planning as their primary
component, while model-free methods primarily rely on learning.</p>
<p>In TSP problem, the model is fully determined by all points given,
and no feedback is generated for each decision made. So it's unclear to
how to map state value with a tour. Therefore, we turn to model-free
methods. In <em>chapter 13 Policy Gradient Methods</em>, a particular
approximation model-free method that learns a parameterized policy that
can select actions without consulting a value function. This approach
fits perfectly with aforementioned pointer networks where the
parameterized policy <span class="math inline">\(p(\pi | s;
\theta)\)</span> is already defined.</p>
Training objective is obvious, the expected tour length of <span class="math inline">\(\pi_\theta\)</span> which, given an input graph
<span class="math inline">\(s\)</span>
<div>
<p><span class="math display">\[
J(\theta | s) = \mathbb{E}_{\pi \sim p_{\theta}(\cdot | s)} L(\pi | s)
\]</span></p>
</div>
<h3 id="monte-carlo-policy-gradient-reinforce-with-baseline">Monte Carlo
Policy Gradient: REINFORCE with Baseline</h3>
<p>In order to find largest reward, a typical way is to optimize the
parameters <span class="math inline">\(\theta\)</span> in the direction
of derivative: <span class="math inline">\(\nabla_{\theta} J(\theta |
s)\)</span>.</p>
<p><span class="math display">\[
\nabla_{\theta} J(\theta | s)=\nabla_{\theta} \mathbb{E}_{\pi \sim
p_{\theta}(\cdot | s)} L(\pi | s)
\]</span></p>
<p>RHS of equation above is the derivative of expectation that we have
no idea how to compute or approximate. Here comes the well-known
REINFORCE trick that turns it into form of expectation of derivative,
which can be approximated easily with Monte Carlo sampling, where the
expectation is replaced by averaging.</p>
<p><span class="math display">\[
\nabla_{\theta} J(\theta | s)=\mathbb{E}_{\pi \sim p_{\theta}(. |
s)}\left[L(\pi | s) \nabla_{\theta} \log p_{\theta}(\pi | s)\right]
\]</span></p>
<p>Another common trick, subtracting a baseline <span class="math inline">\(b(s)\)</span>, leads the derivative of reward to
the following equation. Note that <span class="math inline">\(b(s)\)</span> denotes a baseline function that
must not depend on <span class="math inline">\(\pi\)</span>. <span class="math display">\[
\nabla_{\theta} J(\theta | s)=\mathbb{E}_{\pi \sim p_{\theta}(. |
s)}\left[(L(\pi | s)-b(s)) \nabla_{\theta} \log p_{\theta}(\pi |
s)\right]
\]</span></p>
<p>The trick is explained in as:</p>
<blockquote>
<p>Because the baseline could be uniformly zero, this update is a strict
generalization of REINFORCE. In general, the baseline leaves the
expected value of the update unchanged, but it can have a large effect
on its variance.</p>
</blockquote>
<p>Finally, the equation can be approximated with Monte Carlo sampling,
assuming drawing <span class="math inline">\(B\)</span> i.i.d: <span class="math inline">\(s_{1}, s_{2}, \ldots, s_{B} \sim
\mathcal{S}\)</span> and sampling a single tour per graph: $ <em>{i}
p</em>{}(. | s_{i}) $, as follows <span class="math display">\[
\nabla_{\theta} J(\theta) \approx \frac{1}{B}
\sum_{i=1}^{B}\left(L\left(\pi_{i} |
s_{i}\right)-b\left(s_{i}\right)\right) \nabla_{\theta} \log
p_{\theta}\left(\pi_{i} | s_{i}\right)
\]</span></p>
<h3 id="actor-critic-methods">Actor Critic Methods</h3>
<p>REINFORCE with baseline works quite well but it also has
disadvantage.</p>
<blockquote>
<p>REINFORCE with baseline is unbiased and will converge asymptotically
to a local minimum, but like all Monte Carlo methods it tends to learn
slowly (produce estimates of high variance) and to be inconvenient to
implement online or for continuing problems.</p>
</blockquote>
<p>A typical improvement is actor–critic methods, that not only learn
approximate policy, the actor job, but also learn approximate value
funciton, the critic job. This is because it reduces variance and
accelerates learning via a bootstrapping critic that introduce bias
which is often beneficial. Detailed algorithm in the paper illustrated
below.</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Algorithm Actor-critic training} \\
&amp;1: \quad \textbf{ procedure } \text{ TRAIN(training set }S \text{,
training steps }T \text{, batch size } B \text{)} \\
&amp;2: \quad \quad \text{Initialize pointer network params } \theta \\
&amp;3: \quad \quad \text{Initialize critic network params } \theta_{v}
\\
&amp;4: \quad \quad \textbf{for }t=1  \text{ to } T  \textbf{ do }\\
&amp;5: \quad \quad \quad s_{i} \sim \operatorname{SAMPLE INPUT }  (S)
\text{ for } i \in\{1, \ldots, B\} \\
&amp;6: \quad \quad \quad  \pi_{i} \sim \operatorname{SAMPLE SOLUTION }
\left(p_{\theta}\left(\cdot | s_{i}\right)\right) \text{ for } i \in\{1,
\ldots, B\} \\
&amp;7: \quad \quad \quad b_{i} \leftarrow
b_{\theta_{v}}\left(s_{i}\right) \text{ for } i \in\{1, \ldots, B\} \\
&amp;8: \quad \quad \quad g_{\theta} \leftarrow \frac{1}{B}
\sum_{i=1}^{B}\left(L\left(\pi_{i} | s_{i}\right)-b_{i}\right)
\nabla_{\theta} \log p_{\theta}\left(\pi_{i} | s_{i}\right) \\
&amp;9: \quad \quad \quad  \mathcal{L}_{v} \leftarrow \frac{1}{B}
\sum_{i=1}^{B} \left\| b_{i}-L\left(\pi_{i}\right) \right\| _{2}^{2} \\
&amp;10: \quad \quad \quad  \theta \leftarrow \operatorname{ADAM} \left(
\theta, g_{\theta} \right) \\
&amp;11: \quad \quad \quad  \theta_{v} \leftarrow
\operatorname{ADAM}\left(\theta_{v}, \nabla_{\theta_{v}}
\mathcal{L}_{v}\right) \\
&amp;12: \quad \quad \textbf{end for} \\
&amp;13: \quad \textbf{return } \theta  \\
&amp;14: \textbf{end procedure}
\end{align*}
\]</span></p>
</div>
<h2 id="implementation-in-pytorch">Implementation in PyTorch</h2>
<h3 id="beam-search-in-opennmt-py">Beam Search in OpenNMT-py</h3>
<p>In <a href="/en/2020/tsp-5-rl/!--swig￼9--">Episode 4 Search for Most Likely
Sequence</a>, an 3x3 rectangle trellis is given and several decoding
methods are illustrated in plain python. In PyTorch version, there is a
package <strong>OpenNMT-py</strong> that supports efficient batched beam
search. But due to its complicated <strong>BeamSearch</strong> usage,
previous problem is demonstrated using its API. For its details, please
refer to <a target="_blank" rel="noopener" href="https://medium.com/the-artificial-impostor/implementing-beam-search-part-1-4f53482daabe">Implementing
Beam Search — Part 1: A Source Code Analysis of OpenNMT-py</a></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> exp</span><br><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"><span class="hljs-keyword">from</span> onmt.translate <span class="hljs-keyword">import</span> BeamSearch, GNMTGlobalScorer</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run_example</span>():</span></span><br><span class="line">    BEAM_SIZE = <span class="hljs-number">2</span></span><br><span class="line">    N_BEST = <span class="hljs-number">1</span></span><br><span class="line">    BATCH_SZ = <span class="hljs-number">1</span></span><br><span class="line">    SEQ_LEN = <span class="hljs-number">3</span></span><br><span class="line"></span><br><span class="line">    initial = [<span class="hljs-number">0.35</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.4</span>]</span><br><span class="line">    transition_matrix = [</span><br><span class="line">        [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.1</span>],</span><br><span class="line">        [<span class="hljs-number">0.4</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>],</span><br><span class="line">        [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.4</span>]]</span><br><span class="line"></span><br><span class="line">    beam = BeamSearch(BEAM_SIZE, BATCH_SZ, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, N_BEST, GNMTGlobalScorer(<span class="hljs-number">0.7</span>, <span class="hljs-number">0.</span>, <span class="hljs-string">"avg"</span>, <span class="hljs-string">"none"</span>), <span class="hljs-number">0</span>, <span class="hljs-number">30</span>, <span class="hljs-literal">False</span>, <span class="hljs-number">0</span>, <span class="hljs-built_in">set</span>(), <span class="hljs-literal">False</span>, <span class="hljs-number">0.</span>)</span><br><span class="line">    device_init = torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">    beam.initialize(device_init, torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">30</span>, (BATCH_SZ,)))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">printBestNPaths</span>(<span class="hljs-params">beam: BeamSearch, step: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'\nstep <span class="hljs-subst">{step}</span> beam results:'</span>)</span><br><span class="line">        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(BEAM_SIZE):</span><br><span class="line">            best_path = beam.alive_seq[k].squeeze().tolist()[<span class="hljs-number">1</span>:]</span><br><span class="line">            prob = exp(beam.topk_log_probs[<span class="hljs-number">0</span>][k])</span><br><span class="line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">f'prob <span class="hljs-subst">{prob:<span class="hljs-number">.3</span>f}</span> with path <span class="hljs-subst">{best_path}</span>'</span>)</span><br><span class="line"></span><br><span class="line">    init_scores = torch.log(torch.tensor([initial], dtype=torch.<span class="hljs-built_in">float</span>))</span><br><span class="line">    init_scores = deepcopy(init_scores.repeat(BATCH_SZ * BEAM_SIZE, <span class="hljs-number">1</span>))</span><br><span class="line">    beam.advance(init_scores, <span class="hljs-literal">None</span>)</span><br><span class="line">    printBestNPaths(beam, <span class="hljs-number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(SEQ_LEN - <span class="hljs-number">1</span>):</span><br><span class="line">        idx_list = beam.topk_ids.squeeze().tolist()</span><br><span class="line">        beam_transition = []</span><br><span class="line">        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> idx_list:</span><br><span class="line">            beam_transition.append(transition_matrix[idx])</span><br><span class="line">        beam_transition_tensor = torch.log(torch.tensor(beam_transition))</span><br><span class="line"></span><br><span class="line">        beam.advance(beam_transition_tensor, <span class="hljs-literal">None</span>)</span><br><span class="line">        beam.update_finished()</span><br><span class="line"></span><br><span class="line">        printBestNPaths(beam, step + <span class="hljs-number">1</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>The output is as follows. When <span class="math inline">\(k=2\)</span> and 3 steps, the most likely sequence
is <span class="math inline">\(0 \rightarrow 1 \rightarrow 0\)</span>,
whose probability is 0.084. </p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">step 0 beam results:</span><br><span class="line">prob 0.400 with path [2]</span><br><span class="line">prob 0.350 with path [0]</span><br><span class="line"></span><br><span class="line">step 1 beam results:</span><br><span class="line">prob 0.210 with path [0, 1]</span><br><span class="line">prob 0.160 with path [2, 1]</span><br><span class="line"></span><br><span class="line">step 2 beam results:</span><br><span class="line">prob 0.084 with path [0, 1, 0]</span><br><span class="line">prob 0.000 with path [0, 1, 2]</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="rl-with-pointernetwork">RL with PointerNetwork</h3>
<p>The complete code is on <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/rl_pytorch/TSP_RL_main.py">github
TSP RL</a>. Below are partial core classes.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CombinatorialRL</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">    actor: PointerNet</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, rnn_type, use_embedding, embedding_size, hidden_size, seq_len, num_glimpse, tanh_exploration, use_tanh, attention</span>):</span></span><br><span class="line">        <span class="hljs-built_in">super</span>(CombinatorialRL, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.actor = PointerNet(rnn_type, use_embedding, embedding_size, hidden_size, seq_len, num_glimpse, tanh_exploration, use_tanh, attention)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, batch_input: Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, <span class="hljs-type">List</span>[Tensor], <span class="hljs-type">List</span>[Tensor], <span class="hljs-type">List</span>[Tensor]]:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Args:</span></span><br><span class="line"><span class="hljs-string">            batch_input: [batch_size * 2 * seq_len]</span></span><br><span class="line"><span class="hljs-string">        Returns:</span></span><br><span class="line"><span class="hljs-string">            R: Tensor of shape [batch_size]</span></span><br><span class="line"><span class="hljs-string">            action_prob_list: List of [seq_len], tensor shape [batch_size]</span></span><br><span class="line"><span class="hljs-string">            action_list:      List of [seq_len], tensor shape [batch_size * 2]</span></span><br><span class="line"><span class="hljs-string">            action_idx_list:  List of [seq_len], tensor shape [batch_size]</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        batch_size = batch_input.size(<span class="hljs-number">0</span>)</span><br><span class="line">        seq_len = batch_input.size(<span class="hljs-number">2</span>)</span><br><span class="line">        prob_list, action_idx_list = self.actor(batch_input)</span><br><span class="line"></span><br><span class="line">        action_list = []</span><br><span class="line">        batch_input = batch_input.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span><br><span class="line">        <span class="hljs-keyword">for</span> action_id <span class="hljs-keyword">in</span> action_idx_list:</span><br><span class="line">            action_list.append(batch_input[[x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size)], action_id.data, :])</span><br><span class="line">        action_prob_list = []</span><br><span class="line">        <span class="hljs-keyword">for</span> prob, action_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prob_list, action_idx_list):</span><br><span class="line">            action_prob_list.append(prob[[x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size)], action_id.data])</span><br><span class="line"></span><br><span class="line">        R = self.reward(action_list)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> R, action_prob_list, action_list, action_idx_list</span><br><span class="line">        </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reward</span>(<span class="hljs-params">self, sample_solution: <span class="hljs-type">List</span>[Tensor]</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Computes total distance of tour</span></span><br><span class="line"><span class="hljs-string">        Args:</span></span><br><span class="line"><span class="hljs-string">            sample_solution: list of size N, each tensor of shape [batch_size * 2]</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        Returns:</span></span><br><span class="line"><span class="hljs-string">            tour_len: [batch_size]</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        batch_size = sample_solution[<span class="hljs-number">0</span>].size(<span class="hljs-number">0</span>)</span><br><span class="line">        n = <span class="hljs-built_in">len</span>(sample_solution)</span><br><span class="line">        tour_len = Variable(torch.zeros([batch_size]))</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n - <span class="hljs-number">1</span>):</span><br><span class="line">            tour_len += torch.norm(sample_solution[i] - sample_solution[i + <span class="hljs-number">1</span>], dim=<span class="hljs-number">1</span>)</span><br><span class="line">        tour_len += torch.norm(sample_solution[n - <span class="hljs-number">1</span>] - sample_solution[<span class="hljs-number">0</span>], dim=<span class="hljs-number">1</span>)</span><br><span class="line">        <span class="hljs-keyword">return</span> tour_len</span><br></pre></td></tr></tbody></table></figure>
<h2 id="references">References</h2>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/en/2020/tsp-4-search/" itemprop="url">TSP From DP to Deep Learning. Episode 4: Search for Most Likely Sequence</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-06-05T18:45:01.000Z" itemprop="datePublished">Jun 6 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            10 minutes read (About 1441 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>This is fourth episode of series: TSP From DP to Deep Learning. In
this episode, we systematically compare different searching algorithms
for finding most likely sequence in the context of simplied markov chain
setting. These models can be further utilized in deep learning decoding
stage, which will be illustrated in reinforcement learning, in the next
episode. Full list of this series is listed below.</p>
<ul>
<li><p>Episode 1: <a href="/en/2020/tsp-4-search/!--swig￼6--">AC TSP on AIZU with recursive
DP</a></p></li>
<li><p>Episode 2: <a href="/en/2020/tsp-4-search/!--swig￼7--">TSP DP on a Euclidean
Dataset</a></p></li>
<li><p>Episode 3: <a href="/en/2020/tsp-4-search/!--swig￼8--">Pointer Networks in
PyTorch</a></p></li>
<li><p><strong>Episode 4: <a href="/en/2020/tsp-4-search/!--swig￼9--">Search for Most Likely
Sequence</a></strong></p></li>
<li><p>Episode 5: <a href="/en/2020/tsp-4-search/!--swig￼10--">Reinforcement Learning PyTorch
Implementation</a></p></li>
</ul>
<h2 id="problem-as-markov-chain">Problem as Markov Chain</h2>
<p>In sequence-to-sequence problem, we are always faced with same
problem of determining the best or most likely sequence of output. This
kind of recurring problem exists extensively in algorithms, machine
learning where we are given initial states and the dynamics of the
system, and the goal is to find a path that is most likely. The
corresponding concept, in science or mathematical discipline, is called
Markov Chain.</p>
<p>Let describe the problem in the context of markov chain. Suppose
there are <span class="math inline">\(n\)</span> states, and initial
state is given by $s_0 = [0.35, 0.25, 0.4] $. The transition matrix is
defined by <span class="math inline">\(T\)</span> where $ T[i][j]$
denotes the probability of transitioning from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>. Notice that each row sums to <span class="math inline">\(1.0\)</span>. <span class="math display">\[
T=
\begin{matrix}
&amp; \begin{matrix}0&amp;1&amp;2\end{matrix} \\\\
\begin{matrix}0\\\\1\\\\2\end{matrix} &amp;
  \begin{bmatrix}0.3&amp;0.6&amp;0.1\\\\0.4&amp;0.2&amp;0.4\\\\0.3&amp;0.3&amp;0.4\end{bmatrix}\\\\
\end{matrix}
\]</span></p>
<p>Probability of the next state <span class="math inline">\(s_1\)</span> is derived by multiplication of <span class="math inline">\(s_0\)</span> and <span class="math inline">\(T\)</span>, which can be visually interpreted by
animation below.</p>
<p><img src="/en/2020/tsp-4-search/transition-animated.svg" title="Transition Animation"></p>
<p>The actual probability distribution value of <span class="math inline">\(s_1\)</span> is computed numerically below. Recall
that left multiplying a row with a matrix amounts to making a linear
combination of that row vector.</p>
<p><span class="math display">\[
s_1 =  \begin{bmatrix}0.35&amp; 0.25&amp; 0.4\end{bmatrix}
\begin{matrix}
\begin{bmatrix}0.3&amp;0.6&amp;0.1\\\\0.4&amp;0.2&amp;0.4\\\\0.3&amp;0.3&amp;0.4\end{bmatrix}\\\\
\end{matrix}
= \begin{bmatrix}0.325&amp; 0.35&amp; 0.255\end{bmatrix}
\]</span> Again, state <span class="math inline">\(s_2\)</span> can be
derived in the same way <span class="math inline">\(s_1 \times
T\)</span>, where we assume the transitioning dynamics remains the same.
However, in deep learning problem, the dynamics usually depends on <span class="math inline">\(s_i\)</span>, or vary according to the stage.</p>
<p>Suppose there are only 3 stages in our problem, e.g., <span class="math inline">\(s_0 \rightarrow s_1 \rightarrow s_2\)</span>. Let
<span class="math inline">\(L\)</span> be the number of stages and <span class="math inline">\(N\)</span> be the number of vertices in each
stage. Hence <span class="math inline">\(L=N=3\)</span> in our problem
setting. There could be <span class="math inline">\(N^L\)</span>
different paths starting from initial stage and to final stage.</p>
<p>Let us compute an arbitrary path probability as an example, <span class="math inline">\(2(s_0) \rightarrow 1(s_1) \rightarrow
2(s_2)\)</span>. The total probability is</p>
<p><span class="math display">\[
p(2 \rightarrow 1 \rightarrow 2) = s_0[2] \times T[2][1] \times T[1][2]
= 0.4 \times 0.3 \times 0.4 = 0.048
\]</span></p>
<h2 id="exhaustive-search">Exhaustive Search</h2>
<p>First, we implement <span class="math inline">\(N^L\)</span>
exhaustive or brute force search.</p>
<p>The following Python 3 function returns one most likely sequence and
its probability. Running the algorithm with our example produces 0.084
and route <span class="math inline">\(0 \rightarrow 1 \rightarrow
2\)</span>.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_brute_force</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> combinations_with_replacement</span><br><span class="line">    v = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]</span><br><span class="line">    path_all = combinations_with_replacement(v, L)</span><br><span class="line"></span><br><span class="line">    max_prop = <span class="hljs-number">0.0</span></span><br><span class="line">    max_route = <span class="hljs-literal">None</span></span><br><span class="line">    prob = <span class="hljs-number">0.0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> path <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(path_all):</span><br><span class="line">        <span class="hljs-keyword">for</span> idx, v <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(path):</span><br><span class="line">            <span class="hljs-keyword">if</span> idx == <span class="hljs-number">0</span>:</span><br><span class="line">                prob = initial[v]  <span class="hljs-comment"># reset to initial state</span></span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                prev_v = path[idx-<span class="hljs-number">1</span>]</span><br><span class="line">                prob *= transition[prev_v][v]</span><br><span class="line">        <span class="hljs-keyword">if</span> prob &gt; max_prop:</span><br><span class="line">            max_prop = <span class="hljs-built_in">max</span>(max_prop, prob)</span><br><span class="line">            max_route = path</span><br><span class="line">    <span class="hljs-keyword">return</span> max_prop, max_route</span><br></pre></td></tr></tbody></table></figure>
<h2 id="greedy-search">Greedy Search</h2>
<p>Exhaustive search always generates most likely sequence, as searching
for a needle in the hay at the cost of exponential runtime complexity
<span class="math inline">\(O(N^L)\)</span>. The simplest strategy,
unknown as greedy, identifies one vertex in each stage and then expand
the vertex in next stage. This strategy, of course, is not guaranteed to
find most likely sequence but is fast. See animation below.</p>
<p><img src="/en/2020/tsp-4-search/greedy-animated.svg" title="Greedy Search Animation"></p>
<p>Code in Python 3 is given below. Numpy package is employed to utilize
np.argmax() for code clarity. Notice there are 2 for loops (the other is
np.argmax) so the runtime complexity is <span class="math inline">\(O(N\times L)\)</span>.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_greedy</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">    max_route = []</span><br><span class="line">    max_prop = <span class="hljs-number">0.0</span></span><br><span class="line">    states = np.array(initial)</span><br><span class="line"></span><br><span class="line">    prev_max_v = <span class="hljs-literal">None</span></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, L):</span><br><span class="line">        max_v = np.argmax(states)</span><br><span class="line">        max_route.append(max_v)</span><br><span class="line">        <span class="hljs-keyword">if</span> l == <span class="hljs-number">0</span>:</span><br><span class="line">            max_prop = initial[max_v]</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            max_prop = max_prop * transition[prev_max_v][max_v]</span><br><span class="line">        states = max_prop * states</span><br><span class="line">        prev_max_v = max_v</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> max_prop, max_route</span><br></pre></td></tr></tbody></table></figure>
<h2 id="beam-search">Beam Search</h2>
<p>We could improve greedy strategy a little bit by expanding more
vertices in each stage. In beam search with <span class="math inline">\(k\)</span> nodes, the strategy is in each stage,
identify <span class="math inline">\(k\)</span> nodes with highest
probability and expand these <span class="math inline">\(k\)</span>
nodes into next stage. In our example, <span class="math inline">\(k=2\)</span>, we select first 2 nodes in stage
<span class="math inline">\(s_0\)</span>, expand these 2 nodes and
evaluate <span class="math inline">\(2 \times 3\)</span> nodes in stage
<span class="math inline">\(s_1\)</span>, then select 2 nodes and
evaluate 6 nodes in stage <span class="math inline">\(s_2\)</span>. Beam
search, similar to greedy strategy, is not guaranteed to find most
likely sequence but it extends search space with linear complexity.</p>
<p><img src="/en/2020/tsp-4-search/beam-animated.svg" title="Beam Search Animation"></p>
<p>Below is implementation in Python 3 with PriorityQueue to select top
<span class="math inline">\(k\)</span> nodes. Notice in order to use
reverse order of PriorityQueue, a class with <span class="citation" data-cites="total_ordering">@total_ordering</span> is required to be
defined. The runtime complexity is <span class="math inline">\(O(k\times
N \times L)\)</span> .</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_beam</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span>, K: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    N = <span class="hljs-built_in">len</span>(initial)</span><br><span class="line">    <span class="hljs-keyword">from</span> queue <span class="hljs-keyword">import</span> PriorityQueue</span><br><span class="line">    current_q = PriorityQueue()</span><br><span class="line">    next_q = PriorityQueue()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> total_ordering</span><br><span class="line"><span class="hljs-meta">    @total_ordering</span></span><br><span class="line">    <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PQItem</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, prob, route</span>):</span></span><br><span class="line">            self.prob = prob</span><br><span class="line">            self.route = route</span><br><span class="line">            self.last_v = <span class="hljs-built_in">int</span>(route[-<span class="hljs-number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__eq__</span>(<span class="hljs-params">self, other</span>):</span></span><br><span class="line">            <span class="hljs-keyword">return</span> self.prob == other.prob</span><br><span class="line"></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__lt__</span>(<span class="hljs-params">self, other</span>):</span></span><br><span class="line">            <span class="hljs-keyword">return</span> self.prob &gt; other.prob</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">        next_q.put(PQItem(initial[v], <span class="hljs-built_in">str</span>(v)))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L):</span><br><span class="line">        current_q = next_q</span><br><span class="line">        next_q = PriorityQueue()</span><br><span class="line">        k = K</span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> current_q.empty() <span class="hljs-keyword">and</span> k &gt; <span class="hljs-number">0</span>:</span><br><span class="line">            item = current_q.get()</span><br><span class="line">            prob, route, prev_v = item.prob, item.route, item.last_v</span><br><span class="line">            k -= <span class="hljs-number">1</span></span><br><span class="line">            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                nextItem = PQItem(prob * transition[prev_v][v], route + <span class="hljs-built_in">str</span>(v))</span><br><span class="line">                next_q.put(nextItem)</span><br><span class="line"></span><br><span class="line">    max_item = next_q.get()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> max_item.prob, <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x), max_item.route))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="viterbi-dp">Viterbi DP</h2>
<p>Similarly to TSP DP version, there is a dynamic programming approach,
widely known as Viterbi algorithm, that always finds out sequence with
max probability while reducing runtime complexity from <span class="math inline">\(O(N^L)\)</span> to <span class="math inline">\(O(L
\times N \times N)\)</span> (corresponding to 3 loops in code below).
The core idea is in each stage, an array keeps most likely sequence
ending with each vertex and use the dp array as input to next stage. For
example, let <span class="math inline">\(dp[1][0]\)</span> be the most
likely probability in <span class="math inline">\(s_1\)</span> stage and
end with vertex 0. <span class="math display">\[
dp[1][0] = \max \\{s_0[0] \rightarrow s_1[0], s_0[1] \rightarrow s_1[0],
s_0[2] \rightarrow s_1[0]\\}
\]</span></p>
<p><img src="/en/2020/tsp-4-search/viterbi-animated.svg" title="Viterbi DP Animation"></p>
<p>Illustrative code that returns max probability but not route, in
order to emphasize 3 loop pattern and max operation, honoring the
essence of the algorithm.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_dp</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">    N = <span class="hljs-built_in">len</span>(initial)</span><br><span class="line">    dp = [[<span class="hljs-number">0.0</span> <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(L)]</span><br><span class="line">    dp[<span class="hljs-number">0</span>] = initial[:]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L):</span><br><span class="line">        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">            <span class="hljs-keyword">for</span> prev_v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                dp[l][v] = <span class="hljs-built_in">max</span>(dp[l][v], dp[l - <span class="hljs-number">1</span>][prev_v] * transition[prev_v][v])</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(dp[L-<span class="hljs-number">1</span>])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="probabilistic-sampling">Probabilistic Sampling</h2>
<p>All algorithms described above are deterministic. However, in NLP
deep learning decoding, deterministic property has disadvantage in that
it may get trapped into repeated phrases or sentences. For example,
paragraph like below is commonly generated: </p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This is the best of best of best of ...</span><br></pre></td></tr></tbody></table></figure> One way to get
out of loop is resorting to probabilistic sampling. For example, we can
generate one vertex in each stage probabilistically according to their
weights or according to total path probability.<p></p>
<p>For demonstration purpose, here is the code based on greedy strategy
which probabilistically determines one node at each stage.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_prob_greedy</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">import</span> random</span><br><span class="line">    N = <span class="hljs-built_in">len</span>(initial)</span><br><span class="line">    max_route = []</span><br><span class="line">    max_prop = <span class="hljs-number">0.0</span></span><br><span class="line">    vertices = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]</span><br><span class="line">    prob = initial[:]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, L):</span><br><span class="line">        v_lst = random.choices(vertices, prob)</span><br><span class="line">        v = v_lst[<span class="hljs-number">0</span>]</span><br><span class="line">        max_route.append(v)</span><br><span class="line">        max_prop = prob[v]</span><br><span class="line">        prob = [prob[v] * transition[v][v_target] <span class="hljs-keyword">for</span> v_target <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> max_prop, max_route</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/en/2020/tsp-3-pointer-net/" itemprop="url">TSP From DP to Deep Learning. Episode 3: Pointer Network</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-05-22T06:45:01.000Z" itemprop="datePublished">May 22 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            9 minutes read (About 1349 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>This is third episode of series: TSP From DP to Deep Learning. In
this episode, we will be entering the realm of deep learning,
specifically, a type of sequence-to-sequence called Pointer Networks is
introduced. It is tailored to solve problems like TSP or Convex Hull.
Full list of this series is listed below.</p>
<ul>
<li><p>Episode 1: <a href="/en/2020/tsp-3-pointer-net/!--swig￼4--">AC TSP on AIZU with recursive
DP</a></p></li>
<li><p>Episode 2: <a href="/en/2020/tsp-3-pointer-net/!--swig￼5--">TSP DP on a Euclidean
Dataset</a></p></li>
<li><p><strong>Episode 3: <a href="/en/2020/tsp-3-pointer-net/!--swig￼6--">Pointer Networks in
PyTorch</a></strong></p></li>
<li><p>Episode 4: <a href="/en/2020/tsp-3-pointer-net/!--swig￼7--">Search for Most Likely
Sequence</a></p></li>
<li><p>Episode 5: <a href="/en/2020/tsp-3-pointer-net/!--swig￼8--">Reinforcement Learning PyTorch
Implementation</a></p></li>
</ul>
<h2 id="pointer-networks">Pointer Networks</h2>
<p>In traditional sequence-to-sequence RNN, output classes depend on
pre-defined size. For instance, a word generating RNN will utter one
word from vocabulary of <span class="math inline">\(|V|\)</span> size at
each time step. However, there is large set of problems such as Convex
Hull, Delaunay Triangulation and TSP, where range of the each output is
not pre-defined, but of variable size, defined by the input. <em>Pointer
Networks </em> overcame the constraint by selecting <span class="math inline">\(i\)</span> -th input with probability derived from
attention score.</p>
<h3 id="convex-hull">Convex Hull</h3>
<p>In following example, 10 points are given, the output is a sequence
of points that bounds the set of all points. Each value in the output
sequence is a integer ranging from 1 to 10, in this case, which is the
value given by the concrete example. Generally, finding exact solution
has been proven to be equivelent to sort problem, and has time
complexity <span class="math inline">\(O(n*log(n))\)</span>.</p>
<figure>
<img src="/en/2020/tsp-3-pointer-net/./convex_hull.png" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;=&amp; \left\{P_{1}, \ldots,
P_{10} \right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp; \{2,4,3,5,6,7,2\}
\end{align*}
\]</span></p>
</div>
<h3 id="tsp">TSP</h3>
<p>TSP is almost identical to Convex Hull problem, though output
sequence is of fixed length. In previous epsiode, we reduced from <span class="math inline">\(O(n!)\)</span> to <span class="math inline">\(O(n^2*2^n)\)</span>.</p>
<figure>
<img src="/en/2020/tsp-3-pointer-net/./tsp.svg" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;= &amp;\left\{P_{1}, \ldots, P_{6}
\right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp; \{1,3,2,4,5,6,1\}
\end{align*}
\]</span></p>
</div>
<h3 id="delaunay-triangulation">Delaunay Triangulation</h3>
<p>A Delaunay triangulation for a set of points in a plane is a
triangulation such that each circumcircle of every triangle is empty,
meaning no point from <span class="math inline">\(\mathcal{P}\)</span>
in its interior. This kind of problem outputs a sequence of sets, and
each item in the set ranges from the input set <span class="math inline">\(\mathcal{P}\)</span>. <img src="/en/2020/tsp-3-pointer-net/./delaunay_triangulation.png" alt="image info"></p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;=&amp; \left\{P_{1}, \ldots, P_{5}
\right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp;
\{(1,2,4),(1,4,5),(1,3,5),(1,2,3)\}
\end{align*}
\]</span></p>
</div>
<h3 id="sequence-to-sequence-model">Sequence-to-Sequence Model</h3>
<p>Suppose now n is fixed. given a training pair, <span class="math inline">\((\mathcal{P}, C^{\mathcal{P}})\)</span>, the
vanilla sequence-to-sequence model parameterized by <span class="math inline">\(\theta\)</span> computes the conditional
probability.</p>
<p><span class="math display">\[
\begin{equation}
p\left(\mathcal{C}^{\mathcal{P}} | \mathcal{P} ;
\theta\right)=\prod_{i=1}^{m(\mathcal{P})} p\left(C_{i} | C_{1}, \ldots,
C_{i-1}, \mathcal{P} ; \theta\right)
\end{equation}
\]</span> The parameters of the model are learnt by maximizing the
conditional probabilities for the training set, i.e. <span class="math display">\[
\begin{equation}
\theta^{*}=\underset{\theta}{\arg \max } \sum_{\mathcal{P},
\mathcal{C}^{\mathcal{P}}} \log p\left(\mathcal{C}^{\mathcal{P}} |
\mathcal{P} ; \theta\right)
\end{equation}
\]</span></p>
<h3 id="content-based-input-attention">Content Based Input
Attention</h3>
<p>When attention is applied to vanilla sequence-to-sequence model,
better result is obtained.</p>
<p>Let encoder and decoder states be $ (e_{1}, , e_{n}) $ and $ (d_{1},
, d_{m()}) $, respectively. At each output time <span class="math inline">\(i\)</span>, compute the attention vector <span class="math inline">\(d_i\)</span> to be linear combination of $ (e_{1},
, e_{n}) $ with weights $ (a_{1}^{i}, , a_{n}^{i}) $ <span class="math display">\[
d_{i} = \sum_{j=1}^{n} a_{j}^{i} e_{j}
\]</span></p>
$ (a_{1}^{i}, , a_{n}^{i}) $ is softmax value of $ (u_{1}^{i}, ,
u_{n}^{i}) $ and <span class="math inline">\(u_{j}^{i}\)</span> can be
considered as distance between <span class="math inline">\(d_{i}\)</span> and <span class="math inline">\(e_{j}\)</span>. Notice that <span class="math inline">\(v\)</span>, <span class="math inline">\(W_1\)</span>, and <span class="math inline">\(W_2\)</span> are learnable parameters of the
model.
<div>
<p><span class="math display">\[
\begin{eqnarray}
u_{j}^{i} &amp;=&amp; v^{T} \tanh \left(W_{1} e_{j}+W_{2}
d_\right) \quad j \in(1, \ldots, n) \\
a_{j}^{i} &amp;=&amp; \operatorname{softmax}\left(u_{j}^{i}\right) \quad
j \in(1, \ldots, n)
\end{eqnarray}
\]</span></p>
</div>
<h3 id="pointer-networks-1">Pointer Networks</h3>
<figure>
<img src="/en/2020/tsp-3-pointer-net/./ptr_net.png" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<p>Pointer Networks does not blend the encoder state <span class="math inline">\(e_j\)</span> to propagate extra information to the
decoder, but instead, use <span class="math inline">\(u^i_j\)</span> as
pointers to the input element.</p>
<div>
<p><span class="math display">\[
\begin{eqnarray*}
u_{j}^{i} &amp;=&amp; v^{T} \tanh \left(W_{1} e_{j}+W_{2} d_{i}\right)
\quad j \in(1, \ldots, n) \\
p\left(C_{i} | C_{1}, \ldots, C_{i-1}, \mathcal{P}\right) &amp;=&amp;
\operatorname{softmax}\left(u^{i}\right)
\end{eqnarray*}
\]</span></p>
</div>
<h2 id="more-on-attention">More on Attention</h2>
<p>In <em>FloydHub Blog - Attention Mechanism </em>, a clear and
detailed explanation of difference and similarity between the classic
first type of Attention, commonly referred to as Additive Attention by
<em>Dzmitry Bahdanau </em> and second classic type, known as
Multiplicative Attention and proposed by <em>Thang Luong </em>, is
discussed.</p>
It's well known that in Luong Attention, three ways of alignment scoring
function is defined, or the distance between <span class="math inline">\(d_{i}\)</span> and <span class="math inline">\(e_{j}\)</span>.
<div>
<p><span class="math display">\[
\operatorname{score} \left( d_i, e_j \right)=
\begin{cases}
d_i^{\top} e_j &amp; \text { dot } \\
d_i^{\top} W_a e_j &amp; \text { general } \\
v_a^{\top} \tanh \left( W_a \left[ d_i ; e_j \right] \right) &amp; \text
{ concat }
\end{cases}
\]</span></p>
</div>
<h2 id="pytorch-implementation">PyTorch Implementation</h2>
<p>In <a href="/en/2020/tsp-3-pointer-net/!--swig￼10--">episode 2</a>, we have introduced TSP
dataset where each case is a line, of following form.</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x0, y0, x1, y1, ... output 1 v1 v2 v3 ... 1</span><br></pre></td></tr></tbody></table></figure>
<h3 id="pytorch-dataset">PyTorch Dataset</h3>
<p>Each case is converted to (input, input_len, output_in, output_out,
output_len) of type nd.ndarray with appropriate padding and encapsulated
in a extended PyTorch Dataset. </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPDataset</span>(<span class="hljs-params">Dataset</span>):</span></span><br><span class="line">	<span class="hljs-string">"each data item of form (input, input_len, output_in, output_out, output_len)"</span></span><br><span class="line">	data: <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]</span><br><span class="line">	</span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">		<span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span></span><br><span class="line">		<span class="hljs-built_in">input</span>, input_len, output_in, output_out, output_len = self.data[index]</span><br><span class="line">		<span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>, input_len, output_in, output_out, output_len</span><br></pre></td></tr></tbody></table></figure> <img src="/en/2020/tsp-3-pointer-net/./data_loader.svg" alt="image info"><p></p>
<h3 id="pytorch-pad_packed_sequence">PyTorch pad_packed_sequence</h3>
<p>Code in PyTorch seq-to-seq model typically utilizes
<strong>pack_padded_sequence</strong> and
<strong>pad_packed_sequence</strong> API to reduce computational cost. A
detailed explanation is given here
https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning#decoder-1.</p>
<figure>
<img src="/en/2020/tsp-3-pointer-net/./ex_padded_seq.jpg" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RNNEncoder</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">	rnn: <span class="hljs-type">Union</span>[nn.LSTM, nn.GRU, nn.RNN]</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, rnn_type: <span class="hljs-built_in">str</span>, bidirectional: <span class="hljs-built_in">bool</span>, num_layers: <span class="hljs-built_in">int</span>, input_size: <span class="hljs-built_in">int</span>, hidden_size: <span class="hljs-built_in">int</span>, dropout: <span class="hljs-built_in">float</span></span>):</span></span><br><span class="line">		<span class="hljs-built_in">super</span>(RNNEncoder, self).__init__()</span><br><span class="line">		<span class="hljs-keyword">if</span> bidirectional:</span><br><span class="line">			<span class="hljs-keyword">assert</span> hidden_size % <span class="hljs-number">2</span> == <span class="hljs-number">0</span></span><br><span class="line">			hidden_size = hidden_size // <span class="hljs-number">2</span></span><br><span class="line">		self.rnn = rnn_init(rnn_type, input_size=input_size, hidden_size=hidden_size, bidirectional=bidirectional,num_layers=num_layers, dropout=dropout)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, src: Tensor, src_lengths: Tensor, hidden: Tensor = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, Tensor]:</span></span><br><span class="line">		lengths = src_lengths.view(-<span class="hljs-number">1</span>).tolist()</span><br><span class="line">		packed_src = pack_padded_sequence(src, lengths)</span><br><span class="line">		memory_bank, hidden_final = self.rnn(packed_src, hidden)</span><br><span class="line">		memory_bank = pad_packed_sequence(memory_bank)[<span class="hljs-number">0</span>]</span><br><span class="line">		<span class="hljs-keyword">return</span> memory_bank, hidden_final</span><br></pre></td></tr></tbody></table></figure>
<h3 id="attention-code">Attention Code</h3>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Attention</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">	linear_out: nn.Linear</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dim: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">		<span class="hljs-built_in">super</span>(Attention, self).__init__()</span><br><span class="line">		self.linear_out = nn.Linear(dim * <span class="hljs-number">2</span>, dim, bias=<span class="hljs-literal">False</span>)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score</span>(<span class="hljs-params">self, src: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">		batch_size, src_len, dim = src.size()</span><br><span class="line">		_, target_len, _ = target.size()</span><br><span class="line">		target_ = target</span><br><span class="line">		src_ = src.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span><br><span class="line">		<span class="hljs-keyword">return</span> torch.bmm(target_, src_)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, src: Tensor, target: Tensor, src_lengths: Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, Tensor]:</span></span><br><span class="line">		<span class="hljs-keyword">assert</span> target.dim() == <span class="hljs-number">3</span></span><br><span class="line"></span><br><span class="line">		batch_size, src_len, dim = src.size()</span><br><span class="line">		_, target_len, _ = target.size()</span><br><span class="line"></span><br><span class="line">		align_score = self.score(src, target)</span><br><span class="line"></span><br><span class="line">		mask = sequence_mask(src_lengths)</span><br><span class="line">		<span class="hljs-comment"># (batch_size, max_len) -&gt; (batch_size, 1, max_len)</span></span><br><span class="line">		mask = mask.unsqueeze(<span class="hljs-number">1</span>)</span><br><span class="line">		align_score.data.masked_fill_(~mask, -<span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>))</span><br><span class="line">		align_score = F.softmax(align_score, -<span class="hljs-number">1</span>)</span><br><span class="line"></span><br><span class="line">		c = torch.bmm(align_score, src)</span><br><span class="line"></span><br><span class="line">		concat_c = torch.cat([c, target], -<span class="hljs-number">1</span>)</span><br><span class="line">		attn_h = self.linear_out(concat_c)</span><br><span class="line"></span><br><span class="line">		<span class="hljs-keyword">return</span> attn_h, align_score</span><br></pre></td></tr></tbody></table></figure>
<p>Complete PyTorch implementation source code is also available on <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/tree/master/tsp/ptr_net_pytorch">github</a>.</p>
<h2 id="references">References</h2>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/en/2020/tsp-2-dp-tour/" itemprop="url">TSP From DP to Deep Learning. Episode 2: DP on Euclidean Dataset</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-05-15T06:45:01.000Z" itemprop="datePublished">May 15 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            7 minutes read (About 1098 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>This is second episode of series: TSP From DP to Deep Learning.</p>
<ul>
<li>Episode 1: <a href="/en/2020/tsp-2-dp-tour/!--swig￼10--">AC TSP on AIZU with recursive
DP</a></li>
<li><strong>Episode 2: <a href="/en/2020/tsp-2-dp-tour/!--swig￼11--">TSP DP on a Euclidean
Dataset</a></strong></li>
<li>Episode 3: <a href="/en/2020/tsp-2-dp-tour/!--swig￼12--">Pointer Networks in
PyTorch</a></li>
<li>Episode 4: <a href="/en/2020/tsp-2-dp-tour/!--swig￼13--">Search for Most Likely
Sequence</a></li>
<li>Episode 5: <a href="/en/2020/tsp-2-dp-tour/!--swig￼14--">Reinforcement Learning PyTorch
Implementation</a></li>
</ul>
<h2 id="aizu-tsp-bottom-up-iterative-dp">AIZU TSP Bottom Up Iterative
DP</h2>
<p>In last episode, we provided a top down recursive DP in Python 3 and
Java 8. Now we continue to improve and convert it to bottom up iterative
DP version. Below is a graph with 3 vertices, the top down recursive
calls are completely drawn.</p>
<p><img src="/en/2020/tsp-2-dp-tour/ver3-top-down.svg" title="Top Down Calls"></p>
<p>Looking from bottom up, we could identify corresponding topological
computing order with ease. First, we compute all bit states with 3 ones,
then 2 ones, then 1 one.</p>
<p><img src="/en/2020/tsp-2-dp-tour/ver3-bottom-up.svg" title="Bottom Up States"></p>
<p>Pseudo Java code below.</p>
<figure class="highlight java hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> bitset_num = N; bitset_num &gt;=<span class="hljs-number">0</span>; bitset_num++) {</span><br><span class="line">	<span class="hljs-keyword">while</span>(hasNextCombination(bitset_num)) {</span><br><span class="line">		<span class="hljs-keyword">int</span> state = nextCombination(bitset_num);</span><br><span class="line">		<span class="hljs-comment">// compute dp[state][v], v-th bit is set in state</span></span><br><span class="line">		<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> v = <span class="hljs-number">0</span>; v &lt; n; v++) {</span><br><span class="line">			<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; n; u++) {</span><br><span class="line">				<span class="hljs-comment">// for each u not reached by this state</span></span><br><span class="line">				<span class="hljs-keyword">if</span> (!include(state, u)) {</span><br><span class="line">					dp[state][v] = min(dp[state][v], </span><br><span class="line">						dp[new_state_include_u][u] + dist[v][u]);</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>For example, dp[00010][1] is the min distance starting from vertex 0,
and just arriving at vertex 1: <span class="math inline">\(0 \rightarrow
1 \rightarrow ? \rightarrow ? \rightarrow ? \rightarrow 0\)</span>. In
order to find out total min distance, we need to enumerate all possible
u for first question mark. <span class="math display">\[
(0 \rightarrow 1) +
\begin{align*}
  \min \left\lbrace
  \begin{array}{r@{}l}
    2 \rightarrow ? \rightarrow ? \rightarrow 0 + dist(1,2)
\qquad\text{    new_state=[00110][2] } \qquad\\\\
    3 \rightarrow ? \rightarrow ?  \rightarrow 0 + dist(1,3)
\qquad\text{    new_state=[01010][3] } \qquad\\\\
    4 \rightarrow ? \rightarrow ?  \rightarrow 0 + dist(1,4)
\qquad\text{    new_state=[10010][4] } \qquad
  \end{array}
  \right.
\end{align*}
\]</span></p>
<h3 id="java-iterative-dp-code">Java Iterative DP Code</h3>
<p>AC code in <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_aizu/TSP_loop.py">Python
3</a> and <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_aizu/Main_loop.java">Java
8</a>. Illustrate core Java code below. </p><figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span> </span>{</span><br><span class="line">	<span class="hljs-keyword">int</span> N = g.V_NUM;</span><br><span class="line">	<span class="hljs-keyword">long</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-keyword">long</span>[<span class="hljs-number">1</span> &lt;&lt; N][N];</span><br><span class="line">	<span class="hljs-comment">// init dp[][] with MAX</span></span><br><span class="line">	<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; dp.length; i++) {</span><br><span class="line">		Arrays.fill(dp[i], Integer.MAX_VALUE);</span><br><span class="line">	}</span><br><span class="line">	dp[(<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> state = (<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">2</span>; state &gt;= <span class="hljs-number">0</span>; state--) {</span><br><span class="line">		<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> v = <span class="hljs-number">0</span>; v &lt; N; v++) {</span><br><span class="line">			<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; N; u++) {</span><br><span class="line">				<span class="hljs-keyword">if</span> (((state &gt;&gt; u) &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>) {</span><br><span class="line">					dp[state][v] = Math.min(dp[state][v], dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + g.edges[v][u]);</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">	<span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] == Integer.MAX_VALUE ? -<span class="hljs-number">1</span> : dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>In this way, runtime complexity can be spotted easily, three for
loops leading to O(<span class="math inline">\(2^n * n * n\)</span>) =
O(<span class="math inline">\(2^n*n^2\)</span> ).</p>
<h2 id="dp-on-euclidean-dataset">DP on Euclidean Dataset</h2>
<p>So far, TSP DP has been crystal clear and we move forward to
introducing PTR_NET dataset on <a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/0B2fg8yPGn2TCMzBtS0o4Q2RJaEU">Google
Drive</a> by Oriol Vinyals who is the author of <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.03134">Pointer Networks</a>. Each line
in the dataset has the following pattern: </p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x0, y0, x1, y1, ... output 1 v1 v2 v3 ... 1</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>It first lists n points in (x, y) coordinate, followed by "output",
then followed by one of the minimal distance tours, starting and ending
with vertex 1 (indexed from 1 not 0).</p>
<p>Some examples of 10 vertices are:</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0.607122 0.664447 0.953593 0.021519 0.757626 0.921024 0.586376 0.433565 0.786837 0.052959 0.016088 0.581436 0.496714 0.633571 0.227777 0.971433 0.665490 0.074331 0.383556 0.104392 output 1 3 8 6 10 9 5 2 4 7 1 </span><br><span class="line">0.930534 0.747036 0.277412 0.938252 0.794592 0.794285 0.961946 0.261223 0.070796 0.384302 0.097035 0.796306 0.452332 0.412415 0.341413 0.566108 0.247172 0.890329 0.429978 0.232970 output 1 3 2 9 6 5 8 7 10 4 1 </span><br><span class="line">0.686712 0.087942 0.443054 0.277818 0.494769 0.985289 0.559706 0.861138 0.532884 0.351913 0.712561 0.199273 0.554681 0.657214 0.909986 0.277141 0.931064 0.639287 0.398927 0.406909 output 1 5 2 10 7 4 3 9 8 6 1 </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>Plot first example using code below. </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line">points=<span class="hljs-string">'0.607122 0.664447 0.953593 0.021519 0.757626 0.921024 0.586376 0.433565 0.786837 0.052959 0.016088 0.581436 0.496714 0.633571 0.227777 0.971433 0.665490 0.074331 0.383556 0.104392'</span></span><br><span class="line">float_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">float</span>(x), points.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"></span><br><span class="line">x,y = [],[]</span><br><span class="line"><span class="hljs-keyword">for</span> idx, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(float_list):</span><br><span class="line">  <span class="hljs-keyword">if</span> idx % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:</span><br><span class="line">    x.append(p)</span><br><span class="line">  <span class="hljs-keyword">else</span>:</span><br><span class="line">    y.append(p)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x)):</span><br><span class="line">  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x)):</span><br><span class="line">    <span class="hljs-keyword">if</span> i == j:</span><br><span class="line">      <span class="hljs-keyword">continue</span></span><br><span class="line">    plt.plot((x[i],x[j]),(y[i],y[j]))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><p></p>
<figure>
<img src="/en/2020/tsp-2-dp-tour/tsp10_full.png">
<figcaption>
TSP Case Fully Connected
</figcaption>
</figure>
<p>Now plot the optimal tour: <span class="math display">\[
1 \rightarrow 3 \rightarrow 8 \rightarrow 6 \rightarrow 10 \rightarrow 9
\rightarrow 5 \rightarrow 2 \rightarrow 4 \rightarrow 7 \rightarrow 1
\]</span></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tour_str = <span class="hljs-string">'1 3 8 6 10 9 5 2 4 7 1'</span></span><br><span class="line">tour = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x), tour_str.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tour)-<span class="hljs-number">1</span>):</span><br><span class="line">  p1 = tour[i] - <span class="hljs-number">1</span></span><br><span class="line">  p2 = tour[i + <span class="hljs-number">1</span>] - <span class="hljs-number">1</span></span><br><span class="line">  plt.plot((x[p1],x[p2]),(y[p1],y[p2]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/en/2020/tsp-2-dp-tour/tsp10_tour.png">
<figcaption>
TSP Case Minimal Tour
</figcaption>
</figure>
<h2 id="python-code-illustrated">Python Code Illustrated</h2>
<h3 id="init-graph-edges">Init Graph Edges</h3>
<p>Based on previous top down version, several changes are made. First,
we need to have an edge between every 2 vertices and due to our matrix
representation of the directed edge, edges of 2 directions are
initialized.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">g: Graph = Graph(N)</span><br><span class="line"><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">	<span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">		diff_x = coordinates[v][<span class="hljs-number">0</span>] - coordinates[u][<span class="hljs-number">0</span>]</span><br><span class="line">		diff_y = coordinates[v][<span class="hljs-number">1</span>] - coordinates[u][<span class="hljs-number">1</span>]</span><br><span class="line">		dist: <span class="hljs-built_in">float</span> = math.sqrt(diff_x * diff_x + diff_y * diff_y)</span><br><span class="line">		g.setDist(u, v, dist)</span><br><span class="line">		g.setDist(v, u, dist)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="auxilliary-variable-to-track-tour-vertices">Auxilliary Variable
to Track Tour Vertices</h3>
<p>One major enhancement is to record the optimal tour during
enumerating. We introduce another variable parent[bitstate][v] to track
next vertex u, with shortest path.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ret: <span class="hljs-built_in">float</span> = FLOAT_INF</span><br><span class="line">u_min: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span></span><br><span class="line">	<span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num):</span><br><span class="line">		<span class="hljs-keyword">if</span> (state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>:</span><br><span class="line">			s: <span class="hljs-built_in">float</span> = self._recurse(u, state | <span class="hljs-number">1</span> &lt;&lt; u)</span><br><span class="line">				<span class="hljs-keyword">if</span> s + edges[v][u] &lt; ret:</span><br><span class="line">					ret = s + edges[v][u]</span><br><span class="line">					u_min = u</span><br><span class="line">	dp[state][v] = ret</span><br><span class="line">	self.parent[state][v] = u_min</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>After minimal tour distance is found, one optimal tour is formed with
the help of parent variable. </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_form_tour</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">	self.tour = [<span class="hljs-number">0</span>]</span><br><span class="line">	bit = <span class="hljs-number">0</span></span><br><span class="line">	v = <span class="hljs-number">0</span></span><br><span class="line">	<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num - <span class="hljs-number">1</span>):</span><br><span class="line">		v = self.parent[bit][v]</span><br><span class="line">		self.tour.append(v)</span><br><span class="line">		bit = bit | (<span class="hljs-number">1</span> &lt;&lt; v)</span><br><span class="line">	self.tour.append(<span class="hljs-number">0</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>Note that for each test case, only one tour is given after "output".
Our code may form a different tour but it has same distance as what the
dataset generates, which can be verified by following code snippet. See
full code on <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_plane/TSP_plane.py">github</a>.
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tsp: TSPSolver = TSPSolver(g)</span><br><span class="line">tsp.solve()</span><br><span class="line"></span><br><span class="line">output_dist: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span></span><br><span class="line">output_tour = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x) - <span class="hljs-number">1</span>, output.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(output_tour)):</span><br><span class="line">	pre_v = output_tour[v-<span class="hljs-number">1</span>]</span><br><span class="line">	curr_v = output_tour[v]</span><br><span class="line">	diff_x = coordinates[pre_v][<span class="hljs-number">0</span>] - coordinates[curr_v][<span class="hljs-number">0</span>]</span><br><span class="line">	diff_y = coordinates[pre_v][<span class="hljs-number">1</span>] - coordinates[curr_v][<span class="hljs-number">1</span>]</span><br><span class="line">	dist: <span class="hljs-built_in">float</span> = math.sqrt(diff_x * diff_x + diff_y * diff_y)</span><br><span class="line">	output_dist += dist</span><br><span class="line"></span><br><span class="line">	passed = <span class="hljs-built_in">abs</span>(tsp.dist - output_dist) &lt; <span class="hljs-number">10e-5</span></span><br><span class="line">	<span class="hljs-keyword">if</span> passed:</span><br><span class="line">		<span class="hljs-built_in">print</span>(<span class="hljs-string">f'passed dist=<span class="hljs-subst">{tsp.tour}</span>'</span>)</span><br><span class="line">	<span class="hljs-keyword">else</span>:</span><br><span class="line">		<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Min Tour Distance = <span class="hljs-subst">{output_dist}</span>, Computed Tour Distance = <span class="hljs-subst">{tsp.dist}</span>, Expected Tour = <span class="hljs-subst">{output_tour}</span>, Result = <span class="hljs-subst">{tsp.tour}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/en/2020/tsp-1-dp-alg/" itemprop="url">TSP From DP to Deep Learning. Episode 1: DP Algorithm</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-05-08T06:45:01.000Z" itemprop="datePublished">May 8 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/en/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            9 minutes read (About 1417 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Travelling
salesman problem (TSP)</a> is a classic NP hard computer algorithmic
problem. In this series, we will first solve TSP problem in an exact
manner by ACing TSP on aizu with dynamic programming, and then move on
to train a Pointer Network with Pytorch to obtain an approximate
solution with deep learning and reinforcement learning technology.
Complete episodes are listed as follows:</p>
<ul>
<li><p><strong>Episode 1: <a href="/en/2020/tsp-1-dp-alg/!--swig￼6--">AC TSP on AIZU with
recursive DP</a></strong></p></li>
<li><p>Episode 2: <a href="/en/2020/tsp-1-dp-alg/!--swig￼7--">TSP DP on a Euclidean
Dataset</a></p></li>
<li><p>Episode 3: <a href="/en/2020/tsp-1-dp-alg/!--swig￼8--">Pointer Networks in
PyTorch</a></p></li>
<li><p>Episode 4: <a href="/en/2020/tsp-1-dp-alg/!--swig￼9--">Search for Most Likely
Sequence</a></p></li>
<li><p>Episode 5: <a href="/en/2020/tsp-1-dp-alg/!--swig￼10--">Reinforcement Learning PyTorch
Implementation</a></p></li>
</ul>
<h2 id="tsp-problem-review">TSP Problem Review</h2>
<p>TSP can be modelled as a graph problem where both directed and
undirected graphs and both completely or partially connected graphs are
applicable. The following picture in <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Wikipedia
TSP</a> is an undirected but complete TSP with four vertices, A, B, C,
D. TSP requries a tour with minimal total distance, starting from
arbitrarily picked vertex and ending with the same node while covering
all vertices exactly once. For example, <span class="math inline">\(A
\rightarrow B \rightarrow C \rightarrow D \rightarrow A\)</span> and
<span class="math inline">\(A \rightarrow C \rightarrow B \rightarrow D
\rightarrow A\)</span> are valid tours and among all tours there is only
one minimal distance value (though multiple tours with same minimum may
exist).</p>
<figure>
<img src="/en/2020/tsp-1-dp-alg/wiki_k4.png">
<figcaption>
Wikipedia 4 Vertices Example
</figcaption>
</figure>
Despite different types of graphs, notice that we can always employ an
adjacency matrix to represent a graph. The above graph can thus be
represented by this matrix
<div>
<p><span class="math display">\[
\begin{matrix}
&amp; \begin{matrix}A&amp;B&amp;C&amp;D\end{matrix} \\
\begin{matrix}A\\B\\C\\D\end{matrix} &amp;
  \begin{bmatrix}-&amp;20&amp;42&amp;35\\20&amp;-&amp;30&amp;34\\42&amp;30&amp;-&amp;12\\35&amp;34&amp;12&amp;-\end{bmatrix}\\
\end{matrix}
\]</span></p>
</div>
<p>Of course, typically, TSP problem takes the form of n cooridanates in
a plane, corresponding to complete and undirected graph, because in
plane every pair of vertices has one connected edge and the edge has
same distance in both directions.</p>
<p><img src="/en/2020/tsp-1-dp-alg/5-simplex_graph.svg" title="Fully Connected Graph"></p>
<h2 id="aizu-tsp-online-judge">AIZU TSP Online Judge</h2>
<p><a target="_blank" rel="noopener" href="http://judge.u-aizu.ac.jp/onlinejudge/description.jsp?id=DPL_2_A">AIZU</a>
has a TSP problem where a directed and incomplete graph with V vertices
and E directed edges is given, and the output expects minimal total
distance. For example below having 4 vertices and 6 edges.</p>
<p><img src="/en/2020/tsp-1-dp-alg/vertex4-problem.svg" title="Directed 4 Vertices Problem"></p>
<p>This test case has minimal tour distance 16, with corresponding tour
being <span class="math inline">\(0\rightarrow1\rightarrow3\rightarrow2\rightarrow0\)</span>,
as shown in red edges. However, the AIZU problem may not have a valid
result because not every pair of vertices is guaranteed to be connected.
In that case, -1 is required, which can also be interpreted as
infinity.</p>
<p><img src="/en/2020/tsp-1-dp-alg/vertex4-sol.svg" title="Directed 4 Vertices Solution"></p>
<h3 id="brute-force-solution">Brute Force Solution</h3>
<p>A naive way is to enumerate all possible routes starting from vertex
0 and keep minimal total distance ever generated. Python code below
illustrates a 4 point vertices graph.</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> permutations</span><br><span class="line">v = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]</span><br><span class="line">p = permutations(v)</span><br><span class="line"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(p):</span><br><span class="line">  <span class="hljs-built_in">print</span>([<span class="hljs-number">0</span>] + <span class="hljs-built_in">list</span>(t) + [<span class="hljs-number">0</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>The possible routes are </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure> This approach has a runtime
complexity of O(<span class="math inline">\(n!\)</span>), which won't
pass AIZU.<p></p>
<p><img src="/en/2020/tsp-1-dp-alg/factorial_paths.svg" title="Factorial Number of Paths"></p>
<h3 id="dynamic-programming">Dynamic Programming</h3>
<p>To AC AIZU TSP, we need to have acceleration of the factorial runtime
complexity by using bitmask dynamic programming. First, let us map
visited state to a binary value. In the 4 vertices case, it's "0110" if
node 2 and 1 already visited and ending at node 1. Besides, we need to
track current vertex to start from. So we extend dp from one dimension
to two dimensions <span class="math inline">\(dp[bitstate][v]\)</span>.
In the example, it's <span class="math inline">\(dp["0110"][1]\)</span>. The transition
formula is given by <span class="math display">\[
dp[bitstate][v] = \min ( dp[bitstate \cup \{u\}][u] + dist(v,u) \mid u
\notin bitstate )
\]</span></p>
<p>The resulting time complexity is O(<span class="math inline">\(n^2*2^n\)</span> ), since there are <span class="math inline">\(2^n * n\)</span> total states and for each state
one more round loop is needed. Factorial and exponential functions are
significantly different.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(n!\)</span></th>
<th><span class="math inline">\(n^2*2^n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n=8</td>
<td>40320</td>
<td>16384</td>
</tr>
<tr class="even">
<td>n=10</td>
<td>3628800</td>
<td>102400</td>
</tr>
<tr class="odd">
<td>n=12</td>
<td>479001600</td>
<td>589824</td>
</tr>
<tr class="even">
<td>n=14</td>
<td>87178291200</td>
<td>3211264</td>
</tr>
</tbody>
</table>
<p>Pause a second and think about why bitmask DP works here. Notice
there are lots of redundant sub calls, one of which is hightlighted in
red ellipse below.</p>
<p><img src="/en/2020/tsp-1-dp-alg/dp_paths.svg" title="DP Duplicate State"></p>
<p>In this episode, a straightforward top down memoization DP version is
given in Python 3 and Java 8. Benefit of top down DP approach is that we
don't need to consider topological ordering when permuting all states.
Notice that there is a trick in Java, where each element of dp is
initialized as Integer.MAX_VALUE, so that only one statement is needed
to update new dp value. </p><figure class="highlight java hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = Math.min(res, s + g.edges[v][u]);</span><br></pre></td></tr></tbody></table></figure> However, the code simplicity is at
cost of clarity and care should be taken when dealing with actual INF
(not reachable case). In python version, we could have used the same
trick, perhaps by intializing with a large long value representing INF.
But for clarity, we manually handle different cases in if-else
statements and mark intial value as -1 (INT_INF).<p></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INT_INF = -<span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> s != INT_INF <span class="hljs-keyword">and</span> edges[v][u] != INT_INF:</span><br><span class="line">    <span class="hljs-keyword">if</span> ret == INT_INF:</span><br><span class="line">        ret = s + edges[v][u]</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        ret = <span class="hljs-built_in">min</span>(ret, s + edges[v][u])</span><br></pre></td></tr></tbody></table></figure>
<p>Below is complete AC code in Python 3 and Java 8. Also can be
downloaded on <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/tree/master/tsp/alg_aizu">github</a>.</p>
<h3 id="aizu-java-8-recursive-version">AIZU Java 8 Recursive
Version</h3>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">// passed http://judge.u-aizu.ac.jp/onlinejudge/description.jsp?id=DPL_2_A</span></span><br><span class="line"><span class="hljs-keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="hljs-keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Main</span> </span>{</span><br><span class="line">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Graph</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> V_NUM;</span><br><span class="line">        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span>[][] edges;</span><br><span class="line"></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Graph</span><span class="hljs-params">(<span class="hljs-keyword">int</span> V_NUM)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">this</span>.V_NUM = V_NUM;</span><br><span class="line">            <span class="hljs-keyword">this</span>.edges = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[V_NUM][V_NUM];</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; V_NUM; i++) {</span><br><span class="line">                Arrays.fill(<span class="hljs-keyword">this</span>.edges[i], Integer.MAX_VALUE);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setDist</span><span class="hljs-params">(<span class="hljs-keyword">int</span> src, <span class="hljs-keyword">int</span> dest, <span class="hljs-keyword">int</span> dist)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">this</span>.edges[src][dest] = dist;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSP</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> Graph g;</span><br><span class="line">        <span class="hljs-keyword">long</span>[][] dp;</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">TSP</span><span class="hljs-params">(Graph g)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">this</span>.g = g;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">int</span> N = g.V_NUM;</span><br><span class="line">            dp = <span class="hljs-keyword">new</span> <span class="hljs-keyword">long</span>[<span class="hljs-number">1</span> &lt;&lt; N][N];</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; dp.length; i++) {</span><br><span class="line">                Arrays.fill(dp[i], -<span class="hljs-number">1</span>);</span><br><span class="line">            }</span><br><span class="line">    </span><br><span class="line">            <span class="hljs-keyword">long</span> ret = recurse(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);</span><br><span class="line">            <span class="hljs-keyword">return</span> ret == Integer.MAX_VALUE ? -<span class="hljs-number">1</span> : ret;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> <span class="hljs-title">recurse</span><span class="hljs-params">(<span class="hljs-keyword">int</span> state, <span class="hljs-keyword">int</span> v)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">int</span> ALL = (<span class="hljs-number">1</span> &lt;&lt; g.V_NUM) - <span class="hljs-number">1</span>;</span><br><span class="line">            <span class="hljs-keyword">if</span> (dp[state][v] &gt;= <span class="hljs-number">0</span>) {</span><br><span class="line">                <span class="hljs-keyword">return</span> dp[state][v];</span><br><span class="line">            }</span><br><span class="line">            <span class="hljs-keyword">if</span> (state == ALL &amp;&amp; v == <span class="hljs-number">0</span>) {</span><br><span class="line">                dp[state][v] = <span class="hljs-number">0</span>;</span><br><span class="line">                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="hljs-keyword">long</span> res = Integer.MAX_VALUE;</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; g.V_NUM; u++) {</span><br><span class="line">                <span class="hljs-keyword">if</span> ((state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>) {</span><br><span class="line">                    <span class="hljs-keyword">long</span> s = recurse(state | <span class="hljs-number">1</span> &lt;&lt; u, u);</span><br><span class="line">                    res = Math.min(res, s + g.edges[v][u]);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            dp[state][v] = res;</span><br><span class="line">            <span class="hljs-keyword">return</span> res;</span><br><span class="line">    </span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{</span><br><span class="line">    </span><br><span class="line">        Scanner in = <span class="hljs-keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="hljs-keyword">int</span> V = in.nextInt();</span><br><span class="line">        <span class="hljs-keyword">int</span> E = in.nextInt();</span><br><span class="line">        Graph g = <span class="hljs-keyword">new</span> Graph(V);</span><br><span class="line">        <span class="hljs-keyword">while</span> (E &gt; <span class="hljs-number">0</span>) {</span><br><span class="line">            <span class="hljs-keyword">int</span> src = in.nextInt();</span><br><span class="line">            <span class="hljs-keyword">int</span> dest = in.nextInt();</span><br><span class="line">            <span class="hljs-keyword">int</span> dist = in.nextInt();</span><br><span class="line">            g.setDist(src, dest, dist);</span><br><span class="line">            E--;</span><br><span class="line">        }</span><br><span class="line">        System.out.println(<span class="hljs-keyword">new</span> TSP(g).solve());</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="aizu-python-3-recursive-version">AIZU Python 3 Recursive
Version</h3>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span></span><br><span class="line"></span><br><span class="line">INT_INF = -<span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Graph</span>:</span></span><br><span class="line">    v_num: <span class="hljs-built_in">int</span></span><br><span class="line">    edges: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, v_num: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">        self.v_num = v_num</span><br><span class="line">        self.edges = [[INT_INF <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(v_num)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(v_num)]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setDist</span>(<span class="hljs-params">self, src: <span class="hljs-built_in">int</span>, dest: <span class="hljs-built_in">int</span>, dist: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">        self.edges[src][dest] = dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPSolver</span>:</span></span><br><span class="line">    g: Graph</span><br><span class="line">    dp: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, g: Graph</span>):</span></span><br><span class="line">        self.g = g</span><br><span class="line">        self.dp = [[<span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(g.v_num)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span> &lt;&lt; g.v_num)]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self._recurse(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_recurse</span>(<span class="hljs-params">self, v: <span class="hljs-built_in">int</span>, state: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    </span></span><br><span class="line"><span class="hljs-string">        :param v:</span></span><br><span class="line"><span class="hljs-string">        :param state:</span></span><br><span class="line"><span class="hljs-string">        :return: -1 means INF</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        dp = self.dp</span><br><span class="line">        edges = self.g.edges</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-keyword">if</span> dp[state][v] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</span><br><span class="line">            <span class="hljs-keyword">return</span> dp[state][v]</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-keyword">if</span> (state == (<span class="hljs-number">1</span> &lt;&lt; self.g.v_num) - <span class="hljs-number">1</span>) <span class="hljs-keyword">and</span> (v == <span class="hljs-number">0</span>):</span><br><span class="line">            dp[state][v] = <span class="hljs-number">0</span></span><br><span class="line">            <span class="hljs-keyword">return</span> dp[state][v]</span><br><span class="line">    </span><br><span class="line">        ret: <span class="hljs-built_in">int</span> = INT_INF</span><br><span class="line">        <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num):</span><br><span class="line">            <span class="hljs-keyword">if</span> (state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>:</span><br><span class="line">                s: <span class="hljs-built_in">int</span> = self._recurse(u, state | <span class="hljs-number">1</span> &lt;&lt; u)</span><br><span class="line">                <span class="hljs-keyword">if</span> s != INT_INF <span class="hljs-keyword">and</span> edges[v][u] != INT_INF:</span><br><span class="line">                    <span class="hljs-keyword">if</span> ret == INT_INF:</span><br><span class="line">                        ret = s + edges[v][u]</span><br><span class="line">                    <span class="hljs-keyword">else</span>:</span><br><span class="line">                        ret = <span class="hljs-built_in">min</span>(ret, s + edges[v][u])</span><br><span class="line">        dp[state][v] = ret</span><br><span class="line">        <span class="hljs-keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span></span><br><span class="line">    V, E = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())</span><br><span class="line">    g: Graph = Graph(V)</span><br><span class="line">    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(E):</span><br><span class="line">        src, dest, dist = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())</span><br><span class="line">        g.setDist(src, dest, dist)</span><br><span class="line"></span><br><span class="line">    tsp: TSPSolver = TSPSolver(g)</span><br><span class="line">    <span class="hljs-built_in">print</span>(tsp.solve())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 MyEncyclopedia&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true" aria-controls="dropdown-menu7">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>English</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu">
            <div class="dropdown-content">
            
                <a href="/tags/Deep-Learning/" class="dropdown-item">
                    简体中文
                </a>
            
                <a href="/en/tags/Deep-Learning/" class="dropdown-item">
                    English
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.en.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>