<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>标签: docker - MyEncyclopedia</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">


<link href="/en/tags/docker/" rel="alternate" hreflang="en" />
    


<meta name="description" content="">





    <meta property="og:type" content="website">
<meta property="og:title" content="MyEncyclopedia">
<meta property="og:url" content="https://myencyclopedia.github.io/tags/docker/">
<meta property="og:site_name" content="MyEncyclopedia">
<meta property="og:locale">
<meta property="article:author" content="MyEncyclopedia">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="搜索" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://myencyclopedia.github.io">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#docker</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2023/docker-neuralprophet/" itemprop="url">初识时间序列预测神器 NeuralProphet 实战预测股票指数</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2023-01-01T18:45:01.000Z" itemprop="datePublished">1月 2 2023</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            18 分钟 读完 (约 2690 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><h2 id="neuralprophet-深度学习版-prophet">NeuralProphet 深度学习版
Prophet</h2>
<p>NeuralProphet 是 Facebook开发的新一代 Prophet
时间序列预测框架。加入了 PyTorch 的自回归 （AR）模块，并用 PyTorch
重新实现了 Prophet，它的显著特性如下</p>
<ul>
<li>使用 PyTorch 的优化，性能比原始 Prophet 快不少</li>
<li>引入 AR-Net 建模时间序列自回归，并配有非线性层</li>
<li>自定义损失和指标</li>
<li>滞后协变量（lagged covariates） 和 AR 本地上下文特性 （local context
with support for auto-regression）</li>
</ul>
<p>NeuralProphet 继承了 Prophet
模块可接受性的特点，将预测的值分解到趋势、季节性、AR、事件（节日）几个模块。其中
AR 部分的神经网络实现由 AR-Net: A simple Auto-Regressive Neural Network
for time-series 这篇论文详细描述。</p>
<p>尽管 NeuralProphet
有不少优势，但是使用起来小问题不断，主要表现为文档不甚详细，API
设计的比较智能（隐晦），坑不少。这一期我们来实战体验一下，后续会深入代码和论文。</p>
<p>相关论文链接</p>
<ul>
<li><p>[Prophet] Forecasting at scale <a target="_blank" rel="noopener" href="https://peerj.com/preprints/3190/">https://peerj.com/preprints/3190/</a></p></li>
<li><p>NeuralProphet: Explainable Forecasting at Scale <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.15397">https://arxiv.org/abs/2111.15397</a></p></li>
<li><p>AR-Net: A simple Auto-Regressive Neural Network for time-series
<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.12436">https://arxiv.org/abs/1911.12436</a></p></li>
</ul>
<h2 id="安装neuralprophet">安装NeuralProphet</h2>
<p>使用命令通过 pip 就可以安装 NeuralProphet。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install neuralprophet==0.5.0</span><br></pre></td></tr></tbody></table></figure>
<p>如果在 Jupyter Notebook 中使用
NeuralProphet，最好安装实时版本，允许你实时可视化模型损失。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install neuralprophet[live]==0.5.0</span><br></pre></td></tr></tbody></table></figure>
<p>要注意一点，安装 neuralprophet 会关联安装 Pytorch
CPU版本库，如果你需要使用 GPU 或者不希望覆盖原有的 Pytorch
版本，请手动安装。</p>
<p>此外，<code>MyEncyclopedia</code> 和往常一样，为大家准备了一个 docker
镜像，预装最新的 NeuralProphet
库，镜像中还包含预下载的数据集和本文所有的 Jupyter Notebook
代码。大家关注<code>MyEncyclopedia</code> 公众号，执行下面命令后网页打开
http://localhost:8888/ 开箱即用</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull myencyclopedia/neuralprophet-tut</span><br><span class="line">docker run -p 8888:8888 myencyclopedia/neuralprophet-tut bash -c <span class="hljs-string">'jupyter notebook --port 8888 --NotebookApp.token='</span><span class="hljs-string">' --NotebookApp.password='</span><span class="hljs-string">' --ip 0.0.0.0 --allow-root'</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="标准普尔-500-指数数据集">标准普尔 500 指数数据集</h2>
<p>这次实战我们使用过去 10 年标准普尔 500
指数的每日股价数据。可以通过如下命令下载数据集，使用 docker
镜像的同学无需额外下载。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> pandas_datareader <span class="hljs-keyword">as</span> pdr</span><br><span class="line"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line">%matplotlib inlinestart = datetime(<span class="hljs-number">2010</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>)</span><br><span class="line">end = datetime(<span class="hljs-number">2020</span>, <span class="hljs-number">12</span>, <span class="hljs-number">11</span>)</span><br><span class="line">df_sp500 = pdr.get_data_fred(<span class="hljs-string">'sp500'</span>, start, end)</span><br><span class="line">plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">7</span>))</span><br><span class="line">plt.plot(df_sp500)</span><br><span class="line">plt.title(<span class="hljs-string">'S&amp;P 500 Prices'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/10_year.png"></p>
<p>从图中我们可以清楚地看到标准普尔 500
指数总体呈上升趋势，其中有几个点的价格大幅上涨或下跌。我们可以将这些点视为趋势变化点。鉴于此，我们先从一个仅有趋势模块的
NeuralProphet
模型开始，逐渐加入季节性，AR和节日模块，观察其预测表现和API
具体使用。</p>
<p>使用
NeuralProphet，我们必须确保数据的格式包含如下两列：日期列名<strong>ds</strong>，目标变量列名
<strong>y</strong>。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_sp500 = df_sp500.reset_index().rename(columns={<span class="hljs-string">'DATE'</span>: <span class="hljs-string">'ds'</span>, <span class="hljs-string">'sp500'</span>: <span class="hljs-string">'y'</span>})</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/sp500.png"></p>
<p><img src="/zh/2023/docker-neuralprophet/sp500_head.png"></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">len</span>(df_sp500[~df_sp500.y.isnull()])</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2007</span></span><br></pre></td></tr></tbody></table></figure>
<p>总结 SP 500 数据观察到的特点，后面会反复和过程变量做对比：</p>
<ul>
<li><p>总共<strong>2080</strong>条数据中非空数据有<strong>2007</strong>条</p></li>
<li><p>开始日期为 <strong>2012-12-24</strong>，结束日期
<strong>2020-12-11</strong></p></li>
<li><p>在有效时间段 2012-12-24 至
2020-12-11，非交易的日期（周末，节日）没有在列。</p></li>
</ul>
<h2 id="模块一趋势">模块一：趋势</h2>
<p>使用
NeuralProphet，我们可以通过指定几个重要参数来对时间序列数据中的趋势进行建模。</p>
<ul>
<li><strong>n_changepoints</strong> — 指定趋势发生变化的点数。</li>
<li><strong>trend_reg</strong> — 控制趋势变化点的正则化参数。较大的值
(~1–100) 将惩罚更多的变化点。较小的值 (~0.001–1.0)
将允许更多的变化点。</li>
<li><strong>changepoints_range</strong> — 默认值
0.8，表示后20%的训练数据无 changepoints</li>
</ul>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = NeuralProphet(n_changepoints=<span class="hljs-number">100</span>,</span><br><span class="line">                      trend_reg=<span class="hljs-number">0.05</span>,</span><br><span class="line">                      yearly_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">                      weekly_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">                      daily_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">                      epochs=<span class="hljs-number">100</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="训练模型">训练模型</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_train, df_val = model.split_df(df_sp500, freq=<span class="hljs-string">"D"</span>, valid_p=<span class="hljs-number">0.2</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">metrics = model.fit(df_train,</span><br><span class="line">                    freq=<span class="hljs-string">'D'</span>,</span><br><span class="line">                    validation_df=df_val,</span><br><span class="line">                    progress=<span class="hljs-string">"plot"</span></span><br><span class="line">                    )</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/plot.gif"></p>
<p>训练最终趋于稳定。我们来看看 <code>split_df API</code> 的细节。</p>
<p><img src="/zh/2023/docker-neuralprophet/trend_df_train.png"></p>
<p><img src="/zh/2023/docker-neuralprophet/trend_df_val.png"></p>
<p><code>df_train</code> 共1606 行，为前 80% 记录，df_val 共401
行，为后20% 记录，两者没有交集，合计 2007 行数据，等于 df_sp500
有效数据数。原来默认情况下 <code>split_df</code> 会扔掉 y 值为 NaN
数据。这里两者没有交集，大家注意对比启用AR后的数据切分两者会有交集。原有是启用自回归后，预测需要过去
k 个点作为输入。</p>
<h3 id="预测验证集">预测验证集</h3>
<p>接着来看看验证集，即 <code>df_val</code> 上的预测表现。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">future = model.make_future_dataframe(df_sp500, periods=<span class="hljs-number">60</span>, n_historic_predictions=<span class="hljs-literal">True</span>)</span><br><span class="line">forecast = model.predict(future)</span><br><span class="line">fig = model.plot(forecast)</span><br><span class="line">fig.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/pred_trend.png"></p>
<p>make_future_dataframe 准备好待预测的数据格式，参数
periods=60，n_historic_predictions=True 意义扩展 df_sp500
到未来60天后，同时保留所有所有现有 df_sp500
的数据点，这些历史点也将做预测。我们 dump 出 make_future_dataframe 后的
future 变量。</p>
<p><img src="/zh/2023/docker-neuralprophet/trend_future.png"></p>
<p><img src="/zh/2023/docker-neuralprophet/trend_future_y.png"></p>
<p>future 序列扩展了 df_sp500，有 y 值的共2007条，和 df_sp500
一致。时间扩展到了 2021-02-09，大约是 2021-12-11
后的60天，这个也和总条数 2140 一致，等于 df_sp500 总条数 2080 加上
periods=60 的部分。</p>
<p>接着来看 predict 后的 forecast 变量。y 列依然有 2007 条，多了 yhat1
和 trend 两列。</p>
<p><img src="/zh/2023/docker-neuralprophet/trend_forecast.png"></p>
<p>最后，<code>model.plot(forecast)</code>
会绘制出事实点和预测点的曲线，注意图中预测值比实际值要稍长一些，因为预测值到
<strong>2021-02-09</strong>，实际值仅到
<strong>2020-12-11</strong>。</p>
<h3 id="模块归因">模块归因</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fig_components = model.plot_components(forecast)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/pred_trend_comp.png"></p>
<p>由于只启用了趋势，只有一个模块输出。</p>
<p>很明显，我们的模型捕捉到了标准普尔 500
指数的总体上涨趋势，但该模型存在欠拟合问题，尤其是当我们查看未知未来的60天的预测，更能发现问题。</p>
<h3 id="仅预测未来">仅预测未来</h3>
<p>同样的预测代码，将 n_historic_predictions 改成 False
会只预测未知未来60天。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">future = model.make_future_dataframe(df_sp500, periods=<span class="hljs-number">60</span>, n_historic_predictions=<span class="hljs-literal">False</span>)</span><br><span class="line">forecast = model.predict(future)</span><br><span class="line">fig = model.plot(forecast)</span><br><span class="line">fig.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/pred_trend_no_hist.png"></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(future), <span class="hljs-built_in">len</span>(forecast))</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">60</span> <span class="hljs-number">60</span></span><br></pre></td></tr></tbody></table></figure>
<p>根据上图，我们可以看到模型对未来的预测遵循一条直线，天天上涨的股票，还在这里看什么，还不赶紧去买！</p>
<h2 id="模块二季节性">模块二：季节性</h2>
<p>真实世界的时间序列数据通常涉及季节性模式。即使对于股票市场也是如此，一月效应等趋势可能会逐年出现。我们可以通过添加年度季节性来使之前的模型更加完善。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model = NeuralProphet(n_changepoints=<span class="hljs-number">100</span>,</span><br><span class="line">                      trend_reg=<span class="hljs-number">0.05</span>,</span><br><span class="line">                      yearly_seasonality=<span class="hljs-literal">True</span>,</span><br><span class="line">                      weekly_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">                      daily_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">                      epochs=<span class="hljs-number">100</span>)</span><br><span class="line"></span><br><span class="line">df_train, df_val = model.split_df(df_sp500, freq=<span class="hljs-string">"D"</span>, valid_p=<span class="hljs-number">0.2</span>)</span><br><span class="line"></span><br><span class="line">metrics = model.fit(df_train,</span><br><span class="line">                    freq=<span class="hljs-string">'D'</span>,</span><br><span class="line">                    validation_df=df_val,</span><br><span class="line">                    progress=<span class="hljs-string">"bar"</span></span><br><span class="line">                    )</span><br></pre></td></tr></tbody></table></figure>
<h3 id="预测验证集-1">预测验证集</h3>
<p><img src="/zh/2023/docker-neuralprophet/pred_season.png"></p>
<p>和之前一条直线相比，现在对数据的预测显得更现实些。</p>
<h3 id="section"></h3>
<h3 id="模块归因-1">模块归因</h3>
<p>现在预测的 Y 值是两个部分的模块的加和了。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fig_components = model.plot_components(forecast)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/pred_season_comp.png"></p>
<p>标准普尔 500 指数预测具有年度季节性，包括历史数据。</p>
<h3 id="仅预测未来-1">仅预测未来</h3>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_forecast(model, sp500_data, periods=60, historic_predictions=False, highlight_steps_ahead=60)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/pred_season_no_hist.png"></p>
<p>根据上图，我们可以看到这个模型更真实一些，但仍然存在欠拟合问题。因此，我们再引入自回归模型
AR 来进一步拟合。</p>
<h2 id="模块三自回归-ar">模块三：自回归 AR</h2>
<p>AR-Net
是一种用于时间序列预测的自回归神经网络。自回归模型使用来自先前时间步长的过去历史数据来预测，这就是<strong>自回归</strong>一词的来源。</p>
<p>例如，为了预测标准普尔 500 指数的价格，我们可以训练一个模型，使用过去
60 天的价格来预测未来 60
天的价格。分别对应以下代码中的<strong>n_lags</strong>和<strong>n_forecasts</strong>参数。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = NeuralProphet(</span><br><span class="line">    n_forecasts=<span class="hljs-number">60</span>,</span><br><span class="line">    n_lags=<span class="hljs-number">60</span>,</span><br><span class="line">    changepoints_range=<span class="hljs-number">0.95</span>,</span><br><span class="line">    n_changepoints=<span class="hljs-number">100</span>,</span><br><span class="line">    yearly_seasonality=<span class="hljs-literal">True</span>,</span><br><span class="line">    weekly_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">    daily_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">    batch_size=<span class="hljs-number">32</span>,</span><br><span class="line">    epochs=<span class="hljs-number">100</span>,</span><br><span class="line">    learning_rate=<span class="hljs-number">1.0</span>,</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="训练模型-1">训练模型</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df_train, df_val = model.split_df(df_sp500, freq=<span class="hljs-string">"D"</span>, valid_p=<span class="hljs-number">0.2</span>)</span><br><span class="line">metrics = model.fit(df_train,</span><br><span class="line">                    freq=<span class="hljs-string">'D'</span>,</span><br><span class="line">                    validation_df=df_val,</span><br><span class="line">                    progress=<span class="hljs-string">"plot"</span></span><br><span class="line">                    )</span><br></pre></td></tr></tbody></table></figure>
<p>切分训练和验证集代码一样，但是由于引入 AR，df_train，df_val
之间有60条数据重合，这是因为，在验证或者预测过程中，传入的 dataframe
前60条不做预测，从61条开始预测，预测会使用当前日期前60条作为 AR
模块的输入。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(df_train.ds.tolist()).intersection(<span class="hljs-built_in">set</span>(df_val.ds.tolist())))</span><br><span class="line"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">60</span></span><br></pre></td></tr></tbody></table></figure>
<p>不过奇怪的是，df_train 加上 df_val 总共有 2305 + 665 = 2970
条记录，时间跨度依然是 2012-12-24 至
2020-12-11。但是去除重复的60条记录后居然剩余2910 条， 比 df_sp500 2080
条记录数还要多不少。</p>
<p><img src="/zh/2023/docker-neuralprophet/ar_df_train.png"></p>
<p><img src="/zh/2023/docker-neuralprophet/ar_df_val.png"></p>
<p>这里笔者稍微花了点时间终于弄清楚：df_train 和 df_val 会填充
2012-12-24 至 2020-12-11 所有的 missing 日期，并使用插值填充 y！</p>
<p><img src="/zh/2023/docker-neuralprophet/ar_df_train_head.png"></p>
<h3 id="预测验证集-2">预测验证集</h3>
<p>这一次，我们将 periods 设成 0，也就是不扩展 df_sp500
时间到未知的未来。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">future = model.make_future_dataframe(df_sp500, periods=<span class="hljs-number">0</span>, n_historic_predictions=<span class="hljs-literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/ar_future.png"></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">forecast = model.predict(future)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/ar_forecast.png"></p>
<p>forecast 格式变得复杂，引入了 yhat1, yhat2, ...，yhat60，ar1, ar2,
...，ar60 等众多列，这里的60对应于 n_forecasts=60</p>
<p>第一个预测值开始于 forecast 的第61条记录，对应于 n_lags = 60</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">forecast[~forecast.yhat1.isnull()]</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/ar_forecast_predicted.png"></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fig = model.plot(forecast)</span><br><span class="line">fig.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2023/docker-neuralprophet/pred_ar.png"></p>
<h3 id="模块归因-2">模块归因</h3>
<p><img src="/zh/2023/docker-neuralprophet/pred_ar_comp.png"></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_forecast(model, sp500_data, periods=60, historic_predictions=False, highlight_steps_ahead=60)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="仅预测未来-2">仅预测未来</h3>
<p><img src="/zh/2023/docker-neuralprophet/pred_ar_no_hist.png"></p>
<h2 id="模块四事件节日">模块四：事件（节日）</h2>
<p>我们还可以配置模型以考虑节假日因素，因为节假日很可能会影响股市走势。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model = NeuralProphet(</span><br><span class="line">    n_forecasts=<span class="hljs-number">60</span>,</span><br><span class="line">    n_lags=<span class="hljs-number">60</span>,</span><br><span class="line">    changepoints_range=<span class="hljs-number">0.95</span>,</span><br><span class="line">    n_changepoints=<span class="hljs-number">100</span>,</span><br><span class="line">    yearly_seasonality=<span class="hljs-literal">True</span>,</span><br><span class="line">    weekly_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">    daily_seasonality=<span class="hljs-literal">False</span>,</span><br><span class="line">    batch_size=<span class="hljs-number">32</span>,</span><br><span class="line">    epochs=<span class="hljs-number">100</span>,</span><br><span class="line">    learning_rate=<span class="hljs-number">1.0</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = model.add_country_holidays(<span class="hljs-string">"US"</span>, mode=<span class="hljs-string">"additive"</span>, lower_window=-<span class="hljs-number">1</span>, upper_window=<span class="hljs-number">1</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>只需 add_country_holidays 一条语句就可以启用预定义的美国节假日。</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_forecast(model, sp500_data, periods=60, historic_predictions=False, highlight_steps_ahead=60)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="预测验证集-3">预测验证集</h3>
<p><img src="/zh/2023/docker-neuralprophet/pred_holiday.png"></p>
<h3 id="模块归因-3">模块归因</h3>
<p><img src="/zh/2023/docker-neuralprophet/pred_holiday_comp.png"></p>
<h3 id="仅预测未来-3">仅预测未来</h3>
<p><img src="/zh/2023/docker-neuralprophet/pred_holiday_no_hist.png"></p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2022/docker-faiss-transformer/" itemprop="url">实战入门 faiss 搜索bert 最邻近句子：docker CPU镜像开箱即用，无需额外安装下载</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2022-07-08T18:45:01.000Z" itemprop="datePublished">7月 9 2022</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 分钟 读完 (约 1886 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>在这一期中，我们延续上一期 <em>Bert 中文短句相似度计算 Docker
CPU镜像</em>，继续使用 <code>huggingface transformer</code> 和
<code>sentence-transformer</code> 类库，并将英语句子生成 bert
embedding，然后引入 <code>faiss</code>
类库来建立索引，最后查询最接近的句子。</p>
<h2 id="docker-镜像获取方式">Docker 镜像获取方式</h2>
<p>本期 docker 镜像获取方式为，关注 <code>MyEncyclopedia</code>
公众号后回复 <code>docker-faiss-transformer</code>
即可获取如下完整命令。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 8888:8888 myencyclopedia/faiss-demo bash -c <span class="hljs-string">'jupyter notebook --allow-root --port 8888 --NotebookApp.token= --ip 0.0.0.0'</span></span><br></pre></td></tr></tbody></table></figure>
<p>然后打开浏览器，输入
<code>http://localhost:8888/notebooks/faiss_demo.ipynb</code></p>
<h2 id="faiss-简介">faiss 简介</h2>
<p>Faiss 的全称是Facebook AI Similarity Search，是由 Facebook
开发的适用于稠密向量匹配的开源库，作为向量化检索开山鼻祖，Faiss
提供了一套查询海量高维数据集的解决方案，它从两个方面改善了暴力搜索算法存在的问题：降低空间占用和加快检索速度。此外，Faiss
提供了若干种方法实现数据压缩，包括 PCA、Product-Quantization等。</p>
<p><strong>Faiss 主要特性：</strong></p>
<ul>
<li>支持相似度检索和聚类；</li>
<li>支持多种索引方式；</li>
<li>支持CPU和GPU计算；</li>
<li>支持Python和C++调用；</li>
</ul>
<h3 id="faiss-使用流程">Faiss 使用流程</h3>
<p>使用 faiss
分成两部，第一步需要对原始向量建立索引文件，第二步再对索引文件进行向量
<code>search</code> 操作。</p>
<p>在第一次建立索引文件的时候，需要经过 <code>train</code> 和
<code>add</code>
两个过程；后续如果有新的向量需要被添加到索引文件，只需要一个
<code>add</code>
操作来实现增量索引更新，但是如果增量的量级与原始索引差不多的话，整个向量空间就可能发生了一些变化，这个时候就需要重新建立整个索引文件，也就是再用全部的向量来走一遍
<code>train</code> 和 <code>add</code>，至于具体是如何
<code>train</code> 和 <code>add</code>的，就和特定的索引类型有关了。</p>
<h3 id="indexflatl2-indexflatip"><strong>1. IndexFlatL2</strong> &amp;
indexFlatIP</h3>
<p>对于精确搜索，例如欧式距离 faiss.indexFlatL2 或 内积距离
faiss.indexFlatIP，没有 <code>train</code> 过程，<code>add</code>
完直接可以 <code>search</code>。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> faiss </span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 建立索引, 定义为dimension d = 128</span></span><br><span class="line">index = faiss.IndexFlatL2(d)</span><br><span class="line"></span><br><span class="line"> <span class="hljs-comment"># add vectors, xb 为 (100000,128)大小的numpy</span></span><br><span class="line">index.add(xb)                 </span><br><span class="line"><span class="hljs-built_in">print</span>(index.ntotal) </span><br><span class="line"><span class="hljs-comment"># 索引中向量的数量, 输出100000</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 求4-近邻</span></span><br><span class="line">k = <span class="hljs-number">4</span></span><br><span class="line"><span class="hljs-comment"># xq为query embedding, 大小为(10000,128)</span></span><br><span class="line">D, I = index.search(xq, k)     </span><br><span class="line"><span class="hljs-comment">## D shape (10000,4)，表示每个返回点的embedding 与 query embedding的距离,</span></span><br><span class="line"><span class="hljs-comment">## I shape (10000,4)，表示和query embedding最接近的k个物品id，</span></span><br><span class="line"><span class="hljs-built_in">print</span>(I[:<span class="hljs-number">5</span>])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="indexivfflat"><strong>2. IndexIVFFlat</strong></h3>
<p>IndexFlatL2
的结果虽然精确，但当数据集比较大的时候，暴力搜索的时间复杂度很高，因此我们一般会使用其他方式的索引来加速。比如
IndexIVFFlat，将数据集在 <code>train</code> 阶段分割为几部分，技术术语为
<code>Voronoi
Cells</code>，每个数据向量只能落在一个cell中。<code>Search</code>
时只需要查询query向量落在cell中的数据了，降低了距离计算次数。这个过程本质就是高维
KNN 聚类算法。<code>search</code> 阶段使用倒排索引来。</p>
<p>IndexIVFFlat 需要一个训练的阶段，其与另外一个索引 quantizer
有关，通过 quantizer 来判断属于哪个cell。IndexIVFFlat
在搜索阶段，引入了nlist(cell的数量)与nprob(执行搜索的cell数)参数。增大nprobe可以得到与brute-force更为接近的结果，nprobe就是速度与精度的调节器。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> faiss</span><br><span class="line">nlist = <span class="hljs-number">100</span></span><br><span class="line">k = <span class="hljs-number">4</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 建立索引, 定义为dimension d = 128</span></span><br><span class="line">quantizer = faiss.IndexFlatL2(d)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 使用欧式距离 L2 建立索引。</span></span><br><span class="line">index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">## xb: (100000,128)</span></span><br><span class="line">index.train(xb) </span><br><span class="line">index.add(xb)                </span><br><span class="line">index.nprobe = <span class="hljs-number">10</span>  <span class="hljs-comment"># 默认 nprobe 是 1 ,可以设置的大一些试试</span></span><br><span class="line">D, I = index.search(xq, k)</span><br><span class="line"><span class="hljs-built_in">print</span>(I[-<span class="hljs-number">5</span>:])   <span class="hljs-comment"># 最后五次查询的结果</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="indexivfpq"><strong>3. IndexIVFPQ</strong></h3>
<p>IndexFlatL2 和
IndexIVFFlat都要存储所有的向量数据。对于超大规模数据集来说，可能会不大现实。因此IndexIVFPQ
索引可以用来压缩向量，具体的压缩算法就是
Product-Quantization，注意，由于高维向量被压缩，因此 <code>search</code>
时候返回也是近似的结果。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> faiss</span><br><span class="line"></span><br><span class="line">nlist = <span class="hljs-number">100</span></span><br><span class="line"><span class="hljs-comment"># 每个向量分8段</span></span><br><span class="line">m = <span class="hljs-number">8</span> </span><br><span class="line"><span class="hljs-comment"># 求4-近邻</span></span><br><span class="line">k = <span class="hljs-number">4</span> </span><br><span class="line">quantizer = faiss.IndexFlatL2(d)    <span class="hljs-comment"># 内部的索引方式依然不变</span></span><br><span class="line">index = faiss.IndexIVFPQ(quantizer, d, nlist, m, <span class="hljs-number">8</span>) <span class="hljs-comment"># 每个向量都被编码为8个字节大小</span></span><br><span class="line">index.train(xb)</span><br><span class="line">index.add(xb)</span><br><span class="line">index.nprobe = <span class="hljs-number">10</span>                </span><br><span class="line">D, I = index.search(xq, k)  <span class="hljs-comment"># 检索</span></span><br><span class="line"><span class="hljs-built_in">print</span>(I[-<span class="hljs-number">5</span>:])</span><br></pre></td></tr></tbody></table></figure>
<p>在本期中，我们仅使用基本的 IndexIVFFlat 和 IndexFlatIP 完成 bert
embedding 的索引和搜索，后续会有篇幅来解读 Product-Quantization
的论文原理和代码实践。</p>
<h2 id="ag_news-新闻数据集">ag_news 新闻数据集</h2>
<p>ag_news 新闻数据集 3.0 包含了英语新闻标题，training 部分包含
120000条数据， test 部分包含 7600条数据。</p>
<p>ag_news 可以通过 huggingface datasets API 自动下载</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_dataset</span>(<span class="hljs-params">part=<span class="hljs-string">'test'</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:</span></span><br><span class="line">    ds = datasets.load_dataset(<span class="hljs-string">"ag_news"</span>)</span><br><span class="line">    list_str = [r[<span class="hljs-string">'text'</span>] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> ds[part]]</span><br><span class="line">    <span class="hljs-keyword">return</span> list_str</span><br><span class="line">    </span><br><span class="line">list_str = load_dataset(part=<span class="hljs-string">'train'</span>)</span><br><span class="line"><span class="hljs-built_in">print</span>(<span class="hljs-string">f'<span class="hljs-subst">{<span class="hljs-built_in">len</span>(list_str)}</span>'</span>)</span><br><span class="line"><span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> list_str[:<span class="hljs-number">3</span>]:</span><br><span class="line">    <span class="hljs-built_in">print</span>(s)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">'\n'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>显示前三条新闻标题为</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">120000</span><br><span class="line">Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\band of ultra-cynics, are seeing green again.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\which has a reputation for making well-timed and occasionally\controversial plays in the defense industry, has quietly placed\its bets on another part of the market.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\about the economy and the outlook for earnings are expected to\hang over the stock market next week during the depth of the\summer doldrums.</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="sentence-transformer">sentence-transformer</h2>
<p>和上一期一样，我们利用<code>sentence-transformer</code>
生成句子级别的embedding。其原理基于 Sentence-BERT: Sentence Embeddings
using Siamese BERT-Networks
（https://arxiv.org/abs/1908.10084）这篇论文。基本思想很直接，将句子中的每个词的
bert embedding
，输进入一个池化层(pooling)，例如选择最简单的平均池化层，将所有token
embedding 的均值作为输出，便得到跟输入句子长度无关的一个定长的 sentence
embedding。</p>
<p><img src="/zh/2022/docker-faiss-transformer/model.png"></p>
<h2 id="结果展示">结果展示</h2>
<p>数据集 train 部分由于包含的样本比较多，需要一段时间生成 bert
embedding，大家可以使用 <code>load_dataset(part='test')</code>
来快速体验。下面我们演示一个查询 how to make money 的最接近结果。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">index = load_index(<span class="hljs-string">'news_train.index'</span>)</span><br><span class="line">list_id = query(model, index, <span class="hljs-string">'how to make money'</span>)</span><br><span class="line"><span class="hljs-keyword">for</span> <span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> list_id:</span><br><span class="line">    <span class="hljs-built_in">print</span>(list_str[<span class="hljs-built_in">id</span>])</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Profit From That Traffic Ticket Got a traffic ticket? Can't beat 'em? Join 'em by investing in the company that processes those tickets.</span><br><span class="line"></span><br><span class="line">Answers in the Margins By just looking at operating margins, investors can find profitable industry leaders.</span><br><span class="line"></span><br><span class="line">Types of Investors: Which Are You? Learn a little about yourself, and it may improve your performance.</span><br><span class="line"></span><br><span class="line">Target Can Aim High Target can maintain its discount image while offering pricier services and merchandise.</span><br><span class="line"></span><br><span class="line">Finance moves Ford into the black US carmaker Ford Motor returns to profit, as the money it makes from lending to customers outweighs losses from selling vehicles.</span><br></pre></td></tr></tbody></table></figure>
<h2 id="核心代码">核心代码</h2>
<p>所有可运行代码和数据都已经包含在 docker
镜像中了，下面列出核心代码</p>
<h3 id="建立索引">建立索引</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_flat</span>(<span class="hljs-params">index_name, id_list, embedding_list, num_clusters</span>):</span></span><br><span class="line">    <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">    <span class="hljs-keyword">import</span> faiss</span><br><span class="line"></span><br><span class="line">    dim = <span class="hljs-number">768</span></span><br><span class="line">    m = <span class="hljs-number">16</span></span><br><span class="line">    </span><br><span class="line">    embeddings = np.asarray(embedding_list)</span><br><span class="line">    </span><br><span class="line">    quantiser = faiss.IndexFlatIP(dim)</span><br><span class="line">    index = faiss.IndexIVFFlat(quantiser, dim, num_clusters, faiss.METRIC_INNER_PRODUCT)</span><br><span class="line">    index.train(embeddings)  <span class="hljs-comment">## clustering</span></span><br><span class="line">    </span><br><span class="line">    ids = np.arange(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(id_list))</span><br><span class="line">    ids = np.asarray(ids.astype(<span class="hljs-string">'int64'</span>))</span><br><span class="line">    </span><br><span class="line">    index.add_with_ids(embeddings, ids)</span><br><span class="line">    <span class="hljs-built_in">print</span>(index.is_trained) </span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Total Number of Embeddings in the index"</span>, index.ntotal)</span><br><span class="line">    faiss.write_index(index, index_name)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="查询结果">查询结果</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">query</span>(<span class="hljs-params">model, index, query_str: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span></span><br><span class="line">    topk = <span class="hljs-number">5</span></span><br><span class="line">    q_embed = model.encode([query_str])</span><br><span class="line">    D, I = index.search(q_embed, topk)</span><br><span class="line">    <span class="hljs-built_in">print</span>(D)</span><br><span class="line">    <span class="hljs-built_in">print</span>(I)</span><br><span class="line">    <span class="hljs-keyword">return</span> I[<span class="hljs-number">0</span>].tolist()</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2022/docker-sentence-transformer-chinese/" itemprop="url">Bert 中文短句相似度计算 Docker CPU镜像</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2022-06-17T18:45:01.000Z" itemprop="datePublished">6月 18 2022</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            11 分钟 读完 (约 1576 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>在这一期中，我们还是制作了一个集数据，模型，代码一体的 docker
环境，给大家开箱即用体验中文BERT句子embedding体验。具体地，我们基于
<code>BERT-wwm-ext</code>，<code>huggingface transformer</code> 和
<code>sentence-transformer</code> 把玩中文句子embedding
并寻找和查询短语相似度最接近的句子。</p>
<h2 id="docker-镜像获取方式">Docker 镜像获取方式</h2>
<p>本期 docker 镜像获取方式为，关注 <code>MyEncyclopedia</code>
公众号后回复 <code>docker-sentence-transformer</code>
即可获取镜像地址和启动命令。</p>
<h2 id="哈工大讯飞中文-bert">哈工大讯飞中文 Bert</h2>
<p>在中文预训练领域，哈工大讯飞联合实验室（HFL）发布的基于全词Mask的中文预训练模型
<code>BERT-wwm-ext</code> 是业界的标杆之一。<code>BERT-wwm-ext</code>
支持 <code>Tensorflow</code>, <code>Pytorch</code> （通过
<code>huggingface transformer</code> 接口）以及 <code>PaddleHub</code>
的接口或者类库，使用起来十分方便。下面的代码为官网中通过
<code>huggingface transformer</code> 接口直接下载并加载到
<code>Pytorch</code> 平台中。Github 地址为
https://github.com/ymcui/Chinese-BERT-wwm</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel</span><br><span class="line"></span><br><span class="line">model_name = <span class="hljs-string">'hfl/chinese-bert-wwm'</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(model_name)</span><br><span class="line">model = BertModel.from_pretrained(model_name)</span><br></pre></td></tr></tbody></table></figure>
<p>通过 <code>huggingface transformer</code> 的好处在于
<code>sentence-transformer</code> 也支持
<code>huggingface</code>，因此，通过
<code>huggingface</code>，我们无需手动串联 <code>BERT-wwm-ext</code> 和
<code>sentence-transformer</code>，少写了不少代码。</p>
<h2 id="sentence-transformer">sentence-transformer</h2>
<p><code>sentence-transformer</code> 顾名思义是利用
<code>transformer</code>
词向量的预训练模型来生成句子级别的embedding。原理基于这篇论文
Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
（https://arxiv.org/abs/1908.10084）。基本思想直接了当：将句子中的每个词经
bert embedding 后，输入池化层
(pooling)，例如选择最简单的平均池化层，再将所有token embedding
的均值作为输出，便得到跟输入句子长度无关的一个定长的 sentence
embedding。</p>
<p><img src="/zh/2022/docker-sentence-transformer-chinese/model.png"></p>
<p>下面的代码是其官网的一个基本例子，底层通过 <code>huggingface</code>
接口自动下载并加载 bert 词向量，并计算三句英语句子的 sentence
embedding。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer</span><br><span class="line">model = SentenceTransformer(<span class="hljs-string">'paraphrase-MiniLM-L6-v2'</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Our sentences we like to encode</span></span><br><span class="line">sentences = [<span class="hljs-string">'This framework generates embeddings for each input sentence'</span>,</span><br><span class="line">    <span class="hljs-string">'Sentences are passed as a list of string.'</span>,</span><br><span class="line">    <span class="hljs-string">'The quick brown fox jumps over the lazy dog.'</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Sentences are encoded by calling model.encode()</span></span><br><span class="line">embeddings = model.encode(sentences)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Print the embeddings</span></span><br><span class="line"><span class="hljs-keyword">for</span> sentence, embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sentences, embeddings):</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Sentence:"</span>, sentence)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Embedding:"</span>, embedding)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">""</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>当然，我们也可以绕过 <code>sentence-transformer</code> API，直接使用
<code>pytorch</code> API 和 <code>huggingface</code>
手动实现平均池化层，生成句子的 sentence embedding。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"><span class="hljs-keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Mean Pooling - Take attention mask into account for correct averaging</span></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mean_pooling</span>(<span class="hljs-params">model_output, attention_mask</span>):</span></span><br><span class="line">    token_embeddings = model_output[<span class="hljs-number">0</span>] <span class="hljs-comment">#First element of model_output contains all token embeddings</span></span><br><span class="line">    input_mask_expanded = attention_mask.unsqueeze(-<span class="hljs-number">1</span>).expand(token_embeddings.size()).<span class="hljs-built_in">float</span>()</span><br><span class="line">    sum_embeddings = torch.<span class="hljs-built_in">sum</span>(token_embeddings * input_mask_expanded, <span class="hljs-number">1</span>)</span><br><span class="line">    sum_mask = torch.clamp(input_mask_expanded.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>), <span class="hljs-built_in">min</span>=<span class="hljs-number">1e-9</span>)</span><br><span class="line">    <span class="hljs-keyword">return</span> sum_embeddings / sum_mask</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Sentences we want sentence embeddings for</span></span><br><span class="line">sentences = [<span class="hljs-string">'This framework generates embeddings for each input sentence'</span>,</span><br><span class="line">             <span class="hljs-string">'Sentences are passed as a list of string.'</span>,</span><br><span class="line">             <span class="hljs-string">'The quick brown fox jumps over the lazy dog.'</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Load AutoModel from huggingface model repository</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"sentence-transformers/all-MiniLM-L6-v2"</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="hljs-string">"sentence-transformers/all-MiniLM-L6-v2"</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Tokenize sentences</span></span><br><span class="line">encoded_input = tokenizer(sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, max_length=<span class="hljs-number">128</span>, return_tensors=<span class="hljs-string">'pt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Compute token embeddings</span></span><br><span class="line"><span class="hljs-keyword">with</span> torch.no_grad():</span><br><span class="line">    model_output = model(**encoded_input)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">#Perform pooling. In this case, mean pooling</span></span><br><span class="line">sentence_embeddings = mean_pooling(model_output, encoded_input[<span class="hljs-string">'attention_mask'</span>])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="中文最相近的句子">中文最相近的句子</h2>
<p>有了上面每个组件的使用方法，让我们生成下面中文句子的embedding</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sentences = [</span><br><span class="line">    <span class="hljs-string">'今天晚上想吃牛排'</span>,</span><br><span class="line">    <span class="hljs-string">'MyEncyclopedia公众号全栈人工智能'</span>,</span><br><span class="line">    <span class="hljs-string">'人工智能需要懂很多数学么'</span>,</span><br><span class="line">    <span class="hljs-string">'上海疫情有完没完'</span>,</span><br><span class="line">    <span class="hljs-string">'教育部：连续7天社会面无疫情 高校可组织校园招聘'</span>,</span><br><span class="line">    <span class="hljs-string">'福建舰"下水！100秒看中国航母高光时刻'</span>,</span><br><span class="line">    <span class="hljs-string">'医保承担多少核酸检测费用？压力多大？'</span>,</span><br><span class="line">    <span class="hljs-string">'张家口过度防疫整改后又被曝光：要证明牛是阴性'</span>,</span><br><span class="line">    <span class="hljs-string">'上海多家银行天天排队爆满 有老人凌晨2点开始排队'</span>,</span><br><span class="line">    <span class="hljs-string">'A股不惧海外暴跌！走出独立行情沪指收复3300点'</span>,</span><br><span class="line">    <span class="hljs-string">'俄方称已准备好重启俄乌和谈'</span>,</span><br><span class="line">    <span class="hljs-string">'《自然》：奥密克戎感染后嗅觉丧失症状比原来少了'</span></span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure>
<p>接着我们给出如下三个短语的查询，找到和每个查询最匹配的三个句子
</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q1 = <span class="hljs-string">'码农的春天来了么'</span></span><br><span class="line">q2 = <span class="hljs-string">'国际局势'</span></span><br><span class="line">q3 = <span class="hljs-string">'健康'</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<p>运行结果如下</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Query: 码农的春天来了么</span><br><span class="line"></span><br><span class="line">Top 3 most similar sentences <span class="hljs-keyword">in</span> corpus:</span><br><span class="line">人工智能需要懂很多数学么 (Cosine Score: 0.7606)</span><br><span class="line">MyEncyclopedia公众号全栈人工智能 (Cosine Score: 0.7498)</span><br><span class="line">上海疫情有完没完 (Cosine Score: 0.7449)</span><br><span class="line"></span><br><span class="line">----------------------------------------------</span><br><span class="line">Query: 国际局势</span><br><span class="line"></span><br><span class="line">Top 3 most similar sentences <span class="hljs-keyword">in</span> corpus:</span><br><span class="line">俄方称已准备好重启俄乌和谈 (Cosine Score: 0.7041)</span><br><span class="line">MyEncyclopedia公众号全栈人工智能 (Cosine Score: 0.6897)</span><br><span class="line">上海疫情有完没完 (Cosine Score: 0.6888)</span><br><span class="line"></span><br><span class="line">----------------------------------------------</span><br><span class="line">Query: 健康</span><br><span class="line"></span><br><span class="line">Top 3 most similar sentences <span class="hljs-keyword">in</span> corpus:</span><br><span class="line">上海疫情有完没完 (Cosine Score: 0.5882)</span><br><span class="line">MyEncyclopedia公众号全栈人工智能 (Cosine Score: 0.5870)</span><br><span class="line">今天晚上想吃牛排 (Cosine Score: 0.5815)</span><br></pre></td></tr></tbody></table></figure>
<p>结果发现 <code>上海疫情有完没完</code> 是一切问题的关键。。。</p>
<h2 id="完整代码">完整代码</h2>
<p>附上完整代码</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer</span><br><span class="line"></span><br><span class="line">model_name = <span class="hljs-string">'hfl/chinese-bert-wwm'</span></span><br><span class="line">model = SentenceTransformer(model_name)</span><br><span class="line"></span><br><span class="line">sentences = [</span><br><span class="line">    <span class="hljs-string">'今天晚上想吃牛排'</span>,</span><br><span class="line">    <span class="hljs-string">'MyEncyclopedia公众号全栈人工智能'</span>,</span><br><span class="line">    <span class="hljs-string">'人工智能需要懂很多数学么'</span>,</span><br><span class="line">    <span class="hljs-string">'上海疫情有完没完'</span>,</span><br><span class="line">    <span class="hljs-string">'教育部：连续7天社会面无疫情 高校可组织校园招聘'</span>,</span><br><span class="line">    <span class="hljs-string">'福建舰"下水！100秒看中国航母高光时刻'</span>,</span><br><span class="line">    <span class="hljs-string">'医保承担多少核酸检测费用？压力多大？'</span>,</span><br><span class="line">    <span class="hljs-string">'张家口过度防疫整改后又被曝光：要证明牛是阴性'</span>,</span><br><span class="line">    <span class="hljs-string">'上海多家银行天天排队爆满 有老人凌晨2点开始排队'</span>,</span><br><span class="line">    <span class="hljs-string">'A股不惧海外暴跌！走出独立行情沪指收复3300点'</span>,</span><br><span class="line">    <span class="hljs-string">'俄方称已准备好重启俄乌和谈'</span>,</span><br><span class="line">    <span class="hljs-string">'《自然》：奥密克戎感染后嗅觉丧失症状比原来少了'</span></span><br><span class="line">]</span><br><span class="line">sentence_embeddings = model.encode(sentences)</span><br><span class="line"></span><br><span class="line">q1 = <span class="hljs-string">'码农的春天来了么'</span></span><br><span class="line">q2 = <span class="hljs-string">'国际局势'</span></span><br><span class="line">q3 = <span class="hljs-string">'健康'</span></span><br><span class="line">queries = [q1, q2, q3]</span><br><span class="line">query_embeddings = model.encode(queries)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">import</span> scipy</span><br><span class="line"></span><br><span class="line">number_top_matches = <span class="hljs-number">3</span></span><br><span class="line"><span class="hljs-keyword">for</span> query, query_embedding <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(queries, query_embeddings):</span><br><span class="line">    distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings, <span class="hljs-string">"cosine"</span>)[<span class="hljs-number">0</span>]</span><br><span class="line">    results = <span class="hljs-built_in">zip</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(distances)), distances)</span><br><span class="line">    results = <span class="hljs-built_in">sorted</span>(results, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"\nQuery:"</span>, query)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"\nTop {} most similar sentences in corpus:"</span>.<span class="hljs-built_in">format</span>(number_top_matches))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> idx, distance <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>:number_top_matches]:</span><br><span class="line">        <span class="hljs-built_in">print</span>(sentences[idx].strip(), <span class="hljs-string">"(Cosine Score: %.4f)"</span> % (<span class="hljs-number">1</span>-distance))</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2022/docker-flair-transformer-zero-shot/" itemprop="url">玩转transformer+flair zero shot 短文本分类：无需翻墙或额外下载模型和数据集的CPU docker镜像</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2022-06-09T18:45:01.000Z" itemprop="datePublished">6月 10 2022</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            8 分钟 读完 (约 1160 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>在这一期中，我们来体验两个知名的 NLP 预训练类库 flair 和 transformer
的 zero-shot 短文本分类。所谓zero-shot
的意思是完全不需要数据集来训练，直接掉包解决问题。和以往一样，本期的
docker 镜像已经预装了 flair，transformer，pytorch，jupyter
notebook等<strong>包依赖</strong>，并且还预先下载了 flair 和 transformer
的两个<strong>预训练模型</strong>和 <strong>yahoo
短文本主题数据集</strong>，整个 docker
镜像达到12GB，为了就是让大家无需翻墙下载额外数据或者模型，并且使用CPU就能体验最新的NLP
zero shot 文本分类。</p>
<h2 id="docker-镜像获取方式">Docker 镜像获取方式</h2>
<p>关注 <code>MyEncyclopedia</code> 公众号后回复
<code>docker-transformer-zero-shot</code>
即可获取镜像地址和启动命令。</p>
<h2 id="flair-zero-shot">Flair zero shot</h2>
<p>先来看一个 flair 短文本 zero shot 短文本分类的例子。下面的代码将句子
<strong>Spain beat Swiss for first Nations League win</strong> 归类到
<strong>politics</strong>,
<strong>sports</strong>，<strong>health</strong> 之一。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> flair.models <span class="hljs-keyword">import</span> TARSClassifier</span><br><span class="line"><span class="hljs-keyword">from</span> flair.data <span class="hljs-keyword">import</span> Sentence</span><br><span class="line"><span class="hljs-keyword">import</span> flair, torch</span><br><span class="line">flair.device = torch.device(<span class="hljs-string">'cpu'</span>)</span><br><span class="line"></span><br><span class="line">text = <span class="hljs-string">'Spain beat Swiss for first Nations League win'</span></span><br><span class="line">tars = TARSClassifier.load(<span class="hljs-string">'tars-base'</span>)</span><br><span class="line">sentence = Sentence(text)</span><br><span class="line">classes = [<span class="hljs-string">'politics'</span>, <span class="hljs-string">'sports'</span>, <span class="hljs-string">'health'</span>]</span><br><span class="line">tars.predict_zero_shot(sentence, classes)</span><br><span class="line"></span><br><span class="line"><span class="hljs-built_in">print</span>(sentence)</span><br><span class="line"><span class="hljs-built_in">print</span>(sentence.to_dict())</span><br></pre></td></tr></tbody></table></figure>
<p>最后两行输出如下，<code>all labels</code> 字段显示概率最高的是
<code>sports</code>类别，达到 0.99+。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Sentence: <span class="hljs-string">"Spain beat Swiss for first Nations League win"</span> → sports (0.9952)</span><br><span class="line">{</span><br><span class="line">  <span class="hljs-string">'text'</span>: <span class="hljs-string">'Spain beat Swiss for first Nations League win'</span>, </span><br><span class="line">  <span class="hljs-string">'all labels'</span>: [{<span class="hljs-string">'value'</span>: <span class="hljs-string">'sports'</span>, <span class="hljs-string">'confidence'</span>: 0.9952359795570374}]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">注意，在上面的代码中，`flair.device = torch.device(<span class="hljs-string">'cpu'</span>)` 强制使用了 cpu 资源，否则 flair 默认使用 gpu 会报错。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">## Transformer zero shot</span></span><br><span class="line">再来看看大名鼎鼎的 transformer zero shot 的结果。这里使用了默认的 transformer zero shot 分类的模型 Transformer Bart，小伙伴们可以使用其他模型，但是有些不兼容 zero shot 分类。代码如下</span><br><span class="line"></span><br><span class="line">​```python</span><br><span class="line">from transformers import pipeline</span><br><span class="line"></span><br><span class="line">text = <span class="hljs-string">'Spain beat Swiss for first Nations League win'</span></span><br><span class="line">classes = [<span class="hljs-string">'politics'</span>, <span class="hljs-string">'sports'</span>, <span class="hljs-string">'health'</span>]</span><br><span class="line">classifier = pipeline(<span class="hljs-string">"zero-shot-classification"</span>, device=-1)</span><br><span class="line">result = classifier(text, classes, multi_label=False)</span><br><span class="line"></span><br><span class="line"><span class="hljs-built_in">print</span>(result)</span><br><span class="line"><span class="hljs-built_in">print</span>(result[<span class="hljs-string">'labels'</span>][0])</span><br></pre></td></tr></tbody></table></figure>
<p>最后两行输出为</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">  <span class="hljs-string">'sequence'</span>: <span class="hljs-string">'Spain beat Swiss for first Nations League win'</span>, </span><br><span class="line">  <span class="hljs-string">'labels'</span>: [<span class="hljs-string">'sports'</span>, <span class="hljs-string">'health'</span>, <span class="hljs-string">'politics'</span>], </span><br><span class="line">  <span class="hljs-string">'scores'</span>: [0.9476209878921509, 0.03594793379306793, 0.016431059688329697]</span><br><span class="line">}</span><br><span class="line">sports</span><br></pre></td></tr></tbody></table></figure>
<p><code>result</code> 的
<code>labels</code>中会按照最大概率排序输出类别和对应的分数。对于这句句子，也分的相当准确，<code>sports</code>
为 0.94+。</p>
<p>也注意到 <code>pipeline("zero-shot-classification", device=-1)</code>
语句中 <strong>-1</strong> 表示强制使用 cpu。</p>
<h2 id="yahoo-短文本主题数据分类效果">Yahoo 短文本主题数据分类效果</h2>
<p>最后，来看一个真实数据集中这两者的实际效果，<code>yahoo_answers_topics</code>
是
<code>huggingface</code>的一个短文本分类数据集，可以通过以下命令下载并加载</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yahoo = load_dataset(<span class="hljs-string">'yahoo_answers_topics'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>它的具体类别为</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line"><span class="hljs-string">'Society &amp; Culture'</span>, </span><br><span class="line"><span class="hljs-string">'Science &amp; Mathematics'</span>, </span><br><span class="line"><span class="hljs-string">'Health'</span>, </span><br><span class="line"><span class="hljs-string">'Education &amp; Reference'</span>, </span><br><span class="line"><span class="hljs-string">'Computers &amp; Internet'</span>, </span><br><span class="line"><span class="hljs-string">'Sports'</span>, </span><br><span class="line"><span class="hljs-string">'Business &amp; Finance'</span>, </span><br><span class="line"><span class="hljs-string">'Entertainment &amp; Music'</span>, </span><br><span class="line"><span class="hljs-string">'Family &amp; Relationships'</span>, </span><br><span class="line"><span class="hljs-string">'Politics &amp; Government'</span></span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure>
<p>由于数量比较大，这里只取随机的1000个来测试，一些数据点如下</p>
<table>
<colgroup>
<col style="width: 74%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Text</th>
<th>Topic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A Permanent resident of Canada may stay out of Canada 3 years
without losing status.</td>
<td>Politics &amp; Government</td>
</tr>
<tr class="even">
<td>The official major league opening game occurred on April 10, 2006,
as the Cardinals defeated the Milwaukee Brewers 6-4. (Day Game)</td>
<td>Sports</td>
</tr>
<tr class="odd">
<td>Hold down the Command key while dragging and dropping files.</td>
<td>Computers &amp; Internet</td>
</tr>
</tbody>
</table>
<p>接着，对于每条短文本用 flair 和 transformer
来预测类别，最终统计准确率。</p>
<p>结果是 flair 准确率为 <strong>0.275</strong>，Transformer Bart 为
<strong>0.392</strong>，果然 transformer 显著胜出。其实，在
Yahoo数据集上取得 0.3 - 0.4
左右的效果已经不错了，毕竟有十个类别，全随机的准确率是
0.1。如果大家觉得这个效果一般的话，可以试试 tweet
情感分类数据集（具体在下面的链接中），Transformer 能达到惊人的
0.73。</p>
<p>下面附部分代码，完整代码可以从镜像中获得，或者感兴趣的小伙伴也可以访问</p>
<p>https://github.com/nlptown/nlp-notebooks/blob/master/Zero-Shot%20Text%20Classification.ipynb
获取所有五个数据集的代码，不过由于类库版本的关系，部分代码和模型或数据无法兼容，需要自行调试。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluate_flair</span>(<span class="hljs-params">dataset, default_name=<span class="hljs-string">'neutral'</span></span>):</span></span><br><span class="line">    classifier = TARSClassifier.load(<span class="hljs-string">'tars-base'</span>)</span><br><span class="line">    total, correct = <span class="hljs-number">0</span>, <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> item, gold_label_idx <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">zip</span>(dataset[<span class="hljs-string">"test_texts"</span>], dataset[<span class="hljs-string">"test_labels"</span>]),</span><br><span class="line">                                     total=<span class="hljs-built_in">len</span>(dataset[<span class="hljs-string">"test_texts"</span>])):</span><br><span class="line">        sentence = Sentence(item)</span><br><span class="line">        classifier.predict_zero_shot(sentence, dataset[<span class="hljs-string">"class_names"</span>])</span><br><span class="line">        sorted_labels = <span class="hljs-built_in">sorted</span>(sentence.to_dict()[<span class="hljs-string">'all labels'</span>], key=<span class="hljs-keyword">lambda</span> k: k[<span class="hljs-string">'confidence'</span>], reverse=<span class="hljs-literal">True</span>)</span><br><span class="line">        gold_label = dataset[<span class="hljs-string">"class_names"</span>][gold_label_idx]</span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(sorted_labels) &gt; <span class="hljs-number">0</span>:</span><br><span class="line">            predicted_label = sorted_labels[<span class="hljs-number">0</span>][<span class="hljs-string">'value'</span>]</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            predicted_label = default_name</span><br><span class="line">        <span class="hljs-keyword">if</span> predicted_label == gold_label:</span><br><span class="line">            correct += <span class="hljs-number">1</span></span><br><span class="line">        total += <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> correct / total</span><br><span class="line">    </span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluate_huggingface</span>(<span class="hljs-params">dataset</span>):</span></span><br><span class="line">    classifier = pipeline(<span class="hljs-string">"zero-shot-classification"</span>, device=-<span class="hljs-number">1</span>)</span><br><span class="line">    correct = <span class="hljs-number">0</span></span><br><span class="line">    predictions, gold_labels = [], []</span><br><span class="line">    <span class="hljs-keyword">for</span> text, gold_label_idx <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">zip</span>(dataset[<span class="hljs-string">"test_texts"</span>], dataset[<span class="hljs-string">"test_labels"</span>]),</span><br><span class="line">                                     total=<span class="hljs-built_in">len</span>(dataset[<span class="hljs-string">"test_texts"</span>])):</span><br><span class="line"></span><br><span class="line">        result = classifier(text, dataset[<span class="hljs-string">"class_names"</span>], multi_label=<span class="hljs-literal">False</span>)</span><br><span class="line">        predicted_label = result[<span class="hljs-string">'labels'</span>][<span class="hljs-number">0</span>]</span><br><span class="line"></span><br><span class="line">        gold_label = dataset[<span class="hljs-string">"class_names"</span>][gold_label_idx]</span><br><span class="line"></span><br><span class="line">        predictions.append(predicted_label)</span><br><span class="line">        gold_labels.append(gold_label)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">if</span> predicted_label == gold_label:</span><br><span class="line">            correct += <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line">    accuracy = correct / <span class="hljs-built_in">len</span>(predictions)</span><br><span class="line">    <span class="hljs-keyword">return</span> accuracy</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/docker-gym-nes/" itemprop="url">跨平台任天堂红白机强化学习预制环境</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-11-20T18:45:01.000Z" itemprop="datePublished">11月 21 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            6 分钟 读完 (约 966 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>今天和大家分享强化学习的经典训练环境，任天堂的红白机训练环境。</p>
<p><img src="/zh/2021/docker-gym-nes/gym-demo.gif"></p>
<p>这次的环境，我将分装成 docker 镜像，这样在任何平台：Windows，Linux
甚至 Mac 上都可以运行。</p>
<p>这里将通过大家最常用的 Windows 系统来演示环境的使用。</p>
<h2 id="x-window-服务器">X window 服务器</h2>
<p>在 Windows上，首先，我们要装 X Window Server。可以用 Cygwin 或者是
XLaunch。</p>
<p><img src="/zh/2021/docker-gym-nes/xlaunch.png"></p>
<p>这里采用 XLaunch 是因为安装比较方便，安装包也很小。</p>
<p>如果 XLaunch
正常启动的话，就会在系统托管的地方显示出来。接着我们来下载环境的 docker
images。</p>
<h2 id="拉取镜像">拉取镜像</h2>
<p>用 docker pull 命令我们将预制的公开镜像拉下来</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull myencyclopedia/gym-nes</span><br></pre></td></tr></tbody></table></figure>
<p>拉下来以后，可以用 docker image命令来检查是否存在</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></tbody></table></figure>
<p>下一步，我们需要找到物理机或者 docker host 机器的 IP 地址。</p>
<p>在windows上，我们执行 ipconfig 命令，注意我们要的是 WSL 对应的 IP
地址。</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ipconfig.exe</span><br><span class="line"></span><br><span class="line">Windows IP 配置</span><br><span class="line"></span><br><span class="line">以太网适配器 以太网:</span><br><span class="line">   媒体状态  . . . . . . . . . . . . : 媒体已断开连接</span><br><span class="line">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class="line">以太网适配器 vEthernet (WSL):</span><br><span class="line">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class="line">   本地链接 IPv6 地址. . . . . . . . : fe80::8841:6bd8:5064:9a3c%45</span><br><span class="line">   IPv4 地址 . . . . . . . . . . . . : 172.23.0.1</span><br><span class="line">   子网掩码  . . . . . . . . . . . . : 255.255.240.0</span><br><span class="line">   默认网关. . . . . . . . . . . . . :</span><br></pre></td></tr></tbody></table></figure>
<p>得到了物理机的 docker 网段地址以后，我们将地址保存在物理机的 Display
环境变量中，注意最后需要加上 <code>:0</code></p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-built_in">export</span> DISPLAY=172.23.0.1:0</span><br></pre></td></tr></tbody></table></figure>
<p>至此，我们可以一键跑超级玛丽了。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -e DISPLAY=<span class="hljs-variable">$DISPLAY</span> myencyclopedia/gym-nes bash -c <span class="hljs-string">'python gym_nes_demo.py'</span></span><br></pre></td></tr></tbody></table></figure>
<p>解释一点，<code>-e DISPLAY=$DISPLAY</code> 将 Display 环境变量从当前
shell 注入到 container 中。</p>
<p>一切顺利的话，有个 X
window的窗口会跳出来，无人控制得超级玛丽运行了起来，它会随机执行一些动作。</p>
<p>结束程序记得要把 docker container 显示关掉，需要执行 <code>docker
stop</code>。</p>
<h2 id="各种游戏">各种游戏</h2>
<p>其实，预制的 docker
环境给大家装了更多的游戏，大家也可以修改源码跑其他游戏</p>
<p>具体方法是，将上面命令稍微修改一下 次我们进入 interactive bash。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it  -e DISPLAY=<span class="hljs-variable">$DISPLAY</span> myencyclopedia/gym-nes bash</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2021/docker-gym-nes/docker-bash.gif"></p>
<p>进了 container 之后，我们发现之前执行的 python 原代码是当前目录的
<code>gym_nes_demo.py</code></p>
<p>先列出所有的游戏的 rom 文件。 </p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(py3.7) root@aff72945133b:/proj/nes_py# find . -name '*.nes'</span><br><span class="line">./tests/games/excitebike.nes</span><br><span class="line">./tests/games/super-mario-bros-2.nes</span><br><span class="line">./tests/games/super-mario-bros-3.nes</span><br><span class="line">./tests/games/empty.nes</span><br><span class="line">./tests/games/super-mario-bros-lost-levels.nes</span><br><span class="line">./tests/games/super-mario-bros-1.nes</span><br><span class="line">./tests/games/the-legend-of-zelda.nes</span><br><span class="line">./tests/nes-roms/1942 (Japan, USA).nes</span><br><span class="line">./tests/nes-roms/contra.nes</span><br><span class="line">./tests/nes-roms/Battle City (J).nes</span><br><span class="line">./tests/nes-roms/red.nes</span><br><span class="line">./tests/nes-roms/Gradius 2 (J).nes</span><br><span class="line">./tests/nes-roms/super-mario.nes</span><br><span class="line">./tests/nes-roms/Contra Force (USA).nes</span><br><span class="line">./tests/nes-roms/Rush'n Attack (U).nes</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>文件夹里有很多游戏， 包括魂斗罗，坦克大战等等。</p>
<p>修改 <code>gym_nes_demo.py</code>，将超级玛丽替换成魂斗罗 nes。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> nes_py <span class="hljs-keyword">import</span> NESEnv</span><br><span class="line"><span class="hljs-keyword">import</span> tqdm</span><br><span class="line">env = NESEnv(<span class="hljs-string">'/proj/nes_py/tests/games/super-mario-bros-1.nes'</span>)</span><br><span class="line"></span><br><span class="line">done = <span class="hljs-literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">try</span>:</span><br><span class="line">    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> tqdm.tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">5000</span>)):</span><br><span class="line">        <span class="hljs-keyword">if</span> done:</span><br><span class="line">            state = env.reset()</span><br><span class="line">            done = <span class="hljs-literal">False</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            state, reward, done, info = env.step(env.action_space.sample())</span><br><span class="line">            env.render()</span><br><span class="line"><span class="hljs-keyword">except</span> KeyboardInterrupt:</span><br><span class="line">    <span class="hljs-keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env = NESEnv('./tests/nes-roms/contra.nes')</span><br></pre></td></tr></tbody></table></figure>
<p>保存后，执行</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python gym_nes_demo.py</span><br></pre></td></tr></tbody></table></figure>
<p>魂斗罗的 random agent 也跑起来了。</p>
<p><img src="/zh/2021/docker-gym-nes/contra.png"></p>
<p>下一期，我会把一些很经典的深度强化学习的算法应用到这个环境中，让大家可以很方便得训练调试深度强化学习算法来挑战各种红白机游戏。</p>
<p>最后，感谢大家关注 MyEncyclopedia 公众号，B站频道或者 Youtube
频道。谢谢大家再见。</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 MyEncyclopedia&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true" aria-controls="dropdown-menu7">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>简体中文</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu">
            <div class="dropdown-content">
            
                <a href="/tags/docker/" class="dropdown-item">
                    简体中文
                </a>
            
                <a href="/en/tags/docker/" class="dropdown-item">
                    English
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("zh-CN");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<style>
 .katex-display {
    overflow-x: auto;
    overflow-y: hidden;
    height: 100%;
  }
</style>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="站内搜索" />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>