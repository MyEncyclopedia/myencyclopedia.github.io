<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>标签: Python - MyEncyclopedia</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">


<link href="/en/tags/Python/" rel="alternate" hreflang="en" />
    


<meta name="description" content="">





    <meta property="og:type" content="website">
<meta property="og:title" content="MyEncyclopedia">
<meta property="og:url" content="https://myencyclopedia.github.io/tags/Python/">
<meta property="og:site_name" content="MyEncyclopedia">
<meta property="og:locale">
<meta property="article:author" content="MyEncyclopedia">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="搜索" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://myencyclopedia.github.io">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#Python</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/course-pytorch-geometric/" itemprop="url">Pytorch Geometric (pyg) 系列教程</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-10-11T18:45:01.000Z" itemprop="datePublished">10月 12 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            1 分钟 读完 (约 147 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>请在桌面浏览器中打开此链接，保证最好的浏览体验</p>
<h2 id="关注公众号后回复-docker-geometric获取-docker-image">关注公众号后回复
<code>docker-geometric</code>，获取 Docker Image</h2>
<p><img src="https://myencyclopedia.top/en/img/me_gzh.jpg" width="120px"></p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 导入image</span></span><br><span class="line">docker load &lt; env-torch1.8-geometric.tar</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># 运行 jupyter notebook</span></span><br><span class="line">docker run  -p 8888:8888 -it env-torch1.8-geometric jupyter notebook --allow-root --ip <span class="hljs-string">'0.0.0.0'</span> --notebook-dir=/proj</span><br></pre></td></tr></tbody></table></figure>
<h2 id="在线代码">在线代码</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://mydoc.myencyclopedia.top/pub-html/01_plot_cora.html">01
Plot Cora</a></li>
<li><a target="_blank" rel="noopener" href="https://mydoc.myencyclopedia.top/pub-html/02_data_interface.html">02
Geometric Graph Data Representation</a></li>
<li><a target="_blank" rel="noopener" href="https://mydoc.myencyclopedia.top/pub-html/03_gcn.html">03
GCN</a></li>
</ul>
<h2 id="公众号系列视频链接"><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzkxNzM3Nw==&amp;action=getalbum&amp;album_id=2055350201493585920#wechat_redirect">公众号系列视频链接</a></h2>
<h2 id="b站视频系列链接"><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1f3411i7MQ">B站视频系列链接</a></h2>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/distribution-normal/" itemprop="url">从零构建统计随机变量生成器之正态分布 Box-Muller方法</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-07-09T18:45:01.000Z" itemprop="datePublished">7月 10 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            14 分钟 读完 (约 2106 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>在学习了一些基本的统计变量生成法之后，这次我们来看看如何生成正态分布。它就是大名鼎鼎的
Box-Muller 方法，Box-Muller
的理解过程可以体会到统计模拟的一些精妙思想。</p>
<ul>
<li><a href="/zh/2021/distribution-normal/zh/distribution-discrete-generator.md">从零构建统计随机变量生成器之
离散基础篇</a></li>
<li><a href="/zh/2021/distribution-normal/zh/distribution-inverse-transformation-method.md">从零构建统计随机变量生成器之
用逆变换采样方法构建随机变量生成器</a></li>
<li><a href="/zh/2021/distribution-normal/zh/leetcode-470-rand10.md">深入 LeetCode 470
拒绝采样，状态转移图求期望和一道经典统计求期望题目</a></li>
<li><strong><a href="/zh/2021/distribution-normal/zh/distribution-normal.md">从零构建统计随机变量生成器之 正态分布
Box-Muller方法</a></strong></li>
</ul>
<h2 id="尝试逆变换方法">尝试逆变换方法</h2>
<p>我们先尝试通过标准的逆变换方法来生成正态分布。</p>
<p>正态分布的 PDF 表达式为</p>
<div>
<p><span class="math display">\[
f_Z(z) = \frac{1}{\sqrt{2 \pi}} \exp\left\{-\frac{z^2}{2}\right\}
\]</span></p>
</div>
<p>对应的函数图形是钟形曲线</p>
<p><img src="/zh/2021/distribution-normal/normal-pdf.png"></p>
<p>根据 PDF，其 CDF 的积分形式为 <span class="math display">\[
\Phi(x)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x} e^{-t^{2} / 2} d t
\]</span></p>
<p>和所有 PDF CDF 关系一样，<span class="math inline">\(\Phi(x)\)</span>
表示 <span class="math inline">\(f_Z\)</span> 累积到 <span class="math inline">\(x\)</span> 点的面积。</p>
<p><img src="/zh/2021/distribution-normal/phi.png"></p>
<p>很不幸的是，<span class="math inline">\(\Phi(x)\)</span>
无法写出一般数学表达式，因而也无法直接用逆变换方法。</p>
<h2 id="二维映射到一维">二维映射到一维</h2>
<p>我们知道，高维正态分布有特殊的性质：它的每一维的分量都是正态分布；单个维度对于其他维度的条件概率分布也是正态分布。</p>
<p>用图来理解这两条性质就是，对于下图的二维正态分布 $ x = [x_1, x_2]^T
$，单独的 <span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(x_2\)</span> 都服从一维正态分布。</p>
<p>条件概率 <span class="math inline">\(p(x_2|x_1 \approx1)\)</span>
的PDF 对应图中的红线，显然也是一维正态分布。</p>
<p><img src="/zh/2021/distribution-normal/gaussian2d_slice.png"></p>
<p>写一段简单的代码验证二维正态分布的单个分量服从正态分布。</p>
<p>代码中，我们用<code>np.random.normal</code>生成了 10000
个服从二维正态分布的 x, y 点，然后我们丢弃 y，只保留 x，并画出 10000 个
x 的分布。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_normal_1d</span>():</span></span><br><span class="line">    x, _ = np.random.normal(loc=<span class="hljs-number">0</span>, scale=<span class="hljs-number">1</span>, size=(<span class="hljs-number">2</span>, <span class="hljs-number">10000</span>))</span><br><span class="line">    <span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns</span><br><span class="line">    sns.distplot(x, hist=<span class="hljs-literal">True</span>, kde=<span class="hljs-literal">True</span>, bins=<span class="hljs-number">100</span>, color=<span class="hljs-string">'darkblue'</span>,</span><br><span class="line">                 hist_kws={<span class="hljs-string">'edgecolor'</span>: <span class="hljs-string">'black'</span>},</span><br><span class="line">                 kde_kws={<span class="hljs-string">'linewidth'</span>: <span class="hljs-number">4</span>})</span><br><span class="line">    plt.title(<span class="hljs-string">'PDF Normal 1D from 2D'</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/zh/2021/distribution-normal/2d_to_1d.png"></p>
<h2 id="box-muller-原理">Box-Muller 原理</h2>
<p>虽然无法直接用逆变换方法生成一维正态分布，但我们却能通过先生成二维的正态分布，利用上面一节的性质，生成一维正态分布。</p>
<p><strong>而 Box-Muller
就是巧妙生成二维正态分布样本点的方法。</strong></p>
<p>首先，我们来看看二维正态分布可以认为是两个维度是独立的，每个维度都是正态分布。此时，其
PDF 可以写成两个一维正态分布 PDF 的乘积。</p>
<p><img src="/zh/2021/distribution-normal/normal_x_y.png"></p>
<p>这种写法表明，二维正态分布仅用一个 <strong>r
向量</strong>就可以充分表达。注意，r
是向量，不仅有大小还有角度，有两个分量。这两个分量本质上是独立的，这就是
Box-Muller 方法的巧妙之处。也就是，<strong>Box-Muller
通过角度和半径大小两个分量的独立性分别单独生成并转换成 (x, y)
对。</strong></p>
<p>角度分量是在 <span class="math inline">\(2\pi\)</span>
范围均匀采样，这一点比较直觉好理解。</p>
<p>再来看看半径分量 r。我们令 <span class="math display">\[
s = {r^2 \over 2} \Longrightarrow r = \sqrt{2s}
\]</span></p>
<p>则 s 服从指数分布 <span class="math inline">\(\lambda=1\)</span>
。</p>
<p>不信么？我们不妨来做个模拟实验，下图是模拟 10000次二维正态分布 (x, y)
点后转换成 s 的分布。</p>
<p><img src="/zh/2021/distribution-normal/s_exp.png"></p>
<p>模拟和plot 代码如下</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_r_squared</span>():</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_normal_samples</span>(<span class="hljs-params">n</span>):</span></span><br><span class="line">        x, y = np.random.normal(loc=<span class="hljs-number">0</span>, scale=<span class="hljs-number">1</span>, size=(<span class="hljs-number">2</span>, n))</span><br><span class="line">        <span class="hljs-keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line">    x, y = gen_normal_samples(<span class="hljs-number">10000</span>)</span><br><span class="line">    s = (x * x + y * y)/<span class="hljs-number">2</span></span><br><span class="line">    plot_dist_1d(s, title=<span class="hljs-string">'PDF $s = {{x^2 + y^2}\over{2}} \sim exp(1)$'</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_dist_1d</span>(<span class="hljs-params">X, title=<span class="hljs-string">'PDF '</span></span>):</span></span><br><span class="line">    <span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns</span><br><span class="line">    plt.rcParams.update({</span><br><span class="line">        <span class="hljs-string">"text.usetex"</span>: <span class="hljs-literal">True</span>,</span><br><span class="line">        <span class="hljs-string">"font.family"</span>: <span class="hljs-string">"sans-serif"</span>,</span><br><span class="line">        <span class="hljs-string">"font.sans-serif"</span>: [<span class="hljs-string">"Helvetica"</span>]})</span><br><span class="line">    sns.distplot(X, hist=<span class="hljs-literal">True</span>, kde=<span class="hljs-literal">True</span>, bins=<span class="hljs-number">100</span>, color=<span class="hljs-string">'darkblue'</span>,</span><br><span class="line">                 hist_kws={<span class="hljs-string">'edgecolor'</span>: <span class="hljs-string">'black'</span>},</span><br><span class="line">                 kde_kws={<span class="hljs-string">'linewidth'</span>: <span class="hljs-number">4</span>})</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.show()    </span><br></pre></td></tr></tbody></table></figure>
<p>确信了 s 符合指数分布，根据指数分布的 PDF，可以推出二维正态 PDF中的 $
e<sup>{-r</sup>2/2}$ 也符合指数分布，即 <span class="math display">\[
s \sim \exp(1) \Longrightarrow e^{-r^2/2} \sim \exp(1)
\]</span></p>
<p>至此，总结一下Box-Muller方法。我们视二维正态分布PDF为独立两部分的乘积，第一部分是在
<span class="math inline">\(2\pi\)</span>
范围中的均匀分布，代表了二维平面中的角度 <span class="math inline">\(\theta\)</span>，第二部分为 <span class="math inline">\(\lambda=1\)</span> 的指数分布，代表半径大小。</p>
<p><img src="/zh/2021/distribution-normal/normal_decompose.png"></p>
<p>Box-Muller 方法通过两个服从 [0, 1] 均匀分布的样本
u1和u2，转换成独立的角度和半径样本，具体过程如下</p>
<ol type="1">
<li><p>生成 [0, 1] 的均匀分布 u1，利用逆变换采样方法转换成 exp(1)
样本，此为二维平面点半径 r</p></li>
<li><p>生成 [0, 1] 的均匀分布 u2，乘以 <span class="math inline">\(2\pi\)</span>，即为样本点的角度 <span class="math inline">\(\theta\)</span></p></li>
<li><p>将 r 和 <span class="math inline">\(\theta\)</span> 转换成 x, y
坐标下的点。</p></li>
</ol>
<p>理解了整个过程的意义，下面的代码就很直白。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normal_box_muller</span>():</span></span><br><span class="line">    <span class="hljs-keyword">import</span> random</span><br><span class="line">    <span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt, log, pi, cos, sin</span><br><span class="line">    u1 = random.random()</span><br><span class="line">    u2 = random.random()</span><br><span class="line">    r = sqrt(-<span class="hljs-number">2</span> * log(u1))</span><br><span class="line">    theta = <span class="hljs-number">2</span> * pi * u2</span><br><span class="line">    z0 = r * cos(theta)</span><br><span class="line">    z1 = r * sin(theta)</span><br><span class="line">    <span class="hljs-keyword">return</span> z0, z1</span><br></pre></td></tr></tbody></table></figure>
<p>接下来，我们来看看 Box-Muller 法生成的二维标准正态分布动画吧</p>
<p><img src="/zh/2021/distribution-normal/gaussian2d_anim.gif"></p>
<h2 id="拒绝采样极坐标方法">拒绝采样极坐标方法</h2>
<p>Box-Muller 方法还有一种形式，称为极坐标形式，属于拒绝采样方法。</p>
<h3 id="生成独立的-u-v-和-s">1. 生成独立的 u, v 和 s</h3>
<p>分别生成 [0, 1] 均匀分布 u 和 v。令 <span class="math inline">\(s =
r^2 = u^2 + v^2\)</span>。如果 s = 0或 s ≥ 1，则丢弃 u 和 v
，并尝试另一对 (u , v)。因为 u 和 v
是均匀分布的，并且因为只允许单位圆内的点，所以 s
的值也将均匀分布在开区间 (0, 1) 中。<strong>注意，这里的 s
的意义虽然也为半径，但不同于基本方法中的 s。</strong>这里 s 取值范围为
(0, 1) ，目的是通过 s 生成指数分布，而基本方法中的 s 取值范围为 [0,
+∞]，表示二维正态分布 PDF 采样点的半径。复用符号 s
的原因是为了对应维基百科中关于基本方法和极坐标方法的数学描述。</p>
<p>我们用代码来验证 s 服从 (0, 1) 范围上的均匀分布。 </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_polar_s</span>():</span></span><br><span class="line">    <span class="hljs-keyword">import</span> random</span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">        u = random.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        v = random.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        s = u * u + v * v</span><br><span class="line">        <span class="hljs-keyword">if</span> s &gt;= <span class="hljs-number">1.0</span> <span class="hljs-keyword">or</span> s == <span class="hljs-number">0.0</span>:</span><br><span class="line">            <span class="hljs-keyword">continue</span></span><br><span class="line">        <span class="hljs-keyword">return</span> s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_polar_s</span>():</span></span><br><span class="line">    s = [gen_polar_s() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>) ]</span><br><span class="line">    plot_dist_1d(s, title=<span class="hljs-string">'PDF Polar $s = u^2 + v^2$'</span>)</span><br></pre></td></tr></tbody></table></figure> <img src="/zh/2021/distribution-normal/pdf_polar_s.png"><p></p>
<h3 id="将-u-v-s-转换成-x-y">2. 将 u, v, s 转换成 x, y</h3>
<p>若将 $s = R^2 uniform(0, 1) $ 看成是基本方法中的
u1，就可以用同样的方式转换成指数分布，用以代表二维PDF的半径。</p>
<p>同时，根据下图，<span class="math inline">\(\cos \theta\)</span> 和
<span class="math inline">\(\sin \theta\)</span> 可以直接用 u, v, R
表示出来，并不需要通过三角函数显示计算出 <span class="math inline">\(\theta\)</span>。有了半径， <span class="math inline">\(\cos \theta\)</span> 和 <span class="math inline">\(\sin \theta\)</span> ，则可以直接计算出 x, y
坐标，（下面用 <span class="math inline">\(z_0, z_1\)</span> 代替 <span class="math inline">\(x, y\)</span>）。</p>
<p><img src="/zh/2021/distribution-normal/BoxMullerTransformPolar.png"></p>
<p><span class="math display">\[
z_{0}=\sqrt{-2 \ln U_{1}} \cos \left(2 \pi U_{2}\right)=\sqrt{-2 \ln
s}\left(\frac{u}{\sqrt{s}}\right)=u \cdot \sqrt{\frac{-2 \ln s}{s}}
\]</span></p>
<p><span class="math display">\[
z_{1}=\sqrt{-2 \ln U_{1}} \sin \left(2 \pi U_{2}\right)=\sqrt{-2 \ln
s}\left(\frac{v}{\sqrt{s}}\right)=v \cdot \sqrt{\frac{-2 \ln s}{s}}
\]</span></p>
<p>同样，Box-Muller 极坐标方法的代码和公式一致。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normal_box_muller_polar</span>():</span></span><br><span class="line">    <span class="hljs-keyword">import</span> random</span><br><span class="line">    <span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt, log</span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">        u = random.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        v = random.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span><br><span class="line">        s = u * u + v * v</span><br><span class="line">        <span class="hljs-keyword">if</span> s &gt;= <span class="hljs-number">1.0</span> <span class="hljs-keyword">or</span> s == <span class="hljs-number">0.0</span>:</span><br><span class="line">            <span class="hljs-keyword">continue</span></span><br><span class="line">        z0 = u * sqrt(-<span class="hljs-number">2</span> * log(s) / s)</span><br><span class="line">        z1 = v * sqrt(-<span class="hljs-number">2</span> * log(s) / s)</span><br><span class="line">        <span class="hljs-keyword">return</span> z0, z1</span><br></pre></td></tr></tbody></table></figure>
<h3 id="拒绝采样的效率">拒绝采样的效率</h3>
<p>极坐标方法与基本方法的不同之处在于它是一种拒绝采样。因此，它会丢弃一些生成的随机数，但可能比基本方法更快，因为它计算更简单：<strong>避免使用昂贵的三角函数</strong>，并且在数值上更稳健。极坐标方法丢弃了生成总输入对的
1 − <em>π</em> /4 ≈ 21.46%，即需要 4/ <em>π</em> ≈ 1.2732
个输入随机数，输出一个随机采样。</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/leetcode-470-rand10/" itemprop="url">深入 LeetCode 470 拒绝采样，状态转移图求期望和一道经典统计求期望题目</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-05-28T18:45:01.000Z" itemprop="datePublished">5月 29 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            16 分钟 读完 (约 2430 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>在这篇文章中，我们从一道LeetCode 470
题目出发，通过系统地思考，引出拒绝采样（Reject
Sampling）的概念，并探索比较三种拒绝采样地解法；接着借助状态转移图来定量计算采样效率；最后，我们利用同样的方法来解一道稍微复杂些的经典抛硬币求期望的统计面试题目。</p>
<h2 id="leetcode-470-用-rand7-实现-rand10">Leetcode 470 用 Rand7() 实现
Rand10()</h2>
<p>已有方法 rand7 可生成 1 到 7 范围内的均匀随机整数，试写一个方法
rand10 生成 1 到 10 范围内的均匀随机整数。</p>
<p>不要使用系统的 Math.random() 方法。</p>
<p><strong>思考</strong></p>
<ul>
<li><p>rand7()调用次数的 期望值 是多少 ?</p></li>
<li><p>你能否尽量少调用 rand7() ?</p></li>
</ul>
<h2 id="思维过程">思维过程</h2>
<p>我们已有 rand7() 等概率生成了 [1, 7] 中的数字，我们需要等概率生成 [1,
10] 范围内的数字。第一反应是调用一次rand7()
肯定是不够的，因为覆盖的范围不够。那么，就需要至少2次调用 rand7()
才能生成一次 rand10()，但是还要保证 [1, 10]
的数字生成概率相等，这个是难点。 现在我们先来考虑反问题，给定rand10()
生成 rand7()。这个应该很简单，调用一次 rand10() 得到 [1, 10]，如果是 8,
9, 10
，则丢弃，重新开始，否则返回。想必大家都能想到这个朴素的方法，这种思想就是统计模拟中的拒绝采样（Reject
Sampling）。</p>
<p>有了上面反问题的思考，我们可能会想到，rand7() 可以生成 rand5()，覆盖
[1, 5]的范围，如果将区间 [1, 10] 分成两个5个值的区间 [1, 5] 和 [6,
10]，那么 rand7() 可以通过先等概率选择区间 [1, 5] 或 [6,
10]，再通过rand7() 生成 rand5()就可以了。这个问题就<strong>等价于先用
rand7() 生成 rand2()，决定了 [1, 5] 还是 [6, 10]，再通过rand7() 生成
rand5() 。</strong></p>
<h2 id="解法一rand2-rand5">解法一：rand2() + rand5()</h2>
<p>我们来实现这种解法。下图为调用两次 rand7() 生成 rand10
数值的映射关系：横轴表示第一次调用，1，2，3决定选择区间 [1, 5]
，4，5，6选择区间 [6, 10]。灰色部分表示结果丢弃，重新开始
（注，若第一次得到7无需再次调用 rand7()）。</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/space_slow.png">
<figcaption>
</figcaption>
</figure>
<p>有了上图，我们很容易写出如下 AC 代码。 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 408 ms, faster than 23.80% of Python3 online submissions for Implement Rand10() Using Rand7().</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 16.7 MB, less than 90.76% of Python3 online submissions for Implement Rand10() Using Rand7().</span></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rand10</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">            a = rand7()</span><br><span class="line">            <span class="hljs-keyword">if</span> a &lt;= <span class="hljs-number">3</span>:</span><br><span class="line">                b = rand7()</span><br><span class="line">                <span class="hljs-keyword">if</span> b &lt;= <span class="hljs-number">5</span>:</span><br><span class="line">                    <span class="hljs-keyword">return</span> b</span><br><span class="line">            <span class="hljs-keyword">elif</span> a &lt;= <span class="hljs-number">6</span>:</span><br><span class="line">                b = rand7()</span><br><span class="line">                <span class="hljs-keyword">if</span> b &lt;= <span class="hljs-number">5</span>:</span><br><span class="line">                    <span class="hljs-keyword">return</span> b + <span class="hljs-number">5</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="标准解法rand49">标准解法：rand49()</h2>
<p>从提交的结果来看，第一种解法慢于多数解法。原因是我们的调用 rand7()
的采样效率比较低，第一次有 1/7 的概率结果丢弃，第二次有
2/7的概率被丢弃。</p>
<p>如何在第一种解法的基础上提高采样效率呢？直觉告诉我们一种做法是降低上述
7x7 表格中灰色格子的面积。此时，会想到我们<strong>通过两次 rand7()
已经构建出来 rand49()</strong>了，那么再生成 rand10()
也规约成基本问题了。</p>
<p>下图为 rand49() 和 rand10() 的数字对应关系。</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/space_std.png">
<figcaption>
</figcaption>
</figure>
<p>实现代码比较简单。注意，while True 可以去掉，用递归来代替。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 376 ms, faster than 54.71% of Python3 online submissions for Implement Rand10() Using Rand7().</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 16.9 MB, less than 38.54% of Python3 online submissions for Implement Rand10() Using Rand7().</span></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rand10</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">            a, b = rand7(),  rand7()</span><br><span class="line">            num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b</span><br><span class="line">            <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">40</span>:</span><br><span class="line">                <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="更快的做法">更快的做法</h2>
<p>上面的提交结果发现标准解法在运行时间上有了不少提高，处于中等位置。我们继续思考，看看能否再提高采样效率。</p>
<p>观察发现，rand49() 有 9/49 的概率，生成的值被丢弃，原因是 [41, 49]
只有 9
个数，不足10个。倘若此时能够将这种状态保持下去，那么只需再调用一次
rand7() 而不是从新开始情况下至少调用两次 rand7()， 就可以得到
rand10()了。也就是说，当 rand49() 生成了 [41, 49]
范围内的数的话等价于我们先调用了一次
rand9()，那么依样画葫芦，我们接着调用 rand7() 得到了 rand63()。63
分成了6个10个值的区间后，剩余 3 个数。此时，又等价于
rand3()，循环往复，调用了 rand7() 得到了 rand21()，最后若rand21()
不幸得到21，等价于
rand1()，此时似乎我们走投无路，只能回到最初的状态，一切从头再来了。</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/space_fast.png">
<figcaption>
</figcaption>
</figure>
<p>改进算法代码如下。注意这次击败了 92.7%的提交。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 344 ms, faster than 92.72% of Python3 online submissions for Implement Rand10() Using Rand7().</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 16.7 MB, less than 90.76% of Python3 online submissions for Implement Rand10() Using Rand7().</span></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rand10</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">            a, b = rand7(),  rand7()</span><br><span class="line">            num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b</span><br><span class="line">            <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">40</span>: <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br><span class="line">            a = num - <span class="hljs-number">40</span></span><br><span class="line">            b = rand7()</span><br><span class="line">            num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b</span><br><span class="line">            <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">60</span>: <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br><span class="line">            a = num - <span class="hljs-number">60</span></span><br><span class="line">            b = rand7()</span><br><span class="line">            num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b</span><br><span class="line">            <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">20</span>: <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="采样效率计算">采样效率计算</h2>
<p>通过代码提交的结果和大致的分析，我们已经知道三个解法在采样效率依次变得更快。现在我们来定量计算这三个解法。</p>
<p>我们考虑生成一个 rand10() 平均需要调用多少次
rand7()，作为采样效率的标准。</p>
<p>一种思路是可以通过模拟方法，即将上述每个解法模拟多次，然后用总的
rand7() 调用次数除以 rand10()
的生成次数即可。下面以解法三为例写出代码</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># The rand7() API is already defined for you.</span></span><br><span class="line">rand7_c = <span class="hljs-number">0</span></span><br><span class="line">rand10_c = <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rand7</span>():</span></span><br><span class="line">    <span class="hljs-keyword">global</span> rand7_c</span><br><span class="line">    rand7_c += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">import</span> random</span><br><span class="line">    <span class="hljs-keyword">return</span> random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">7</span>)</span><br><span class="line">    </span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rand10</span>():</span></span><br><span class="line">    <span class="hljs-keyword">global</span> rand10_c</span><br><span class="line">    rand10_c += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">        a, b = rand7(), rand7()</span><br><span class="line">        num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b</span><br><span class="line">        <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">40</span>: <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br><span class="line">        a = num - <span class="hljs-number">40</span>   <span class="hljs-comment"># [1, 9]</span></span><br><span class="line">        b = rand7()</span><br><span class="line">        num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b  <span class="hljs-comment"># [1, 63]</span></span><br><span class="line">        <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">60</span>: <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br><span class="line">        a = num - <span class="hljs-number">60</span>  <span class="hljs-comment"># [1, 3]</span></span><br><span class="line">        b = rand7()</span><br><span class="line">        num = (a - <span class="hljs-number">1</span>) * <span class="hljs-number">7</span> + b  <span class="hljs-comment"># [1, 21]</span></span><br><span class="line">        <span class="hljs-keyword">if</span> num &lt;= <span class="hljs-number">20</span>: <span class="hljs-keyword">return</span> num % <span class="hljs-number">10</span> + <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:</span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">        rand10()</span><br><span class="line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'<span class="hljs-subst">{rand10_c}</span> <span class="hljs-subst">{<span class="hljs-built_in">round</span>(rand7_c/rand10_c, <span class="hljs-number">2</span>)}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>运行代码，发现解法三的采样效率稳定在 2.19。</p>
<h2 id="采样效率精确计算">采样效率精确计算</h2>
<h3 id="计算解法二">计算解法二</h3>
<p>为了精确计算三个解法的采样效率，我们通过代码得到对应的状态转移图来帮助计算。</p>
<p>例如，解法一可以对应到下图：初始状态 Start 节点中的 +2
表示经过此节点会产生 2次 rand7() 的代价。从 Start 节点有 40/49
的概率到达被接受状态 AC，有 9/49 概率到达拒绝状态 REJ。REJ
需要从头开始，则用虚线表示重新回到 Start节点，<strong>也就是说 REJ
的代价等价于 Start</strong>。注意，从某个节点出发的所有边之和为1。</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/graph_std.png">
<figcaption>
</figcaption>
</figure>
<p>有了上述状态转移关系图，我们令初始状态的平均代价为 <span class="math inline">\(C_2\)</span>，则可以写成递归表达式，因为其中 REJ
的代价就是 <span class="math inline">\(C_2\)</span>，即</p>
<p><span class="math display">\[
C_2 = 2 + (\frac{40}{49}\cdot0 + \frac{9}{49} C_2)
\]</span></p>
<p>解得 <span class="math inline">\(C_2\)</span></p>
<p><span class="math display">\[
C_2 = 2.45
\]</span></p>
<h3 id="计算解法一">计算解法一</h3>
<p>同样的，对于另外两种解法，虽然略微复杂，也可以用同样的方法求得。</p>
<p>解法一的状态转移图为</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/graph_slow.png">
<figcaption>
</figcaption>
</figure>
<p>递归方程表达式为</p>
<p><span class="math display">\[
C_1 = 1+\frac{3}{7} \cdot (1+\frac{5}{7} \cdot 0 + \frac{2}{7} \cdot
C_1) \cdot2+ \frac{1}{7} \cdot (C_1)
\]</span></p>
<p>解得 <span class="math inline">\(C_1\)</span></p>
<p><span class="math display">\[
C_1 = \frac{91}{30} \approx 3.03
\]</span></p>
<h3 id="计算解法三">计算解法三</h3>
<p>最快的解法三状态转移图为</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/graph_fast.png">
<figcaption>
</figcaption>
</figure>
<p>递归方程表达式为</p>
<p><span class="math display">\[
C_3 = 2+\frac{40}{49} \cdot 0 + \frac{9}{49} (1+\frac{60}{63} \cdot 0 +
\frac{3}{63} \cdot (1+\frac{20}{21} \cdot 0 + \frac{1}{21} \cdot C_3))
\]</span></p>
<p>解得 <span class="math inline">\(C_3\)</span> <span class="math display">\[
C_3 = \frac{329}{150} \approx 2.193
\]</span></p>
<p>至此总结一下，三个解法的平均代价为 <span class="math display">\[
C_1 \approx 3.03 &gt; C_2 = 2.45 &gt; C_3 \approx 2.193
\]</span> 这些值和我们通过模拟得到的结果一致。</p>
<h2 id="稍难些的经典概率求期望题目">稍难些的经典概率求期望题目</h2>
<p>至此，LeetCode 470
我们已经分析透彻。现在，我们已经可以很熟练的将此类拒绝采样的问题转变成有概率的状态转移图，再写成递推公式去求平均采样的代价（即期望）。这里，如果大家感兴趣的话不妨再来看一道略微深入的经典统计概率求期望的题目。</p>
<p>问题：给定一枚抛正反面概率一样的硬币，求连续抛硬币直到两个正面（正面记为H，两个正面HH）的平均次数。例如：HTTHH是一个连续次数为5的第一次出现HH的序列。</p>
<p>分析问题画出状态转移图：我们令初始状态下得到第一个HH的平均长度记为
S，那么下一次抛硬币有 1/2 机会是 T，此时状态等价于初始状态，另有 1/2
机会是 H，我们记这个状态下第一次遇见HH的平均长度为
H（下图蓝色节点）。从此蓝色节点出发，当下一枚硬币是H则结束，是T是返回初始状态。于是构建出下图。</p>
<figure>
<img src="/zh/2021/leetcode-470-rand10/graph_hh.png">
<figcaption>
</figcaption>
</figure>
<p>这个问题稍微复杂的地方在于我们有两个未知状态互相依赖，但问题的本质和方法是一样的，分别从
S 和 H 出发考虑状态的概率转移，可以写成如下两个方程式：</p>
<div>
<p><span class="math display">\[
\left\{
\begin{array}{c}
S =&amp;\frac{1}{2} \cdot(1+H) + \frac{1}{2} \cdot(1+S) \\
H =&amp;\frac{1}{2} \cdot 1 + \frac{1}{2} \cdot(1+S)
\end{array}
\right.
\]</span></p>
</div>
<p>解得</p>
<div>
<p><span class="math display">\[
\left\{
\begin{array}{c}
H= 4 \\
S = 6
\end{array}
\right.
\]</span></p>
</div>
<p>因此，平均下来，需要6次抛硬币才能得到
HH，这个是否和你直觉的猜测一致呢？</p>
<p>这个问题还可以有另外一问，可以作为思考题让大家来练习一下：第一次得到
HT 的平均次数是多少？这个是否和 HH 一样呢？</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/rl-ppo-1984/" itemprop="url">深度强化学习之：PPO训练红白机1942</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-05-08T18:45:01.000Z" itemprop="datePublished">5月 9 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            19 分钟 读完 (约 2804 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>本篇是深度强化学习动手系列文章，自MyEncyclopedia公众号文章<a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457480980&amp;idx=1&amp;sn=ef919157726080caf9eebb3aaa8314f9&amp;chksm=87bc993ab0cb102c399687912b65d6a38994f2cb9ac87b531bf0ca2eaf119b8db0ea84e45916&amp;scene=21#wechat_redirect">深度强化学习之：DQN训练超级玛丽闯关</a>发布后收到不少关注和反馈，这一期，让我们实现目前主流深度强化学习算法PPO来打另一个红白机经典游戏1942。</p>
<p>相关文章链接如下：</p>
<p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457481574&amp;idx=1&amp;sn=712e92f15d5488dcb73470c9a6420a04&amp;chksm=87bc8748b0cb0e5eb839afe27712dd990ad3d4a2083b923593a499f8a1c4ada37e6dfa1db7e0&amp;scene=21#wechat_redirect">强化学习开源环境集</a></p>
<p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457481652&amp;idx=1&amp;sn=ddc083c1a7ce4930b4302384c507cbd5&amp;chksm=87bc879ab0cb0e8c6e68d5f7f5638e09b7167576edc7c8ed075531ec221630356eea7ff4ad56&amp;scene=21#wechat_redirect">视频论文解读：PPO算法</a></p>
<p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457481622&amp;idx=1&amp;sn=dbdce93433de31c68e99da08afb8699c&amp;chksm=87bc87b8b0cb0eaed487d3c553ad565513b07c887692bce33d83b1424926cd367d5d5f75ea5f&amp;scene=21#wechat_redirect">视频论文解读：组合优化的强化学习方法</a></p>
<p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457481507&amp;idx=1&amp;sn=0ae5e2c434973d35d45f3b794ffe52e3&amp;chksm=87bc870db0cb0e1ba11aa778283faee8fbba750e6208d56d663b689ee7ccdb31cb036365a41e&amp;scene=21#wechat_redirect">解读TRPO论文，深度强化学习结合传统优化方法</a></p>
<p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457481304&amp;idx=1&amp;sn=35eb9c72f2ed4feaff57db64e3dd0932&amp;chksm=87bc8676b0cb0f6013a71f5e16229e48e63a9fc30bd8695a761904a915f9482a224cb6e19217&amp;scene=21#wechat_redirect">解读深度强化学习基石论文：函数近似的策略梯度方法</a></p>
<h2 id="nes-1942-环境安装">NES 1942 环境安装</h2>
<p>红白机游戏环境可以由OpenAI Retro来模拟，OpenAI Retro还在 Gym
集成了其他的经典游戏环境，包括Atari 2600，GBA，SNES等。</p>
<p>不过，受到版权原因，除了一些基本的rom，大部分游戏需要自行获取rom。</p>
<p>环境准备部分相关代码如下</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gym-retro</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m retro.import /path/to/your/ROMs/directory/</span><br></pre></td></tr></tbody></table></figure>
<h2 id="openai-gym-输入动作类型">OpenAI Gym 输入动作类型</h2>
<p>在创建 retro
环境时，可以在retro.make中通过参数use_restricted_actions指定 action
space，即按键的配置。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env = retro.make(game=<span class="hljs-string">'1942-Nes'</span>, use_restricted_actions=retro.Actions.FILTERED)</span><br></pre></td></tr></tbody></table></figure>
<p>可选参数如下，FILTERED，DISCRETE和MULTI_DISCRETE
都可以指定过滤的动作，过滤动作需要通过配置文件加载。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Actions</span>(<span class="hljs-params">Enum</span>):</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Different settings for the action space of the environment</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    ALL = <span class="hljs-number">0</span>  <span class="hljs-comment">#: MultiBinary action space with no filtered actions</span></span><br><span class="line">    FILTERED = <span class="hljs-number">1</span>  <span class="hljs-comment">#: MultiBinary action space with invalid or not allowed actions filtered out</span></span><br><span class="line">    DISCRETE = <span class="hljs-number">2</span>  <span class="hljs-comment">#: Discrete action space for filtered actions</span></span><br><span class="line">    MULTI_DISCRETE = <span class="hljs-number">3</span>  <span class="hljs-comment">#: MultiDiscete action space for filtered actions</span></span><br></pre></td></tr></tbody></table></figure>
<p>DISCRETE和MULTI_DISCRETE 是 Gym 里的
Action概念，它们的基类都是gym.spaces.Space，可以通过
sample()方法采样，下面具体一一介绍。</p>
<ul>
<li>Discrete：对应一维离散空间，例如，Discrete(n=4) 表示 [0, 3]
范围的整数。</li>
</ul>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.spaces <span class="hljs-keyword">import</span> Discrete</span><br><span class="line">space = Discrete(<span class="hljs-number">4</span>)</span><br><span class="line"><span class="hljs-built_in">print</span>(space.sample())</span><br></pre></td></tr></tbody></table></figure>
<p>输出是</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>Box：对应多维连续空间，每一维的范围可以用 [low，high] 指定。
举例，Box(low=-1.0, high=2, shape=(3, 4,), dtype=np.float32) 表示 shape
是 [3, 4]，每个范围在 [-1, 2] 的float32型 tensor。</li>
</ul>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.spaces <span class="hljs-keyword">import</span> Box</span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">space = Box(low=-<span class="hljs-number">1.0</span>, high=<span class="hljs-number">2.0</span>, shape=(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>), dtype=np.float32)</span><br><span class="line"><span class="hljs-built_in">print</span>(space.sample())</span><br></pre></td></tr></tbody></table></figure>
<p>输出是 </p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[-0.7538084   0.96901214  0.38641307 -0.05045208]</span><br><span class="line"> [-0.85486996  1.3516271   0.3222616   1.2540635 ]</span><br><span class="line"> [-0.29908678 -0.8970335   1.4869047   0.7007356 ]]</span><br></pre></td></tr></tbody></table></figure><p></p>
<ul>
<li>MultiBinary: 0或1的多维离散空间。例如，MultiBinary([3,2]) 表示 shape
是3x2的0或1的tensor。 <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.spaces <span class="hljs-keyword">import</span> MultiBinary</span><br><span class="line">space = MultiBinary([<span class="hljs-number">3</span>,<span class="hljs-number">2</span>])</span><br><span class="line"><span class="hljs-built_in">print</span>(space.sample())</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<p>输出是</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1 0]</span><br><span class="line"> [1 1]</span><br><span class="line"> [0 0]]</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>MultiDiscrete：多维整型离散空间。例如，MultiDiscrete([5,2,2])
表示三维Discrete空间，第一维范围在 [0-4]，第二，三维范围在[0-1]。</li>
</ul>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.spaces <span class="hljs-keyword">import</span> MultiDiscrete</span><br><span class="line">space = MultiDiscrete([<span class="hljs-number">5</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>])</span><br><span class="line"><span class="hljs-built_in">print</span>(space.sample())</span><br></pre></td></tr></tbody></table></figure>
<p>输出是</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[2 1 0]</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>Tuple：组合成 tuple 复合空间。举例来说，可以将
Box，Discrete，Discrete组成tuple 空间：Tuple(spaces=(Box(low=-1.0,
high=1.0, shape=(3,), dtype=np.float32), Discrete(n=3),
Discrete(n=2)))</li>
</ul>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.spaces <span class="hljs-keyword">import</span> *</span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">space = <span class="hljs-type">Tuple</span>(spaces=(Box(low=-<span class="hljs-number">1.0</span>, high=<span class="hljs-number">1.0</span>, shape=(<span class="hljs-number">3</span>,), dtype=np.float32), Discrete(n=<span class="hljs-number">3</span>), Discrete(n=<span class="hljs-number">2</span>)))</span><br><span class="line"><span class="hljs-built_in">print</span>(space.sample())</span><br></pre></td></tr></tbody></table></figure>
<p>输出是</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(array([ 0.22640526,  0.75286865, -0.6309239 ], dtype=float32), 0, 1)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>Dict：组合成有名字的复合空间。例如，Dict({'position':Discrete(2),
'velocity':Discrete(3)}) <figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.spaces <span class="hljs-keyword">import</span> *</span><br><span class="line">space = <span class="hljs-type">Dict</span>({<span class="hljs-string">'position'</span>:Discrete(<span class="hljs-number">2</span>), <span class="hljs-string">'velocity'</span>:Discrete(<span class="hljs-number">3</span>)})</span><br><span class="line"><span class="hljs-built_in">print</span>(space.sample())</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<p>输出是</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(<span class="hljs-string">'position'</span>, 1), (<span class="hljs-string">'velocity'</span>, 1)])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="nes-1942-动作空间配置">NES 1942 动作空间配置</h2>
<p>了解了 gym/retro 的动作空间，我们来看看1942的默认动作空间
</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">env = retro.make(game=<span class="hljs-string">'1942-Nes'</span>)</span><br><span class="line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"The size of action is: "</span>, env.action_space.shape)</span><br></pre></td></tr></tbody></table></figure><p></p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The size of action is:  (9,)</span><br></pre></td></tr></tbody></table></figure>
<p>表示有9个 Discrete 动作，包括 start, select这些控制键。</p>
<p>从训练1942角度来说，我们希望指定最少的有效动作取得最好的成绩。根据经验，我们知道这个游戏最重要的键是4个方向加上
fire
键。限定游戏动作空间，官方的做法是在创建游戏环境时，指定预先生成的动作输入配置文件。但是这个方式相对麻烦，我们采用了直接指定按键的二进制表示来达到同样的目的，此时，需要设置
use_restricted_actions=retro.Actions.FILTERED。</p>
<p>下面的代码限制了6种按键，并随机play。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">action_list = [</span><br><span class="line">    <span class="hljs-comment"># No Operation</span></span><br><span class="line">    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],</span><br><span class="line">    <span class="hljs-comment"># Left</span></span><br><span class="line">    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],</span><br><span class="line">    <span class="hljs-comment"># Right</span></span><br><span class="line">    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],</span><br><span class="line">    <span class="hljs-comment"># Down</span></span><br><span class="line">    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],</span><br><span class="line">    <span class="hljs-comment"># Up</span></span><br><span class="line">    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],</span><br><span class="line">    <span class="hljs-comment"># B</span></span><br><span class="line">    [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">random_play</span>(<span class="hljs-params">env, action_list, sleep_seconds=<span class="hljs-number">0.01</span></span>):</span></span><br><span class="line">    env.viewer = <span class="hljs-literal">None</span></span><br><span class="line">    state = env.reset()</span><br><span class="line">    score = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>):</span><br><span class="line">        env.render()</span><br><span class="line">        time.sleep(sleep_seconds)</span><br><span class="line">        action = np.random.randint(<span class="hljs-built_in">len</span>(action_list))</span><br><span class="line"></span><br><span class="line">        next_state, reward, done, _ = env.step(action_list[action])</span><br><span class="line">        state = next_state</span><br><span class="line">        score += reward</span><br><span class="line">        <span class="hljs-keyword">if</span> done:</span><br><span class="line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"Episode Score: "</span>, score)</span><br><span class="line">            env.reset()</span><br><span class="line">            <span class="hljs-keyword">break</span></span><br><span class="line">            </span><br><span class="line">env = retro.make(game=<span class="hljs-string">'1942-Nes'</span>, use_restricted_actions=retro.Actions.FILTERED)</span><br><span class="line">random_play(env, action_list)</span><br></pre></td></tr></tbody></table></figure>
<p>来看看其游戏效果，全随机死的还是比较快。</p>
<figure>
<img src="/zh/2021/rl-ppo-1984/random.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="图像输入处理">图像输入处理</h2>
<p>一般对于通过屏幕像素作为输入的RL
end-to-end训练来说，对图像做预处理很关键。因为原始图像较大，一方面我们希望能尽量压缩图像到比较小的tensor，另一方面又要保证关键信息不丢失，比如子弹的图像不能因为图片缩小而消失。另外的一个通用技巧是将多个连续的frame合并起来组成立体的frame，这样可以有效表示连贯动作。</p>
<p>下面的代码通过 pipeline 将游戏每帧原始图像从shape (224, 240, 3)
转换成 (4, 84, 84)，也就是原始的 width=224，height=240，rgb=3转换成
width=84，height=240，stack_size=4的黑白图像。具体 pipeline为</p>
<ol type="1">
<li><p>MaxAndSkipEnv：每两帧过滤一帧图像，减少数据量。</p></li>
<li><p>FrameDownSample：down sample 图像到指定小分辨率
84x84，并从彩色降到黑白。</p></li>
<li><p>FrameBuffer：合并连续的4帧，形成 (4, 84, 84) 的图像输入</p></li>
</ol>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_env</span>():</span></span><br><span class="line">    env = retro.make(game=<span class="hljs-string">'1942-Nes'</span>, use_restricted_actions=retro.Actions.FILTERED)</span><br><span class="line">    env = MaxAndSkipEnv(env, skip=<span class="hljs-number">2</span>)</span><br><span class="line">    env = FrameDownSample(env, (<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</span><br><span class="line">    env = FrameBuffer(env, <span class="hljs-number">4</span>)</span><br><span class="line">    env.seed(<span class="hljs-number">0</span>)</span><br><span class="line">    <span class="hljs-keyword">return</span> env</span><br></pre></td></tr></tbody></table></figure>
<p>观察图像维度变换</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">env = retro.make(game=<span class="hljs-string">'1942-Nes'</span>, use_restricted_actions=retro.Actions.FILTERED)</span><br><span class="line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"Initial shape: "</span>, env.observation_space.shape)</span><br><span class="line"></span><br><span class="line">env = build_env(env)</span><br><span class="line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"Processed shape: "</span>, env.observation_space.shape)</span><br></pre></td></tr></tbody></table></figure>
<p>确保shape 从 (224, 240, 3) 转换成 (4, 84, 84)</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Initial shape:  (224, 240, 3)</span><br><span class="line">Processed shape:  (4, 84, 84)</span><br></pre></td></tr></tbody></table></figure>
<p>FrameDownSample实现如下，我们使用了 cv2
类库来完成黑白化和图像缩放</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FrameDownSample</span>(<span class="hljs-params">ObservationWrapper</span>):</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, env, exclude, width=<span class="hljs-number">84</span>, height=<span class="hljs-number">84</span></span>):</span></span><br><span class="line">        <span class="hljs-built_in">super</span>(FrameDownSample, self).__init__(env)</span><br><span class="line">        self.exclude = exclude</span><br><span class="line">        self.observation_space = Box(low=<span class="hljs-number">0</span>,</span><br><span class="line">                                     high=<span class="hljs-number">255</span>,</span><br><span class="line">                                     shape=(width, height, <span class="hljs-number">1</span>),</span><br><span class="line">                                     dtype=np.uint8)</span><br><span class="line">        self._width = width</span><br><span class="line">        self._height = height</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">observation</span>(<span class="hljs-params">self, observation</span>):</span></span><br><span class="line">        <span class="hljs-comment"># convert image to gray scale</span></span><br><span class="line">        screen = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># crop screen [up: down, left: right]</span></span><br><span class="line">        screen = screen[self.exclude[<span class="hljs-number">0</span>]:self.exclude[<span class="hljs-number">2</span>], self.exclude[<span class="hljs-number">3</span>]:self.exclude[<span class="hljs-number">1</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># to float, and normalized</span></span><br><span class="line">        screen = np.ascontiguousarray(screen, dtype=np.float32) / <span class="hljs-number">255</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># resize image</span></span><br><span class="line">        screen = cv2.resize(screen, (self._width, self._height), interpolation=cv2.INTER_AREA)</span><br><span class="line">        <span class="hljs-keyword">return</span> screen</span><br></pre></td></tr></tbody></table></figure>
<p>MaxAndSkipEnv，每两帧过滤一帧</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MaxAndSkipEnv</span>(<span class="hljs-params">Wrapper</span>):</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, env=<span class="hljs-literal">None</span>, skip=<span class="hljs-number">4</span></span>):</span></span><br><span class="line">        <span class="hljs-built_in">super</span>(MaxAndSkipEnv, self).__init__(env)</span><br><span class="line">        self._obs_buffer = deque(maxlen=<span class="hljs-number">2</span>)</span><br><span class="line">        self._skip = skip</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self, action</span>):</span></span><br><span class="line">        total_reward = <span class="hljs-number">0.0</span></span><br><span class="line">        done = <span class="hljs-literal">None</span></span><br><span class="line">        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self._skip):</span><br><span class="line">            obs, reward, done, info = self.env.step(action)</span><br><span class="line">            self._obs_buffer.append(obs)</span><br><span class="line">            total_reward += reward</span><br><span class="line">            <span class="hljs-keyword">if</span> done:</span><br><span class="line">                <span class="hljs-keyword">break</span></span><br><span class="line">        max_frame = np.<span class="hljs-built_in">max</span>(np.stack(self._obs_buffer), axis=<span class="hljs-number">0</span>)</span><br><span class="line">        <span class="hljs-keyword">return</span> max_frame, total_reward, done, info</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reset</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        self._obs_buffer.clear()</span><br><span class="line">        obs = self.env.reset()</span><br><span class="line">        self._obs_buffer.append(obs)</span><br><span class="line">        <span class="hljs-keyword">return</span> obs</span><br></pre></td></tr></tbody></table></figure>
<p>FrameBuffer，将最近的4帧合并起来</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FrameBuffer</span>(<span class="hljs-params">ObservationWrapper</span>):</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, env, num_steps, dtype=np.float32</span>):</span></span><br><span class="line">        <span class="hljs-built_in">super</span>(FrameBuffer, self).__init__(env)</span><br><span class="line">        obs_space = env.observation_space</span><br><span class="line">        self._dtype = dtype</span><br><span class="line">        self.observation_space = Box(low=<span class="hljs-number">0</span>, high=<span class="hljs-number">255</span>, shape=(num_steps, obs_space.shape[<span class="hljs-number">0</span>], obs_space.shape[<span class="hljs-number">1</span>]), dtype=self._dtype)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reset</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        frame = self.env.reset()</span><br><span class="line">        self.buffer = np.stack(arrays=[frame, frame, frame, frame])</span><br><span class="line">        <span class="hljs-keyword">return</span> self.buffer</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">observation</span>(<span class="hljs-params">self, observation</span>):</span></span><br><span class="line">        self.buffer[:-<span class="hljs-number">1</span>] = self.buffer[<span class="hljs-number">1</span>:]</span><br><span class="line">        self.buffer[-<span class="hljs-number">1</span>] = observation</span><br><span class="line">        <span class="hljs-keyword">return</span> self.buffer</span><br></pre></td></tr></tbody></table></figure>
<p>最后，visualize
处理后的图像，同样还是在随机play中，确保关键信息不丢失</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">random_play_preprocessed</span>(<span class="hljs-params">env, action_list, sleep_seconds=<span class="hljs-number">0.01</span></span>):</span></span><br><span class="line">    <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">    env.viewer = <span class="hljs-literal">None</span></span><br><span class="line">    state = env.reset()</span><br><span class="line">    score = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>):</span><br><span class="line">        time.sleep(sleep_seconds)</span><br><span class="line">        action = np.random.randint(<span class="hljs-built_in">len</span>(action_list))</span><br><span class="line"></span><br><span class="line">        plt.imshow(state[-<span class="hljs-number">1</span>], cmap=<span class="hljs-string">"gray"</span>)</span><br><span class="line">        plt.title(<span class="hljs-string">'Pre Processed image'</span>)</span><br><span class="line">        plt.pause(sleep_seconds)</span><br><span class="line"></span><br><span class="line">        next_state, reward, done, _ = env.step(action_list[action])</span><br><span class="line">        state = next_state</span><br><span class="line">        score += reward</span><br><span class="line">        <span class="hljs-keyword">if</span> done:</span><br><span class="line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"Episode Score: "</span>, score)</span><br><span class="line">            env.reset()</span><br><span class="line">            <span class="hljs-keyword">break</span></span><br></pre></td></tr></tbody></table></figure>
<p>matplotlib 动画输出</p>
<figure>
<img src="/zh/2021/rl-ppo-1984/preprocess.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="cnn-actor-critic">CNN Actor &amp; Critic</h2>
<p>Actor 和 Critic 模型相同，输入是 (4, 84, 84) 的图像，输出是 [0, 5]
的action index。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Actor</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, input_shape, num_actions</span>):</span></span><br><span class="line">        <span class="hljs-built_in">super</span>(Actor, self).__init__()</span><br><span class="line">        self.input_shape = input_shape</span><br><span class="line">        self.num_actions = num_actions</span><br><span class="line"></span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_shape[<span class="hljs-number">0</span>], <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">8</span>, stride=<span class="hljs-number">4</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(self.feature_size(), <span class="hljs-number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="hljs-number">512</span>, self.num_actions),</span><br><span class="line">            nn.Softmax(dim=<span class="hljs-number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        dist = Categorical(x)</span><br><span class="line">        <span class="hljs-keyword">return</span> dist</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ppo核心代码">PPO核心代码</h2>
<p>先计算 <span class="math inline">\(r_t(\theta)\)</span>，这里采用了一个技巧，对 <span class="math inline">\(\pi_\theta\)</span> 取 log，相减再取
exp，这样可以增强数值稳定性。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dist = self.actor_net(state)</span><br><span class="line">new_log_probs = dist.log_prob(action)</span><br><span class="line">ratio = (new_log_probs - old_log_probs).exp()</span><br><span class="line">surr1 = ratio * advantage</span><br></pre></td></tr></tbody></table></figure>
<p>surr1 对应PPO论文中的 <span class="math inline">\(L^{CPI}\)</span></p>
<figure>
<img src="/zh/2021/rl-ppo-1984/L_CPI.PNG">
<figcaption>
</figcaption>
</figure>
<p>然后计算 surr2，对应 <span class="math inline">\(L^{CLIP}\)</span>
中的 clip 部分，clip可以由 torch.clamp 函数实现。<span class="math inline">\(L^{CLIP}\)</span> 则对应 actor_loss。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">surr2 = torch.clamp(ratio, <span class="hljs-number">1.0</span> - self.clip_param, <span class="hljs-number">1.0</span> + self.clip_param) * advantage</span><br><span class="line">actor_loss = - torch.<span class="hljs-built_in">min</span>(surr1, surr2).mean()</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2021/rl-ppo-1984/L_CLIP.PNG">
<figcaption>
</figcaption>
</figure>
<p>最后，计算总的 loss <span class="math inline">\(L_t^{CLIP+VF+S}\)</span>，包括
actor_loss，critic_loss 和 policy的 entropy。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">entropy = dist.entropy().mean()</span><br><span class="line"></span><br><span class="line">critic_loss = (return_ - value).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean()</span><br><span class="line">loss = actor_loss + <span class="hljs-number">0.5</span> * critic_loss - <span class="hljs-number">0.001</span> * entropy</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2021/rl-ppo-1984/loss.PNG">
<figcaption>
</figcaption>
</figure>
<p>上述完整代码如下</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.ppo_epoch):</span><br><span class="line">    <span class="hljs-keyword">for</span> state, action, old_log_probs, return_, advantage <span class="hljs-keyword">in</span> sample_batch():</span><br><span class="line">        dist = self.actor_net(state)</span><br><span class="line">        value = self.critic_net(state)</span><br><span class="line"></span><br><span class="line">        entropy = dist.entropy().mean()</span><br><span class="line">        new_log_probs = dist.log_prob(action)</span><br><span class="line"></span><br><span class="line">        ratio = (new_log_probs - old_log_probs).exp()</span><br><span class="line">        surr1 = ratio * advantage</span><br><span class="line">        surr2 = torch.clamp(ratio, <span class="hljs-number">1.0</span> - self.clip_param, <span class="hljs-number">1.0</span> + self.clip_param) * advantage</span><br><span class="line"></span><br><span class="line">        actor_loss = - torch.<span class="hljs-built_in">min</span>(surr1, surr2).mean()</span><br><span class="line">        critic_loss = (return_ - value).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean()</span><br><span class="line"></span><br><span class="line">        loss = actor_loss + <span class="hljs-number">0.5</span> * critic_loss - <span class="hljs-number">0.001</span> * entropy</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Minimize the loss</span></span><br><span class="line">        self.actor_optimizer.zero_grad()</span><br><span class="line">        self.critic_optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.actor_optimizer.step()</span><br><span class="line">        self.critic_optimizer.step()</span><br></pre></td></tr></tbody></table></figure>
<p>补充一下 GAE 的计算，advantage 根据公式</p>
<figure>
<img src="/zh/2021/rl-ppo-1984/gae.PNG">
<figcaption>
</figcaption>
</figure>
<p>可以转换成如下代码</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_gae</span>(<span class="hljs-params">self, next_value</span>):</span></span><br><span class="line">    gae = <span class="hljs-number">0</span></span><br><span class="line">    returns = []</span><br><span class="line">    values = self.values + [next_value]</span><br><span class="line">    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.rewards))):</span><br><span class="line">        delta = self.rewards[step] + self.gamma * values[step + <span class="hljs-number">1</span>] * self.masks[step] - values[step]</span><br><span class="line">        gae = delta + self.gamma * self.tau * self.masks[step] * gae</span><br><span class="line">        returns.insert(<span class="hljs-number">0</span>, gae + values[step])</span><br><span class="line">    <span class="hljs-keyword">return</span> returns</span><br></pre></td></tr></tbody></table></figure>
<h2 id="外层-training-代码">外层 Training 代码</h2>
<p>外层调用代码基于随机 play 的逻辑，agent.act()封装了采样和 forward
prop，agent.step() 则封装了 backprop 和参数学习迭代的逻辑。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_epoch + <span class="hljs-number">1</span>, n_episodes + <span class="hljs-number">1</span>):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    score = <span class="hljs-number">0</span></span><br><span class="line">    timestamp = <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">while</span> timestamp &lt; <span class="hljs-number">10000</span>:</span><br><span class="line">        action, log_prob, value = agent.act(state)</span><br><span class="line">        next_state, reward, done, info = env.step(action_list[action])</span><br><span class="line">        score += reward</span><br><span class="line">        timestamp += <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line">        agent.step(state, action, value, log_prob, reward, done, next_state)</span><br><span class="line">        <span class="hljs-keyword">if</span> done:</span><br><span class="line">            <span class="hljs-keyword">break</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            state = next_state</span><br></pre></td></tr></tbody></table></figure>
<h2 id="训练结果">训练结果</h2>
<p>让我们来看看学习的效果吧，注意我们的飞机学到了一些关键的技巧，躲避子弹；飞到角落尽快击毙敌机；一定程度预测敌机出现的位置并预先走到位置。</p>
<div class="bili_video"><iframe src="https://player.bilibili.com/player.html?aid=NaN&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" width="544" height="452" allowfullscreen="true"> </iframe></div>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/stat-ml-mle-1/" itemprop="url">深入形象地理解极大似然估计(MLE) 1: 引入问题</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-04-03T18:45:01.000Z" itemprop="datePublished">4月 4 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            19 分钟 读完 (约 2816 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>导读：极大似然估计(MLE)
是统计机器学习中最基本的概念，但是能真正全面深入地理解它的性质和背后和其他基本理论的关系不是件容易的事情。极大似然估计和以下概念都有着紧密的联系：随机变量，无偏性质（unbiasedness），一致估计（consistent），asymptotic
normality，最优化（optimization），Fisher
Information，MAP（最大后验估计），KL-Divergence，sufficient
statistics等。在众多阐述 MLE
的文章或者课程中，总体来说都比较抽象，注重公式推导。本系列文章受3blue1brown
可视化教学的启发，坚持从第一性原理出发，通过数学原理结合模拟和动画，深入浅出地让读者理解极大似然估计。</p>
<p>相关链接</p>
<h2 id="抛硬币问题">抛硬币问题</h2>
<p>我们来思考这个老套问题，考虑手上有一枚硬币，旋转（抛）硬币得到正反面的概率固定（令正面概率为<span class="math inline">\(\theta^{\star}\)</span>）但未知，我们如何能通过实验推测出
<span class="math inline">\(\theta^{\star}\)</span></p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/toss.gif">
<figcaption>
</figcaption>
</figure>
<p>朴素的想法是，不断尝试抛硬币，随着次数 n 的增多，正面的比例会趋近于
<span class="math inline">\(\theta^{\star}\)</span></p>
<p>对应到数学形式上，令我们对于 <span class="math inline">\(\theta^{\star}\)</span> 的估计为 <span class="math inline">\(\hat{\theta}_{n}\)</span>，则希望 <span class="math display">\[
\hat{\theta}_n = {n_{head} \over n} \to \theta^{\star} \text{  as n }
\to \infty
\]</span></p>
<h2 id="模拟试验代码">模拟试验代码</h2>
<p>假设我们尝试了n次，每次的结果为 <span class="math inline">\(x_i\)</span>，<span class="math inline">\(x_i\)</span>为1（正面） 或
0（反面）。比如试了三次的结果是 [1, 0, 1]，则 <span class="math inline">\(x_1=1, x_2=0,
x_3=1\)</span>。一般，我们将观察到的数据写成向量形式</p>
<p><span class="math display">\[X=[x_1, x_2, x_3]^T=[1, 0,
1]^{T}\]</span></p>
<p>我们知道硬币的正反结果符合伯努利分布，也就是 <span class="math display">\[
\begin{align*}
P_{ber}(x;\theta) =
\left\lbrace
  \begin{array}{r@{}l}
   \theta &amp;\text{  if x=1} \\
   1-\theta &amp;\text{  if x=0}
\end{array}
\right.
\end{align*}
\]</span></p>
<p>因为 x
只有0，1两种取值，因此上式也可以写成等价如下的不含条件分支的形式 <span class="math display">\[
P_{ber} = \theta^x \cdot (1-\theta)^x
\]</span></p>
<p>假设 <span class="math inline">\(\theta^{\star} =
0.7\)</span>，如果做 n=10 次试验，结果应该比较接近7个1，3个0。</p>
<p>下面我们来模拟一下 n=10，看看结果如何。</p>
<p>下面代码的实现上我们直接使用了pytorch 内置的 bernoulli 函数生成 n
个随机变量实例 </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_coins</span>(<span class="hljs-params">theta, n=<span class="hljs-number">1</span></span>):</span></span><br><span class="line">    <span class="hljs-keyword">import</span> torch</span><br><span class="line">    theta_vec = torch.tensor(n*[theta])</span><br><span class="line">    random_values = torch.bernoulli(theta_vec)</span><br><span class="line">    <span class="hljs-keyword">return</span> random_values</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>让我们来做三次 n=10 的试验</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):</span><br><span class="line">    coins = gen_coins(theta=<span class="hljs-number">0.7</span>, n=<span class="hljs-number">10</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'trial <span class="hljs-subst">{i}</span>'</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'head #: <span class="hljs-subst">{<span class="hljs-built_in">sum</span>(coins)}</span>'</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'tail #: <span class="hljs-subst">{<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>-coins)}</span>'</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>()</span><br></pre></td></tr></tbody></table></figure>
<p>能发现 7个1，3个0 确实是比较可能的结果。 </p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">trial 0</span><br><span class="line">head <span class="hljs-comment">#: 7.0</span></span><br><span class="line">tail <span class="hljs-comment">#: 3.0</span></span><br><span class="line"></span><br><span class="line">trial 1</span><br><span class="line">head <span class="hljs-comment">#: 9.0</span></span><br><span class="line">tail <span class="hljs-comment">#: 1.0</span></span><br><span class="line"></span><br><span class="line">trial 2</span><br><span class="line">head <span class="hljs-comment">#: 7.0</span></span><br><span class="line">tail <span class="hljs-comment">#: 3.0</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="生成概率">生成概率</h2>
<p>直觉告诉我们，当 <span class="math inline">\(\theta^{\star}=0.7\)</span> 时，根据 $P_{ber}(x;)
$，7个1，3个0 出现的概率应该是最大，6个1，4个0 或者 8个1，2个0
这两种情况出现概率稍小，其他的情况概率更小。通过基本概率和伯努利公式，重复
n 次试验
1和0出现的概率可以由下面公式算出。（注：7个1，3个0不是单一事件，需要乘以组合数算出实际概率）</p>
<p><span class="math display">\[
P_{X} = \theta^{heads} \cdot (1-\theta)^{tails} \cdot {n \choose heads}
\]</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>P(X)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>head=0</td>
<td>0.000006</td>
</tr>
<tr class="even">
<td>head=1</td>
<td>0.000138</td>
</tr>
<tr class="odd">
<td>head=2</td>
<td>0.000032</td>
</tr>
<tr class="even">
<td>head=3</td>
<td>0.001447</td>
</tr>
<tr class="odd">
<td>head=4</td>
<td>0.036757</td>
</tr>
<tr class="even">
<td>head=5</td>
<td>0.102919</td>
</tr>
<tr class="odd">
<td>head=6</td>
<td>0.200121</td>
</tr>
<tr class="even">
<td>head=7</td>
<td>0.266828</td>
</tr>
<tr class="odd">
<td>head=8</td>
<td>0.233474</td>
</tr>
<tr class="even">
<td>head=9</td>
<td>0.121061</td>
</tr>
<tr class="odd">
<td>head=10</td>
<td>0.028248</td>
</tr>
</tbody>
</table>
<p>画出图看的很明显，1出现7次的概率确实最大。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/joint_prob.png">
<figcaption>
</figcaption>
</figure>
<p>回到我们的问题，我们先假定 <span class="math inline">\(\theta^{\star}
= 0.7\)</span> 的硬币做 n=10 次试验的结果就是 7个1，3个0，或者具体序列为
[1, 0, 0, 1, 0, 1, 1, 1, 1, 1]。那么我们希望按照某种方法推测的估计值
<span class="math inline">\(\hat\theta\)</span> 也为 0.7。</p>
<p>若将这个方法也记做 <span class="math inline">\(\hat\theta\)</span>，它是<span class="math inline">\(X\)</span> 的函数，即 <span class="math inline">\(\hat\theta(X=[1, 0, 0, 1, 0, 1, 1, 1, 1,
1]^T)=0.7\)</span></p>
<p>我们如何构建这个方法呢？很显然，<span class="math inline">\(X\)</span> 中 1 的个数就可以胜任，<span class="math inline">\(\hat\theta=\bar
X\)</span>。这个方式确实是正确的，后面的文章我们也会证明它是MLE在伯努利分布参数估计时的计算方法。</p>
<p>但是伯努利分布参数估计的问题中是最简单的情况，背后对应的更一般的问题是：假设我们知道某个过程或者实验生成了某种分布
P，但是不知道它的参数 <span class="math inline">\(\theta\)</span>，如何能通过反复的试验来推断 <span class="math inline">\(\theta\)</span>，同时，我们希望随着试验次数的增多，<span class="math inline">\(\hat\theta\)</span> 能逼近 <span class="math inline">\(\theta\)</span>。</p>
<p>由于过程是有随机性，试验结果 <span class="math inline">\(X\)</span>
并不能确定一定是从 <span class="math inline">\(\hat\theta\)</span>
生成的，因此我们需要对所有 <span class="math inline">\(\theta\)</span>
打分。对于抛硬币试验来说，我们穷举所有在 [0, 1] 范围内的 <span class="math inline">\(\theta\)</span>，定义它的打分函数 <span class="math inline">\(f(\theta)\)</span>，并且希望我们定义的 <span class="math inline">\(f(\theta;X=[1, 0, 0, 1, 0, 1, 1, 1, 1,
1]^T)\)</span> 在 <span class="math inline">\(\theta=0.7\)</span>
时得分最高。推广到一般场景，有如下性质 <span class="math display">\[
f(\theta^\star;X) &gt;= f(\theta;X)
\]</span></p>
<p>如此，我们将推测参数问题转换成了优化问题 <span class="math display">\[
\hat\theta = \theta^{\star} = \operatorname{argmax}_{\theta} f(\theta;
X) = 0.7
\]</span></p>
<h2 id="朴素方法">朴素方法</h2>
<p>一种朴素的想法是，由于 <span class="math inline">\(\theta^\star=0.7\)</span>，因此我们每次的结果应该稍微偏向
1，如果出现了
1，就记0.7分，出现了0，记0.3分，那么我们可以用10个结果的总分来定义总得分，即最大化函数</p>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
&amp;\operatorname{argmax}_{\theta} f(\theta) \\
=&amp; \operatorname{argmax}_{\theta} P(x_1) + P(x_2) + ... + P(x_n) \\
=&amp; \operatorname{argmax}_{\theta} P(x_1|\theta) + P(x_2|\theta) +
... + P(x_n|\theta) \\
=&amp; \operatorname{argmax}_{\theta} \sum P(x_i|\theta) \\
\end{aligned}
\end{equation*}
\]</span></p>
<p>很可惜，我们定义的 f 并不符合 <span class="math inline">\(\theta=0.7\)</span> 时取到最大的原则。下面画出了
<span class="math inline">\(\theta\)</span> 在 [0, 1] 范围内 f 值，X
固定为 [1, 0, 0, 1, 0, 1, 1, 1, 1, 1]。显然，极值在 0.5 左右。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/sum-likelihood_w.gif">
<figcaption>
</figcaption>
</figure>
<p>这种对于观察到的变量实例在整个参数空间打分的方法是最大似然方法的雏形。我们将每次试验结果对于不同
<span class="math inline">\(\theta\)</span>
的打分就是似然函数的概念。</p>
<h2 id="伯努利似然函数likelihood">伯努利似然函数（Likelihood)</h2>
<p>伯努利单个结果的似然函数 <span class="math inline">\(l(\theta)\)</span> 视为 <span class="math inline">\(\theta\)</span>
的函数，x视为给定值，它等价于概率质量函数 PMF</p>
<p><span class="math display">\[
l(\theta|x) = \theta^x \cdot (1-\theta)^x
\]</span></p>
<h2 id="极大似然估计mle">极大似然估计(MLE)</h2>
<p>有了单个结果的似然函数，我们如何定义 <span class="math inline">\(f(\theta)\)</span> 呢？我们定义的 <span class="math inline">\(f(\theta)\)</span> 需要满足，在 <span class="math inline">\(\theta^\star=0.7\)</span> ，<span class="math inline">\(n=10\)</span> 的情况下，试验最有可能的结果是 7
个1，3个0，此时 f 需要在 <span class="math inline">\(\theta=0.7\)</span>
时取到最大值。</p>
<p>极大似然估计(MLE) 为我们定义了合理的 <span class="math inline">\(f(\theta)\)</span>
，和朴素的想法类似，但是这次用单个结果的似然函数连乘而非连加 <span class="math display">\[
L(\theta|X) = l(\theta|x_1) \cdot l(\theta|x_2) \cdot ...l(\theta|x_n) =
\prod l(\theta|x_i)
\]</span></p>
<p>我们再来看一下当 $X=[1, 0, 0, 1, 0, 1, 1, 1, 1, 1] $ 时 <span class="math inline">\(L\)</span> 在 <span class="math inline">\(\theta\)</span> 空间的取值情况，果然，MLE 能在
0.7时取到最大值。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/prod_likelihood_w.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="对数似然函数">对数似然函数</h2>
<p>最大似然函数 $_{} L() $ 能让我们找到最可能的 <span class="math inline">\(\theta\)</span>，但现实中，我们一般采用最大其 log
的形式。</p>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
&amp;\operatorname{argmax}_{\theta} \log L(\theta|X) \\
=&amp; \operatorname{argmax}_{\theta} \log [l(\theta|x_1) \cdot
l(\theta|x_2) \cdot ... \cdot l(\theta|x_n)]   \\
=&amp; \operatorname{argmax}_{\theta} \log l(\theta|x_1) + \log
l(\theta|x_2) \cdot ... + \log l(\theta|x_n)
\end{aligned}
\end{equation*}
\]</span></p>
<p>理论能证明，最大对数似然函数得到的极值等价于最大似然函数。但这么做有什么额外好处呢？</p>
<p>我们先将对数似然函数画出来</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/prod_log_likelihood_w.gif">
<figcaption>
</figcaption>
</figure>
<p>它的极大值也在 0.7，但是我们发现对数似然函数是个 concave
函数。在优化领域，最大化 concave 函数或者最小化 convex
函数可以有非常高效的解法。再仔细看之前的似然函数，它并不是一个 concave
函数。另一个非常重要的好处是，随着 n 的增大，连乘会导致浮点数
underflow，而单个点的对数似然函数的和的形式就不会有这个问题。</p>
<h2 id="pytorch-mle-代码">Pytorch MLE 代码</h2>
<p>就让我们来实践一下，通过 pytorch 梯度上升来找到极值点。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> stats.coin <span class="hljs-keyword">import</span> gen_coins</span><br><span class="line"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">num_head: <span class="hljs-built_in">int</span>, num_tail: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">    <span class="hljs-keyword">import</span> torch</span><br><span class="line">    theta = torch.tensor(<span class="hljs-number">0.5</span>, requires_grad=<span class="hljs-literal">True</span>)</span><br><span class="line"></span><br><span class="line">    recent = deque(<span class="hljs-number">3</span>*[<span class="hljs-number">100</span>], maxlen=<span class="hljs-number">3</span>)</span><br><span class="line"></span><br><span class="line">    lr = <span class="hljs-number">0.00001</span></span><br><span class="line">    <span class="hljs-keyword">for</span> <span class="hljs-built_in">iter</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):</span><br><span class="line">        loss = -(num_head * torch.log(theta) + num_tail * torch.log(<span class="hljs-number">1</span> - theta))</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="hljs-keyword">with</span> torch.no_grad():</span><br><span class="line">            theta -= lr * theta.grad</span><br><span class="line">            <span class="hljs-comment"># print(f'{iter}: {theta}, {theta.grad}')</span></span><br><span class="line">            recent.append(theta.grad.item())</span><br><span class="line">            <span class="hljs-keyword">if</span> <span class="hljs-built_in">all</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">abs</span>(x) &lt; <span class="hljs-number">1</span>, recent)):</span><br><span class="line">                <span class="hljs-keyword">break</span></span><br><span class="line">        theta.grad.zero_()</span><br><span class="line">    <span class="hljs-keyword">return</span> theta.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:</span><br><span class="line">    data = gen_coins(<span class="hljs-number">0.6</span>, n=<span class="hljs-number">200</span>)</span><br><span class="line"></span><br><span class="line">    num_head = (data.detach() == <span class="hljs-number">1</span>).<span class="hljs-built_in">sum</span>().item()</span><br><span class="line">    num_tail = (data.detach() == <span class="hljs-number">0</span>).<span class="hljs-built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-built_in">print</span>(num_head, num_tail)</span><br><span class="line">    <span class="hljs-built_in">print</span>(train(num_head, num_tail))</span><br></pre></td></tr></tbody></table></figure>
<p>一点需要说明的是，在迭代过程中，我们保存最后三个导数的值，当最新的三个导数都很小时就退出迭代。</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if all(map(lambda x: abs(x) &lt; 1, recent))</span><br></pre></td></tr></tbody></table></figure>
<p>运行代码，能发现最大化对数似然函数能很稳定的找到 <span class="math inline">\(\theta\)</span>。</p>
<p>现在大家对于伯努利MLE有了一定了解，接着，我们来思考一下最大化似然函数方法是否随着观察次数的增多能不断逼近真实的
<span class="math inline">\(\theta^\star\)</span>呢？</p>
<h2 id="mle-theta-估计的收敛性">MLE <span class="math inline">\(\theta\)</span> 估计的收敛性</h2>
<p><span class="math inline">\(\theta^\star=0.7\)</span>
的情况下，我们来这样做试验，第一次做 n=1生成观察数据 <span class="math inline">\(X_{1}\)</span>，第二次做 n=2生成观察数据 <span class="math inline">\(X_{2}\)</span> <span class="math display">\[
X_1,X_2, X_3, ..., X_N
\]</span> 对于每个数据集 <span class="math inline">\(X_i\)</span>
通过最大似然方法求得估计的 <span class="math inline">\(\hat\theta\)</span> <span class="math display">\[
\hat\theta_1=MLE(X_1), \hat\theta_2=MLE(X_2), ..., \hat\theta_N=MLE(X_N)
\]</span> 将这些 <span class="math inline">\(\hat\theta_i\)</span>
画出来，可以看到，随着 <span class="math inline">\(n \to
\infty\)</span>，<span class="math inline">\(\hat\theta_i \to
\theta^\star=0.7\)</span></p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/bias_w.gif">
<figcaption>
</figcaption>
</figure>
<p>换一个角度来看一下，我们将 <span class="math inline">\(\hat\theta_i\)</span>
数列按照顺序，离散化后再归一化比例，如下图画出来，红色的柱代表了最新的值
<span class="math inline">\(\hat\theta\)</span>。可以发现，初始时候，<span class="math inline">\(\hat\theta\)</span> 在较远离 0.7 的地方出现，随着
n 的增大，出现的位置比较接近 0.7。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/converge_w.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="mle-theta-估计的偏差和方差">MLE <span class="math inline">\(\theta\)</span> 估计的偏差和方差</h2>
<p>我们已经知道 MLE 方法可以通过观察数据推测出最有可能的 <span class="math inline">\(\hat\theta\)</span>，由于观察数据 <span class="math inline">\(X\)</span> 是伯努利过程产生的，具有随机性，那么
<span class="math inline">\(\hat\theta\)</span> 可以看成是 <span class="math inline">\(\theta^\star\)</span>
的随机变量。我们已经通过上面的试验知道随着试验次数的增大，我们的估计会越来越逼近真实值，现在的问题是对于<strong>固定的n</strong>，<span class="math inline">\(\hat\theta\)</span>
的方差是多少，它的均值是否是无偏的呢？</p>
<p>带着这样的疑问，我们现在做如下试验：</p>
<p>固定 n=10，重复做实验，画出随着次数增多 <span class="math inline">\(\hat\theta\)</span>
的分布，见图中绿色部分。同样的，红色是 n=80 不断试验的分布变换。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/theta_variance_w.gif">
<figcaption>
</figcaption>
</figure>
<p>看的出来，随着试验次数的增多 - <span class="math inline">\(\hat\theta_{10}, \hat\theta_{80}\)</span>
都趋近于正态分布</p>
<ul>
<li><p><span class="math inline">\(\hat\theta_{10}\)</span> 的分散度比 $
_{80}$ 要大，即方差要大</p></li>
<li><p><span class="math inline">\(\hat\theta_{10},
\hat\theta_{80}\)</span> 的均值都在 0.7</p></li>
</ul>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/leetcode-1029-two-city-scheduling/" itemprop="url">Leetcode 1029 两地调度优化解法（附OR-Tools和PuLP代码）</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-02-19T18:45:01.000Z" itemprop="datePublished">2月 20 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 分钟 读完 (约 1850 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><h2 id="leetcode-1029.-两地调度-medium">Leetcode 1029. 两地调度
(medium)</h2>
<p>公司计划面试 2N 人。第 i 人飞往 A 市的费用为 costs[i][0]，飞往 B
市的费用为 costs[i][1]。</p>
<p>返回将每个人都飞到某座城市的最低费用，要求每个城市都有 N
人抵达。&nbsp;</p>
<p>示例：</p>
<blockquote>
<p>输入：[[10,20],[30,200],[400,50],[30,20]] 输出：110 解释： 第一个人去
A 市，费用为 10。 第二个人去 A 市，费用为 30。 第三个人去 B 市，费用为
50。 第四个人去 B 市，费用为 20。 最低总费用为 10 + 30 + 50 + 20 =
110，每个城市都有一半的人在面试。</p>
</blockquote>
<p>提示：</p>
<p>1 &lt;= costs.length &lt;= 100 costs.length 为偶数 1 &lt;=
costs[i][0], costs[i][1] &lt;= 1000</p>
<p>链接：https://leetcode-cn.com/problems/two-city-scheduling</p>
<h2 id="暴力枚举法">暴力枚举法</h2>
<p>最直接的方式是暴力枚举出所有分组的可能。因为 2N
个人平均分成两组，总数为 <span class="math inline">\({2n \choose
n}\)</span>，是 n 的指数级数量。在文章<a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457480569&amp;idx=1&amp;sn=dd90016214931db2f48140d6e269b137&amp;chksm=87bc9b57b0cb12419631a7bcd96b5cd6e6d4081ffdfc49852572a31c4823bda4d42c5e73dcba&amp;scene=21#wechat_redirect">24
点游戏算法题的 Python 函数式实现: 学用itertools，yield，yield from
巧刷题</a>，我们展示如何调用 Python 的
itertools包，这里，我们也用同样的方式产生 [0, 2N]
的所有集合大小为N的可能（保存在left_set_list中），再遍历找到最小值即可。当然，这种解法会TLE，只是举个例子来体会一下暴力做法。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> math</span><br><span class="line"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">twoCitySchedCost</span>(<span class="hljs-params">self, costs: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        L = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(costs))</span><br><span class="line">        <span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> combinations</span><br><span class="line">        left_set_list = [<span class="hljs-built_in">set</span>(c) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> combinations(<span class="hljs-built_in">list</span>(L), <span class="hljs-built_in">len</span>(L)//<span class="hljs-number">2</span>)]</span><br><span class="line"></span><br><span class="line">        min_total = math.inf</span><br><span class="line">        <span class="hljs-keyword">for</span> left_set <span class="hljs-keyword">in</span> left_set_list:</span><br><span class="line">            cost = <span class="hljs-number">0</span></span><br><span class="line">            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> L:</span><br><span class="line">                is_left = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i <span class="hljs-keyword">in</span> left_set <span class="hljs-keyword">else</span> <span class="hljs-number">0</span></span><br><span class="line">                cost += costs[i][is_left]</span><br><span class="line">            min_total = <span class="hljs-built_in">min</span>(min_total, cost)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> min_total</span><br></pre></td></tr></tbody></table></figure>
<h2 id="on-ac解法">O(N) AC解法</h2>
<p>对于组合优化问题来说，例如TSP问题（解法链接 <a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA4NzkxNzM3Nw==&amp;mid=2457480484&amp;idx=1&amp;sn=bf45afaa2bd987747c34a03b9176e89f&amp;chksm=87bc9b0ab0cb121c311299dbf16a55fe76b2b60d6d9e073f37deec49e28766ca416860a7659c#rd">TSP问题从DP算法到深度学习1：递归DP方法
AC AIZU TSP问题</a>），一般都是
NP-Hard问题，意味着没有多项次复杂度的解法。但是这个问题比较特殊，它增加了一个特定条件：去城市A和城市B的人数相同，也就是我们已经知道两个分组的数量是一样的。我们仔细思考一下这个意味着什么？考虑只有四个人的小规模情况，如果让你来手动规划，你一定不会穷举出所有两两分组的可能，而是比较人与人相对的两个城市的cost差。举个例子，有如下四个人的costs
</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0 A:3,  B:1</span><br><span class="line">1 A:99, B:100</span><br><span class="line">2 A:2,  B:2</span><br><span class="line">3 A:3,  B:3</span><br></pre></td></tr></tbody></table></figure> 虽然1号人去城市A（99）cost
很大，但是相比较他去B（100）来说，可以省下 100-99 = 1
的钱，这个钱比0号人去B不去A省下的钱 3-1 = 2
还要多，因此你一定会选择让1号人去A而让0号人去B。<p></p>
<p>有了这个想法，再整理一下，就会发现让某人去哪个城市和他去两个城市的cost
差 $ C_a -
C_b$相关，如果这个值越大，那么他越应该去B。但是最后决定他是否去B取决于他的差在所有人中的排名，由于两组人数相等，因此差能大到排在前一半，则他就去B，在后一半就去A。</p>
<p>按照这个思路，很快能写出代码，代码写法有很多，下面略举一例。代码中由于用到排序，复杂度为
<span class="math inline">\(O(N \cdot \log(N))\)</span>
。这里补充一点，理论上只需找数组中位数的值即可，最好的时间复杂度是 <span class="math inline">\(O(N)\)</span>。</p>
<p>代码实现上，cost_diff_list 将每个人的在原数组的index 和他的cost差组成
pair。即</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(0, cost_0), (1, cost_1), ... ]</span><br></pre></td></tr></tbody></table></figure>
<p>这样我们可以将这个数组按照cost排序，排完序后前面N个元素属于B城市。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 36 ms, faster than 87.77% of Python3 online submissions</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 14.5 MB, less than 14.84% of Python3 online</span></span><br><span class="line"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">twoCitySchedCost</span>(<span class="hljs-params">self, costs: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        L = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(costs))</span><br><span class="line">        cost_diff_lst = [(i, costs[i][<span class="hljs-number">0</span>] - costs[i][<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> L]</span><br><span class="line">        cost_diff_lst.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>])</span><br><span class="line"></span><br><span class="line">        total_cost = <span class="hljs-number">0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> c, (idx, _) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(cost_diff_lst):</span><br><span class="line">            is_left = <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> c &lt; <span class="hljs-built_in">len</span>(L) // <span class="hljs-number">2</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span></span><br><span class="line">            total_cost += costs[idx][is_left]</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> total_cost</span><br></pre></td></tr></tbody></table></figure>
<h2 id="转换成整数规划问题">转换成整数规划问题</h2>
<p>这个问题对于略有算法经验的人来说，很类似于背包问题。它们都需要回答N个物品取或者不取，并同时最大最小化总cost。区别在它们的约束条件不一样。这道题的约束是去取（去城市A）和不取（去城市B）的数量一样。这一类问题即
<em>integer
programming</em>，即整数规划。下面我们选取两个比较流行的优化库来展示如何调包解这道题。</p>
<p>首先我们先来formulate这个问题，因为需要表达两个约束条件，我们将每个人的状态分成是否去A和是否去B两个变量。</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x[i-th-person][0]: boolean 表示是否去 city a</span><br><span class="line">x[i-th-person][1]: boolean 表示是否去 city b</span><br></pre></td></tr></tbody></table></figure>
<p>这样，问题转换成如下优化模型</p>
<p><span class="math display">\[
\begin{array}{rrclcl}
\displaystyle \min_{x} &amp; costs[i][0] \cdot x[i][0] + costs[i][1]
\cdot x[i][1]\\
\textrm{s.t.} &amp; x[i][0] + x[i][1] =1\\
&amp;x[i][0] + x[i][1] + ... =N    \\
\end{array}
\]</span></p>
<h2 id="google-or-tools">Google OR-Tools</h2>
<p>Google OR-Tools
是业界最好的优化库，下面为调用代码，由于直接对应于上面的数学优化问题，不做赘述。当然
Leetcode上不支持这些第三方的库，肯定也不能AC。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> ortools.sat.python <span class="hljs-keyword">import</span> cp_model</span><br><span class="line"></span><br><span class="line">costs = [[<span class="hljs-number">515</span>,<span class="hljs-number">563</span>],[<span class="hljs-number">451</span>,<span class="hljs-number">713</span>],[<span class="hljs-number">537</span>,<span class="hljs-number">709</span>],[<span class="hljs-number">343</span>,<span class="hljs-number">819</span>],[<span class="hljs-number">855</span>,<span class="hljs-number">779</span>],[<span class="hljs-number">457</span>,<span class="hljs-number">60</span>],[<span class="hljs-number">650</span>,<span class="hljs-number">359</span>],[<span class="hljs-number">631</span>,<span class="hljs-number">42</span>]]</span><br><span class="line"></span><br><span class="line">I = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(costs))</span><br><span class="line"></span><br><span class="line">model = cp_model.CpModel()</span><br><span class="line">x = []</span><br><span class="line">total_cost = model.NewIntVar(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>, <span class="hljs-string">'total_cost'</span>)</span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I:</span><br><span class="line">    t = []</span><br><span class="line">    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):</span><br><span class="line">        t.append(model.NewBoolVar(<span class="hljs-string">'x[%i,%i]'</span> % (i, j)))</span><br><span class="line">    x.append(t)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Constraints</span></span><br><span class="line"><span class="hljs-comment"># Each person must be assigned to at exact one city</span></span><br><span class="line">[model.Add(<span class="hljs-built_in">sum</span>(x[i][j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)) == <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I]</span><br><span class="line"><span class="hljs-comment"># equal number of person assigned to two cities</span></span><br><span class="line">model.Add(<span class="hljs-built_in">sum</span>(x[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I) == (<span class="hljs-built_in">len</span>(I) // <span class="hljs-number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Total cost</span></span><br><span class="line">model.Add(total_cost == <span class="hljs-built_in">sum</span>(x[i][<span class="hljs-number">0</span>] * costs[i][<span class="hljs-number">0</span>] + x[i][<span class="hljs-number">1</span>] * costs[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I))</span><br><span class="line">model.Minimize(total_cost)</span><br><span class="line"></span><br><span class="line">solver = cp_model.CpSolver()</span><br><span class="line">status = solver.Solve(model)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> status == cp_model.OPTIMAL:</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Total min cost = %i'</span> % solver.ObjectiveValue())</span><br><span class="line">    <span class="hljs-built_in">print</span>()</span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I:</span><br><span class="line">        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):</span><br><span class="line">            <span class="hljs-keyword">if</span> solver.Value(x[i][j]) == <span class="hljs-number">1</span>:</span><br><span class="line">                <span class="hljs-built_in">print</span>(<span class="hljs-string">'People '</span>, i, <span class="hljs-string">' assigned to city '</span>, j, <span class="hljs-string">'  Cost = '</span>, costs[i][j])</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>完整代码可以从我的github下载。</p>
<p>https://github.com/MyEncyclopedia/leetcode/blob/master/1029_Two_City_Scheduling/1029_ortool.py</p>
<h2 id="pulp">PuLP</h2>
<p>类似的，另一种流行 python 优化库 PuLP 的代码为</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> pulp</span><br><span class="line"></span><br><span class="line">costs = [[<span class="hljs-number">259</span>,<span class="hljs-number">770</span>],[<span class="hljs-number">448</span>,<span class="hljs-number">54</span>],[<span class="hljs-number">926</span>,<span class="hljs-number">667</span>],[<span class="hljs-number">184</span>,<span class="hljs-number">139</span>],[<span class="hljs-number">840</span>,<span class="hljs-number">118</span>],[<span class="hljs-number">577</span>,<span class="hljs-number">469</span>]]   <span class="hljs-comment"># 1859</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">I = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(costs))</span><br><span class="line"></span><br><span class="line">items=[i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I]</span><br><span class="line">city_a = pulp.LpVariable.dicts(<span class="hljs-string">'left'</span>, items, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, pulp.LpBinary)</span><br><span class="line">city_b = pulp.LpVariable.dicts(<span class="hljs-string">'right'</span>, items, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, pulp.LpBinary)</span><br><span class="line"></span><br><span class="line">m = pulp.LpProblem(<span class="hljs-string">"Two Cities"</span>, pulp.LpMinimize)</span><br><span class="line"></span><br><span class="line">m += pulp.lpSum((costs[i][<span class="hljs-number">0</span>] * city_a[i] + costs[i][<span class="hljs-number">1</span>] * city_b[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> items)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Constraints</span></span><br><span class="line"><span class="hljs-comment"># Each person must be assigned to at exact one city</span></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I:</span><br><span class="line">    m += pulp.lpSum([city_a[i] + city_b[i]]) == <span class="hljs-number">1</span></span><br><span class="line"><span class="hljs-comment"># create a binary variable to state that a table setting is used</span></span><br><span class="line">m += pulp.lpSum(city_a[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I) == (<span class="hljs-built_in">len</span>(I) // <span class="hljs-number">2</span>)</span><br><span class="line"></span><br><span class="line">m.solve()</span><br><span class="line"></span><br><span class="line">total = <span class="hljs-number">0</span></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> I:</span><br><span class="line">    <span class="hljs-keyword">if</span> city_a[i].value() == <span class="hljs-number">1.0</span>:</span><br><span class="line">        total += costs[i][<span class="hljs-number">0</span>]</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        total += costs[i][<span class="hljs-number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"Total cost {}"</span>.<span class="hljs-built_in">format</span>(total))</span><br></pre></td></tr></tbody></table></figure>
<p>代码地址为</p>
<p>https://github.com/MyEncyclopedia/leetcode/blob/master/1029_Two_City_Scheduling/1029_pulp.py</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/distribution-inverse-transformation-method/" itemprop="url">用逆变换采样方法构建随机变量生成器</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-01-29T18:45:01.000Z" itemprop="datePublished">1月 30 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 分钟 读完 (约 1887 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>上期 <a href="/zh/2021/distribution-inverse-transformation-method/zh/distribution-discrete-generator.md">从零构建统计随机变量生成器之离散基础篇</a>，我们从零出发构建了基于伯努利的基础离散分布，这一期我们来详细介绍广泛使用的
Inverse Transform Method（逆变换采样方法）。</p>
<ul>
<li><a href="/zh/2021/distribution-inverse-transformation-method/zh/distribution-discrete-generator.md">从零构建统计随机变量生成器之
离散基础篇</a></li>
<li><strong><a href="/zh/2021/distribution-inverse-transformation-method/zh/distribution-inverse-transformation-method.md">从零构建统计随机变量生成器之
用逆变换采样方法构建随机变量生成器</a></strong></li>
<li><a href="/zh/2021/distribution-inverse-transformation-method/zh/leetcode-470-rand10.md">深入 LeetCode 470
拒绝采样，状态转移图求期望和一道经典统计求期望题目</a></li>
<li><a href="/zh/2021/distribution-inverse-transformation-method/zh/distribution-normal.md">从零构建统计随机变量生成器之
正态分布 Box-Muller方法</a></li>
</ul>
<h2 id="逆变换采样方法">逆变换采样方法</h2>
<p>Inverse Transform Method
是最基础常见的方法，可用于离散分布和连续分布。常见的分布一般都能通过此方法生成，只需要随机变量CDF的解析表达式。假设随机变量
<span class="math inline">\(X\)</span>，其CDF为 <span class="math inline">\(F^{-1}\)</span>，则 Inverse Transform Method
仅有两步</p>
<ol type="1">
<li>通过生成 [0, 1] 之间的均匀随机数 <span class="math inline">\(u\)</span></li>
<li>代入 <span class="math inline">\(F^{-1}\)</span> 即产生满足<span class="math inline">\(X\)</span>分布的实例 <span class="math inline">\(x
= F^{-1}(u)\)</span></li>
</ol>
<h3 id="离散例子">离散例子</h3>
<p>我们先举一个离散分布来直观感受一下其工作机制。有如下PMF的离散类别分布，范围在
[1, 5]。 <span class="math display">\[
P(X = 1)=\frac{1}{15}
\]</span></p>
<p><span class="math display">\[
P(X = 2)=\frac{2}{15}
\]</span></p>
<p><span class="math display">\[
P(X = 3)=\frac{1}{5}
\]</span></p>
<p><span class="math display">\[
P(X = 4)=\frac{4}{15}
\]</span></p>
<p><span class="math display">\[
P(X = 5)=\frac{1}{3}
\]</span></p>
<p>转换成CDF为</p>
<p><span class="math display">\[
P(X \leq 1)=\frac{1}{15}
\]</span></p>
<p><span class="math display">\[
P(X \leq 2)=\frac{1}{15}+\frac{2}{15}=\frac{1}{5}
\]</span></p>
<p><span class="math display">\[
P(X \leq 3)=\frac{1}{15}+\frac{2}{15}+\frac{1}{5}=\frac{6}{15}
\]</span></p>
<p><span class="math display">\[
P(X \leq
4)=\frac{1}{15}+\frac{2}{15}+\frac{1}{5}+\frac{4}{15}=\frac{2}{3}
\]</span></p>
<p><span class="math display">\[
P(X \leq
5)=\frac{1}{15}+\frac{2}{15}+\frac{1}{5}+\frac{4}{15}+\frac{1}{3}=1
\]</span></p>
<p>画出对应的CDF图</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/categorical_cdf.png">
<figcaption>
</figcaption>
</figure>
<p>那么Inverse Transformation Method 的第一步，随机生成 0-1 之间的数
u，可以直观的认为是在 y 轴上生成一个随机的点
u。注意到5段竖虚线对应了5个离散的取值，它们的长度和为1，并且每一段长度代表了每个值的权重。因此，通过在
y 轴上的均匀采样可以生成给定PMF的 x 的分布。</p>
<p>离散分布的逆变换采样方法用数学公式可以表述为：找到第一个
x，其CDF的范围包括了 u，即</p>
<p><span class="math display">\[
F^{-1}(u)=\min \{x: F(x) \geq u\}
\]</span></p>
<h3 id="扩展到连续分布">扩展到连续分布</h3>
<p>有了离散类别分布的直观感受，扩展到连续分布也就不难理解了。类似于微积分中将连续空间做离散切分，再通过极限的方法，连续光滑函数在
y 轴上可以切分成长度为 <span class="math inline">\(\Delta u\)</span>
的线段，那么生成的 x 值就是其近似值。随着 $ _{u } $，最终 $ x=F^{-1}(u)
$ 即为满足要求的分布。</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/inverse-discrete-continuous.png">
<figcaption>
</figcaption>
</figure>
<h2 id="指数分布连续">指数分布（连续）</h2>
<p>以最为常见的指数分布为例，我们来看看具体的步骤。</p>
<p>我们知道指数分布的PDF如下</p>
<div>
<p><span class="math display">\[
f(x)=\left\{\begin{array}{ll}\lambda e^{-\lambda x}, &amp; x \geq 0 \\
0, &amp; x&lt;0\end{array}\right.
\]</span></p>
</div>
<p>PDF 图为</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/distrib_exp_inv.png">
<figcaption>
</figcaption>
</figure>
<p>计算CDF为</p>
<div>
<p><span class="math display">\[
F(x)=\int_{-\infty}^{x} f(t) d t=\left\{\begin{array}{ll}1-e^{-\lambda
x}, &amp; x \geq 0 \\ 0, &amp; x&lt;0\end{array}\right.
\]</span></p>
</div>
<p>CDF 图</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/exp_cdf.jpg">
<figcaption>
</figcaption>
</figure>
<p>可以求得逆函数为</p>
<p><span class="math display">\[
x=F^{-1}(u)=-\frac{1}{\lambda} \ln (1-u)
\]</span></p>
<p>由于 1-u 在 [0, 1] 范围上的随机数等价于 u，因此，x
的生成公式等价于</p>
<p><span class="math display">\[
x=-\frac{1}{\lambda} \ln (u)
\]</span></p>
<h3 id="实现代码">实现代码</h3>
<p>对应代码很简单</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log2 <span class="hljs-keyword">as</span> ln</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">exp_gen</span>(<span class="hljs-params">lambbda: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> -ln(u) / lambbda</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/coutinous_exp_inv.py</p>
<h2 id="类别分布离散">类别分布（离散）</h2>
<p>我们再来看基于类别分布 Inverse Transformation
Method的其他离散分布例子。在<a href="/zh/2021/distribution-inverse-transformation-method/!--swig￼6--">从零构建统计随机变量生成器之离散基础篇</a>中，我们已经介绍了类别分布（Categorical
Distribution）的逆变换采样算法，同时还介绍了通过模拟 Bernoulli
实验来生成二项，几何，超几何分布的方法。在这一篇中，我们通过逆变换采样算法再来生成这些分布。</p>
<p>先回顾一下类别分布的逆变换采样实现。</p>
<p>给定如下的类别分布， $p = [0.2, 0.3, 0.1, 0.4] $</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/distrib_category.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-1">实现代码</h3>
<p>类别分布的逆变换采样实现需要找到第一个大于 u
的元素的索引序号，在我们的实现中，将 $p = [0.2, 0.3, 0.1, 0.4] $
转换成累计概率 $c = [0.2, 0.5, 0.6, 1] $ 后，由于 <span class="math inline">\(\vec c\)</span>
数组是非递减的，因此我们可以用二分法代替线性查找，将时间复杂度降到 <span class="math inline">\(O(log(n))\)</span>。下面的实现中直接调用 python
bisect 函数即可。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> bisect</span><br><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">categorical</span>(<span class="hljs-params">probs: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">abs</span>(<span class="hljs-built_in">sum</span>(probs) - <span class="hljs-number">1.0</span>) &lt; <span class="hljs-number">0.001</span></span><br><span class="line">    cum = probs.copy()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(cum)):</span><br><span class="line">        cum[i] = cum[i-<span class="hljs-number">1</span>] + probs[i]</span><br><span class="line"></span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> bisect.bisect(cum, u)</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_categorical.py</p>
<h2 id="二项分布离散">二项分布（离散）</h2>
<p>二项分布（Binomial Distribution）有两个参数 n 和
p，表示伯努利实验做n次后成功的次数。图中为 n=6，p=0.5的二项分布。</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/distrib_binomial.png">
<figcaption>
</figcaption>
</figure>
<h3 id="概率质量函数pmf">概率质量函数（PMF）</h3>
<div>
<p><span class="math display">\[
\operatorname{P}_\text{Binomial}(X=k)=\left(\begin{array}{c}n \\
k\end{array}\right)p^{k}(1- p)^{n-k}
\]</span></p>
</div>
<h3 id="实现代码-2">实现代码</h3>
<p>根据上面的PMF定义，我们将 [0, 6]
上的PMF计算出来，然后调用类别分布的逆变换采样实现即可：</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scipy.special <span class="hljs-keyword">import</span> comb</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">from</span> discrete_categorical <span class="hljs-keyword">import</span> categorical</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> <span class="hljs-built_in">pow</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">binomial</span>(<span class="hljs-params">n: <span class="hljs-built_in">int</span>, p: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    pmf = [comb(n, k, exact=<span class="hljs-literal">True</span>) * <span class="hljs-built_in">pow</span>(p, k) * <span class="hljs-built_in">pow</span>(<span class="hljs-number">1</span>-p, n-k) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n + <span class="hljs-number">1</span>)]</span><br><span class="line">    <span class="hljs-keyword">return</span> categorical(pmf)</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_binomial_inv.py</p>
<h2 id="超几何分布离散">超几何分布（离散）</h2>
<p>同样的，超几何分布（HyperGeometric Distribution）也可以如法炮制。</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/distrib_hypergeo.png">
<figcaption>
</figcaption>
</figure>
<h3 id="概率质量函数pmf-1">概率质量函数（PMF）</h3>
<div>
<p><span class="math display">\[
\operatorname{P}_\text{Hypergeo}(X=k)=\frac{\left(\begin{array}{c}K \\
k\end{array}\right)\left(\begin{array}{c}N-k \\
n-k\end{array}\right)}{\left(\begin{array}{l}N \\ n\end{array}\right)}
\]</span></p>
</div>
<h3 id="实现代码-3">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> scipy.special <span class="hljs-keyword">import</span> comb</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">from</span> discrete_categorical <span class="hljs-keyword">import</span> categorical</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hypergeometric</span>(<span class="hljs-params">N: <span class="hljs-built_in">int</span>, K_succ_num: <span class="hljs-built_in">int</span>, n_trial_num: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    pmf = [comb(K_succ_num, k, exact=<span class="hljs-literal">True</span>) * comb(N - K_succ_num, n_trial_num - k, exact=<span class="hljs-literal">True</span>) / comb(N, n_trial_num, exact=<span class="hljs-literal">True</span>)</span><br><span class="line">           <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, n_trial_num - (N - K_succ_num)), <span class="hljs-built_in">min</span>(K_succ_num, n_trial_num) + <span class="hljs-number">1</span>)]</span><br><span class="line">    <span class="hljs-keyword">return</span> categorical(pmf)</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_hypergeometric_inv.py</p>
<h2 id="几何分布离散">几何分布（离散）</h2>
<p>几何分布（Geometric
Distribution）和上面的二项分布以及超几何分布不同的是，它的 support
是所有非负整数，因此，我们无法穷举计算所有 x
的概率。但是，我们可以通过将CDF 推出 Inverse
CDF的解析表达式来直接实现。</p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/distrib_geometric.png">
<figcaption>
</figcaption>
</figure>
<h3 id="概率质量函数pmf-2">概率质量函数（PMF）</h3>
<p><span class="math display">\[
\operatorname{P}_\text{Geometric}(X=k)=(1-p)^{k-1} p
\]</span></p>
<h3 id="cdf">CDF</h3>
<p><span class="math display">\[
F_X(x) = 1- (1-p)^x
\]</span></p>
<h3 id="inverse-cdf">Inverse CDF</h3>
<p>反函数求得为 <span class="math display">\[
F^{-1}(u) = \lfloor { log(1-u) \over log(1-p) }\rfloor
\]</span></p>
<h3 id="实现代码-4">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> floor</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> log2 <span class="hljs-keyword">as</span> ln</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">geometric</span>(<span class="hljs-params">p: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> floor(ln(u) / ln(<span class="hljs-number">1</span>-p))</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_geometric_inv.py</p>
<h2 id="标准正态分布">标准正态分布</h2>
<p>一般，标准正态分布用Box-Muller
方法来生成，这个后续将做详细介绍。这里我们用 Schmeiser 提出的基于Inverse
Transformation Method的近似方法来生成：</p>
<p><span class="math display">\[
X=F^{-1}(u) \approx \frac{u^{0.135}-(1-u)^{0.135}}{0.1975}
\]</span></p>
<figure>
<img src="/zh/2021/distribution-inverse-transformation-method/distrib_normal.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-5">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">normal</span>():</span></span><br><span class="line">    <span class="hljs-keyword">import</span> math</span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> (math.<span class="hljs-built_in">pow</span>(u, <span class="hljs-number">0.135</span>) - math.<span class="hljs-built_in">pow</span>(<span class="hljs-number">1</span>-u, <span class="hljs-number">0.135</span>)) / <span class="hljs-number">0.1975</span></span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/coutinous_normal_apprx.py</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/distribution-poisson/" itemprop="url">从零构建统计随机变量生成器之泊松分布</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-01-29T18:45:01.000Z" itemprop="datePublished">1月 30 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            1 分钟 读完 (约 172 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>http://www.columbia.edu/~ks20/4404-Sigman/4404-Notes-ITM.pdf</p>
<p>https://www.win.tue.nl/~marko/2WB05/lecture8.pdf</p>
<h2 id="泊松分布">泊松分布</h2>
<figure>
<img src="/zh/2021/distribution-poisson/distrib_poisson.png">
<figcaption>
</figcaption>
</figure>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> exp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">poisson</span>(<span class="hljs-params">lambdda: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    total = <span class="hljs-number">1.0</span></span><br><span class="line">    i = <span class="hljs-number">0</span></span><br><span class="line">    threshold = exp(-<span class="hljs-number">1</span> * lambdda)</span><br><span class="line">    <span class="hljs-keyword">while</span> total &gt;= threshold:</span><br><span class="line">        u = random.random()</span><br><span class="line">        total *= u</span><br><span class="line">        i += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> i - <span class="hljs-number">1</span></span><br></pre></td></tr></tbody></table></figure>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_poisson_inv.py</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> numpy.random <span class="hljs-keyword">import</span> exponential</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">poisson</span>(<span class="hljs-params">lambdda: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    total = <span class="hljs-number">0.0</span></span><br><span class="line">    i = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> total &lt;= lambdda:</span><br><span class="line">        y = exponential(<span class="hljs-number">1</span>)</span><br><span class="line">        total += y</span><br><span class="line">        i += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> i - <span class="hljs-number">1</span></span><br></pre></td></tr></tbody></table></figure>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_poisson_from_exp.py</p>
<h2 id="泊松分布-1">泊松分布</h2>
<figure>
<img src="/zh/2021/distribution-poisson/distrib_poisson.png">
<figcaption>
</figcaption>
</figure>
<p>$ E_{1}, E_{2}, E_{3}, (1) $</p>
<p><span class="math display">\[
\mathbb{P}(K \geqslant k)=\mathbb{P}\left(E_{1}+\cdots+E_{k} \leqslant
\lambda\right)
\]</span></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> numpy.random <span class="hljs-keyword">import</span> exponential</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">poisson</span>(<span class="hljs-params">lambdda: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    total = <span class="hljs-number">0.0</span></span><br><span class="line">    i = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> total &lt;= lambdda:</span><br><span class="line">        y = exponential(<span class="hljs-number">1</span>)</span><br><span class="line">        total += y</span><br><span class="line">        i += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> i - <span class="hljs-number">1</span></span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_poisson_from_exp.py</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-policy-gradient/" itemprop="url">深度强化学习之：Policy Gradient Theorem 一些理解</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-12-11T18:45:01.000Z" itemprop="datePublished">12月 12 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            17 分钟 读完 (约 2538 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>Policy gradient
定理作为现代深度强化学习的基石，同时也是actor-critic的基础，重要性不言而喻。但是它的推导和理解不是那么浅显，不同的资料中又有着众多形式，不禁令人困惑。本篇文章MyEncyclopedia试图总结众多资料背后的一些相通的地方，并写下自己的一些学习理解心得。</p>
<h2 id="引入-policy-gradient">引入 Policy Gradient</h2>
Policy gradient 引入的目的是若我们将策略 <span class="math inline">\(\pi_{\theta}\)</span> 的参数 <span class="math inline">\(\theta\)</span> 直接和一个标量 <span class="math inline">\(J\)</span>
直接联系在一起的话，就能够利用目前最流行的深度学习自动求导的方法，迭代地去找到
<span class="math inline">\(\theta^*\)</span> 来最大化 <span class="math inline">\(J\)</span>：
<div>
<p><span class="math display">\[
\theta^{\star}=\arg \max _{\theta} J(\theta)
\]</span></p>
</div>
<div>
<p><span class="math display">\[
{\theta}_{t+1} \doteq {\theta}_{t}+\alpha \nabla J(\theta)
\]</span></p>
</div>
此时，训练神经网络成功地收敛到 <span class="math inline">\(\theta^{*}\)</span> 时可以直接给出任意一个状态 s
的动作分布。
<figure>
<img src="/zh/2020/rl-policy-gradient/policy_net.png">
<figcaption>
</figcaption>
</figure>
<p>那么问题来了，首先一个如何定义 <span class="math inline">\(J(\theta)\)</span>，其次，如何求出或者估计 $
J()$。</p>
<p>第一个问题比较直白，用value function或者广义的expected
return都可以。</p>
<p>这里列举一些常见的定义。对于episodic 并且初始都是 <span class="math inline">\(s_0\)</span>状态的情况，直接定义成v值，即Sutton教程中的episodic情况下的定义</p>
<div>
<p><span class="math display">\[
J(\boldsymbol{\theta}) \doteq
v_{\pi_{\boldsymbol{\theta}}}\left(s_{0}\right)  \quad \quad
\text{(1.1)}
\]</span></p>
</div>
进一步，上式等价于 <span class="math inline">\(V(s)\)</span>
在状态平稳分布下的均值。
<div>
<p><span class="math display">\[
\begin{aligned}
J(\theta) &amp;= \sum_{s \in \mathcal{S}} d^{\pi}(s) V^{\pi}(s) \\
&amp;=\sum_{s \in \mathcal{S}} d^{\pi}(s) \sum_{a \in \mathcal{A}}
\pi_{\theta}(a \mid s) Q^{\pi}(s, a)
\end{aligned} \quad \quad \text{(1.2)}
\]</span></p>
</div>
<p>其中，状态平稳分布 <span class="math inline">\(d^{\pi}(s)\)</span>
定义为</p>
<div>
<p><span class="math display">\[
d^{\pi}(s)=\lim _{t \rightarrow \infty} P\left(s_{t}=s \mid s_{0},
\pi_{\theta}\right)
\]</span></p>
</div>
另一种定义从trajectory角度出发，公式如下：
<div>
<p><span class="math display">\[
J(\boldsymbol{\theta}) \doteq E_{\tau \sim
p_{\theta}(\tau)}\left[\sum_{t} r\left(\mathbf{s}_{t},
\mathbf{a}_{t}\right)\right] \quad \quad \text{(1.3)}
\]</span></p>
</div>
<p>即$ $ 是一次trajectory，服从以 <span class="math inline">\(\theta\)</span> 作为参数的随机变量</p>
<div>
<p><span class="math display">\[
\tau \sim p_{\theta}\left(\mathbf{s}_{1}, \mathbf{a}_{1}, \ldots,
\mathbf{s}_{T}, \mathbf{a}_{T}\right)
\]</span></p>
</div>
<p><span class="math inline">\(J(\theta)\)</span> 对于所有的可能的 <span class="math inline">\(\tau\)</span> 求 expected
return。这种视角下对于finite 和 infinite horizon来说也有变形。</p>
Infinite horizon 情况下，通过 <span class="math inline">\((s,
a)\)</span> 的marginal distribution来计算
<div>
<p><span class="math display">\[
J(\boldsymbol{\theta}) \doteq E_{(\mathbf{s}, \mathbf{a}) \sim
p_{\theta}(\mathbf{s}, \mathbf{a})}[r(\mathbf{s}, \mathbf{a})] \quad
\quad \text{(1.4)}
\]</span></p>
</div>
Finite horizon 情况下，通过每一时刻下 <span class="math inline">\((s_t,
a_t)\)</span> 的marginal distribution来计算
<div>
<p><span class="math display">\[
J(\boldsymbol{\theta}) \doteq \sum_{t=1}^{T} E_{\left(\mathbf{s}_{t},
\mathbf{a}_{t}\right) \sim p_{\theta}\left(\mathbf{s}_{t},
\mathbf{a}_{t}\right)} \quad \quad \text{(1.5)}
\]</span></p>
</div>
关于第二个问题，如何求出或者估计 $ J()$ 就是 policy gradient theorem
的主题了。仔细想想确实会有一些问题。一是 reward 随机变量 <span class="math inline">\(R(s, a)\)</span> 是离散情况下 $ J()$
还是否存在，再是 <span class="math inline">\(J(\theta)\)</span>
不仅取决于agent 主观的 <span class="math inline">\(\pi_{\theta}\)</span>，还取决于环境客观的dynamics
model
<div>
<p><span class="math display">\[
p\left(s^{\prime}, r \mid s, a\right) =
\operatorname{Pr}\left\{S_{t}=s^{\prime}, R_{t}=r \mid S_{t-1}=s,
A_{t-1}=a\right\}
\]</span></p>
</div>
<p>当环境dynamics未知时，如何再去求 $ J()$
呢。还有就是如果涉及到状态的分布也是取决于环境dynamics的，计算 $ J()$
也面临同样的问题。</p>
<p>幸好，policy
gradient定理完美的解答了上述问题。我们先来看看它的表述内容。</p>
<h2 id="policy-gradient-theorem">Policy Gradient Theorem</h2>
策略梯度定理证明了，无论定义何种 <span class="math inline">\(J(\theta)\)</span> ，策略梯度等比于下式，其中
<span class="math inline">\(\mu(s)\)</span> 为 <span class="math inline">\(\pi_{\theta}\)</span>
下的状态分布。等比系数在episodic情况下为episode的平均长度，在infinite
horizon情况下为1。
<div>
<p><span class="math display">\[
\nabla J(\boldsymbol{\theta}) \propto \sum_{s} \mu(s) \sum_{a}
q_{\pi}(s, a) \nabla \pi(a \mid s, \boldsymbol{\theta}) \quad \quad
\text{(2.1)}
\]</span></p>
</div>
考虑到系数可以包含在步长 <span class="math inline">\(\alpha\)</span>
中， <span class="math inline">\(\mu(s)\)</span> 是on policy <span class="math inline">\(\pi_{\theta}\)</span> 的权重，<span class="math inline">\(\nabla J(\theta)\)</span>
也可以写成期望形式的等式，注意，下式中 <span class="math inline">\(S_t\)</span> 从具体 <span class="math inline">\(s\)</span> 变成了随机变量，随机概率部分移到了
<span class="math inline">\(\mathbb{E}_{\pi}\)</span>中了。
<div>
<p><span class="math display">\[
\nabla J(\boldsymbol{\theta}) =\mathbb{E}_{\pi}\left[\sum_{a}
q_{\pi}\left(S_{t}, a\right) \nabla \pi\left(a \mid S_{t},
\boldsymbol{\theta}\right)\right]  \quad \quad \text{(2.2)}
\]</span></p>
</div>
<p>Policy Gradient 定理的伟大之处在于等式右边并没有 <span class="math inline">\(d^{\pi}(s)\)</span>，或者环境transition model
<span class="math inline">\(p\left(s^{\prime}, r \mid s,
a\right)\)</span>！同时，等式右边变换成了最利于统计采样的期望形式，因为期望可以通过样本的平均来估算。</p>
<p>但是，这里必须注意的是action space的期望并不是基于 $(a S_{t}, ) $
的权重的，因此，继续改变形式，引入 action space的 on policy 权重 $(a
S_{t}, ) $ ，得到 2.3式。</p>
<div>
<p><span class="math display">\[
\nabla J(\boldsymbol{\theta})=\mathbb{E}_{\pi}\left[\sum_{a} \pi\left(a
\mid S_{t}, \boldsymbol{\theta}\right) q_{\pi}\left(S_{t}, a\right)
\frac{\nabla \pi\left(a \mid S_{t},
\boldsymbol{\theta}\right)}{\pi\left(a \mid S_{t},
\boldsymbol{\theta}\right)}\right] \quad \quad \text{(2.3)}
\]</span></p>
</div>
将 <span class="math inline">\(a\)</span> 替换成 $A_{t} $，得到2.4式
<div>
<p><span class="math display">\[
\nabla J(\boldsymbol{\theta})==\mathbb{E}_{\pi}\left[q_{\pi}\left(S_{t},
A_{t}\right) \frac{\nabla \pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}\right)}{\pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}\right)}\right]  \quad \quad \text{(2.4)}
\]</span></p>
</div>
<p>将 <span class="math inline">\(q_{\pi}\)</span>替换成 <span class="math inline">\(G_t\)</span>，由于</p>
<div>
<p><span class="math display">\[
\mathbb{E}_{\pi}[G_{t} \mid S_{t}, A_{t}]= q_{\pi}\left(S_{t},
A_{t}\right)
\]</span></p>
</div>
<p>得到2.5式</p>
<div>
<p><span class="math display">\[
\nabla J(\boldsymbol{\theta})==\mathbb{E}_{\pi}\left[G_{t} \frac{\nabla
\pi\left(A_{t} \mid S_{t}, \boldsymbol{\theta}\right)}{\pi\left(A_{t}
\mid S_{t}, \boldsymbol{\theta}\right)}\right]  \quad \quad \text{(2.5)}
\]</span></p>
</div>
至此，action 和 state space的权重都源自 <span class="math inline">\(\pi_{\theta}\)</span>，期望内的随机变量可以通过
<span class="math inline">\(\pi_{\theta}\)</span> 在每一时间 t
采样来无偏估计，这便是大名鼎鼎的 REINFORCE 算法，即Monte Carlo Policy
Gradient。
<div>
<p><span class="math display">\[
\nabla J(\boldsymbol{\theta}) \approx G_{t} \frac{\nabla \pi\left(A_{t}
\mid S_{t}, \boldsymbol{\theta}\right)}{\pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}\right)} \quad \quad \text{(2.6)}
\]</span></p>
</div>
此时，<span class="math inline">\(\theta\)</span> 迭代更新公式为
<div>
<p><span class="math display">\[
\boldsymbol{\theta}_{t+1} \doteq \boldsymbol{\theta}_{t}+\alpha G_{t}
\frac{\nabla \pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}{\pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}  \quad \quad \text{(2.7)}
\]</span></p>
</div>
下面是REINFORCE算法完整流程
<figure>
<img src="/zh/2020/rl-policy-gradient/reinforce.png">
<figcaption>
</figcaption>
</figure>
<h2 id="policy-gradient-theorem---trajectory-form">Policy Gradient
Theorem - Trajectory Form</h2>
Trajectory 形式的策略梯度定理也很常见，这里也总结一下，回顾 1.3 式 <span class="math inline">\(J(\theta)\)</span>的定义
<div>
<p><span class="math display">\[
J(\boldsymbol{\theta}) \doteq E_{\tau \sim
p_{\theta}(\tau)}\left[\sum_{t} r\left(\mathbf{s}_{t},
\mathbf{a}_{t}\right)\right] \quad \quad \text{(1.3)}
\]</span></p>
</div>
最后可以证明出
<div>
<p><span class="math display">\[
\nabla_{\theta} J\left(\pi_{\theta}\right)=\underset{\tau \sim
\pi_{\theta}}{\mathrm{E}}\left[\sum_{t=0}^{T} \nabla_{\theta} \log
\pi_{\theta}\left(a_{t} \mid s_{t}\right) R(\tau)\right] \quad \quad
\text{(3.1)}
\]</span></p>
</div>
3.1式中每一时刻 t 中依赖全时刻的 <span class="math inline">\(R(\tau)\)</span> ，进一步优化可以证明，时刻 t
只依赖于后续reward sum，即 reward-to-go， $ _{t}$
<div>
<p><span class="math display">\[
\hat{R}_{t} \doteq \sum_{t^{\prime}=t}^{T} R\left(s_{t^{\prime}},
a_{t^{\prime}}, s_{t^{\prime}+1}\right)
\]</span></p>
</div>
最终的策略梯度定理的形式为：
<div>
<p><span class="math display">\[
\nabla_{\theta} J\left(\pi_{\theta}\right)=\underset{\tau \sim
\pi_{\theta}}{\mathrm{E}}\left[\sum_{t=0}^{T} \nabla_{\theta} \log
\pi_{\theta}\left(a_{t} \mid s_{t}\right) \hat{R}_{t} \right] \quad
\quad \text{(3.2)}
\]</span></p>
</div>
由于 log-derivative trick的存在，3.2式和2.5式（Sutton 教程中的policy
gradient）等价。
<div>
<p><span class="math display">\[
\nabla_{\theta} \log \pi_{\theta}(a)=\frac{\nabla_{\theta}
\pi_{\theta}}{\pi_{\theta}} \quad \quad \text{(3.3)}
\]</span></p>
</div>
<h2 id="和监督学习的联系">和监督学习的联系</h2>
<p>Policy Gradient中的 <span class="math inline">\(\nabla_{\theta} \log
\pi\)</span> 广泛存在在机器学习范畴中，被称为 score function gradient
estimator。RL 在supervised learning settings 中有 imitation
learning，即通过专家的较优stochastic policy <span class="math inline">\(\pi_{\theta}(a|s)\)</span> 收集数据集</p>
<div>
<p><span class="math display">\[
\{(s_1, a^{*}_1), (s_2, a^{*}_2), ...\}
\]</span></p>
</div>
算法有监督的学习去找到max log likelyhook 的 <span class="math inline">\(\theta^{*}\)</span>
<div>
<p><span class="math display">\[
\theta^{*}=\operatorname{argmax}_{\theta} \sum_{n} \log
\pi_{\theta}\left(a_{n}^{*} \mid s_{n}\right) \quad \quad \text{(4.1)}
\]</span></p>
</div>
此时，参数迭代公式为
<div>
<p><span class="math display">\[
\theta_{n+1} \leftarrow \theta_{n}+\alpha_{n} \nabla_{\theta} \log
\pi_{\theta}\left(a_{n}^{*} \mid s_{n}\right) \quad \quad \text{(4.2)}
\]</span></p>
</div>
<p>对照Policy Graident RL，on-policy <span class="math inline">\(\pi_{\theta}(a|s)\)</span> 产生数据集</p>
<div>
<p><span class="math display">\[
\{(s_1, a_1, r_1), (s_2, a_2, r_2), ...\}
\]</span></p>
</div>
<p>目标是最大化on-policy <span class="math inline">\(\pi_{\theta}\)</span> 分布下的expected return</p>
<div>
<p><span class="math display">\[
\theta^{*}=\operatorname{argmax}_{\theta} \sum_{n} R(\tau_{n})
\]</span></p>
</div>
对照2.7式 <span class="math inline">\(\theta\)</span>
的更新公式，2.7式可以写成如下4.3式
<div>
<p><span class="math display">\[
\theta_{n+1} \leftarrow \theta_{n}+\alpha_{n}  G_{n} \nabla_{\theta}
\log \pi_{\theta}\left(a_{n} \mid s_{n}\right) \quad \quad \text{(4.3)}
\]</span></p>
</div>
<p>对比 4.3 和 4.2，发现此时4.3中只多了一个权重系数 <span class="math inline">\(G_n\)</span>。</p>
<p>关于 $G_{n} <em>{} </em>{}(a_{n} s_{n}) $ 或者 <span class="math inline">\(G_{t} \frac{\nabla \pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}{\pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}\)</span> 有一些深入的理解。</p>
首先policy gradient RL 不像supervised imitation learning直接有label
作为signal，PG
RL必须通过采样不同的action获得reward或者return作为signal，即1.4式中的
<div>
<p><span class="math display">\[
E_{(\mathbf{s}, \mathbf{a}) \sim p_{\theta}(\mathbf{s},
\mathbf{a})}[r(\mathbf{s}, \mathbf{a})] \quad \quad \text{(5.1)}
\]</span></p>
</div>
广义的score function gradient estimator
对于形式为5.2的函数期望求gradient。对比上式，PG RL ， <span class="math inline">\(f(x)\)</span>视为reward 随机变量，期望是under
on-policy <span class="math inline">\(\pi_{\theta}\)</span>。
<div>
<p><span class="math display">\[
E_{x \sim p(x \mid \theta)}[f(x)] \quad \quad \text{(5.2)}
\]</span></p>
</div>
以下是score function gradient
estimator的推导，这里不做赘述，主要利用了3.3式的 log-derivative trick。
<div>
<p><span class="math display">\[
\begin{aligned} \nabla_{\theta} E_{x}[f(x)] &amp;=\nabla_{\theta}
\sum_{x} p(x) f(x) \\ &amp;=\sum_{x} \nabla_{\theta} p(x) f(x) \\
&amp;=\sum_{x} p(x) \frac{\nabla_{\theta} p(x)}{p(x)} f(x) \\
&amp;=\sum_{x} p(x) \nabla_{\theta} \log p(x) f(x) \\
&amp;=E_{x}\left[f(x) \nabla_{\theta} \log p(x)\right] \end{aligned}
\quad \quad \text{(5.3)}
\]</span></p>
</div>
<p>Policy Gradient 工作的机制大致如下</p>
<p>首先，根据现有的 on-policy <span class="math inline">\(\pi_{\theta}\)</span> 采样出一些动作 action
产生trajectories，这些trajectories最终得到反馈 <span class="math inline">\(R(\tau)\)</span></p>
<figure>
<img src="/zh/2020/rl-policy-gradient/pg_sample.png">
<figcaption>
</figcaption>
</figure>
用采样到的数据通过R加权来代替imitation learning的labeled loss
<div>
<p><span class="math display">\[
R(s,a) \nabla \pi_{\theta_{t}}(a \mid s) \approx \nabla
\pi_{\theta_{t}}(a^{*} \mid s)
\]</span></p>
</div>
<p>最后，由于采样到的action分布服从于<span class="math inline">\(a \sim
\pi_{\theta}(a)\)</span> ，除掉 <span class="math inline">\(\pi_{\theta}\)</span> ：</p>
<p><span class="math inline">\(G_{t} \frac{\nabla \pi\left(A_{t} \mid
S_{t}, \boldsymbol{\theta}_{t}\right)}{\pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}\)</span></p>
<p>此时，采样的均值可以去无偏估计2.2式中的Expectation。</p>
<div>
<p><span class="math display">\[
\sum_N G_{t} \frac{\nabla \pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}{\pi\left(A_{t} \mid S_{t},
\boldsymbol{\theta}_{t}\right)}
\]</span></p>
</div>
<div>
<p><span class="math display">\[
=\mathbb{E}_{\pi}\left[\sum_{a} q_{\pi}\left(S_{t}, a\right) \nabla
\pi\left(a \mid S_{t}, \boldsymbol{\theta}\right)\right]
\]</span></p>
</div>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-dqn-mario/" itemprop="url">深度强化学习之：DQN训练超级玛丽闯关</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-12-04T18:45:01.000Z" itemprop="datePublished">12月 5 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 分钟 读完 (约 1743 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>上一期 MyEncyclopedia公众号文章 <a href="/zh/2020/rl-dqn-mario/!--swig￼9--">从Q-Learning
演化到
DQN</a>，我们从原理上讲解了DQN算法，这一期，让我们通过代码来实现任天堂游戏机中经典的超级玛丽的自动通关吧。本文所有代码在
https://github.com/MyEncyclopedia/reinforcement-learning-2nd/tree/master/super_mario。</p>
<h2 id="dqn-算法回顾">DQN 算法回顾</h2>
<p>上期详细讲解了DQN中的两个重要的技术：Target Network 和 Experience
Replay，正是有了它们才使得 Deep Q
Network在实战中容易收敛，以下是Deepmind 发表在Nature 的 Human-level
control through deep reinforcement learning 的完整算法流程。</p>
<figure>
<img src="/zh/2020/rl-dqn-mario/dqn_alg_nature.png">
<figcaption>
</figcaption>
</figure>
<h2 id="超级玛丽-nes-openai-环境">超级玛丽 NES OpenAI 环境</h2>
<p>安装基于OpenAI gym的超级玛丽环境执行下面的 pip 命令即可。</p>
<figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gym-super-mario-bros</span><br></pre></td></tr></tbody></table></figure>
<p>我们先来看一下游戏环境的输入和输出。下面代码采用随机的action来和游戏交互。有了
<a href="/zh/2020/rl-dqn-mario/!--swig￼10--">组合游戏系列3: 井字棋、五子棋的OpenAI Gym
GUI环境</a> 对于OpenAI Gym
接口的介绍，现在对于其基本的交互步骤已经不陌生了。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> gym_super_mario_bros</span><br><span class="line"><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> random, randrange</span><br><span class="line"><span class="hljs-keyword">from</span> gym_super_mario_bros.actions <span class="hljs-keyword">import</span> RIGHT_ONLY</span><br><span class="line"><span class="hljs-keyword">from</span> nes_py.wrappers <span class="hljs-keyword">import</span> JoypadSpace</span><br><span class="line"><span class="hljs-keyword">from</span> gym <span class="hljs-keyword">import</span> wrappers</span><br><span class="line"></span><br><span class="line">env = gym_super_mario_bros.make(<span class="hljs-string">'SuperMarioBros-v0'</span>)</span><br><span class="line">env = JoypadSpace(env, RIGHT_ONLY)</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment"># Play randomly</span></span><br><span class="line">done = <span class="hljs-literal">False</span></span><br><span class="line">env.reset()</span><br><span class="line"></span><br><span class="line">step = <span class="hljs-number">0</span></span><br><span class="line"><span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:</span><br><span class="line">    action = randrange(<span class="hljs-built_in">len</span>(RIGHT_ONLY))</span><br><span class="line">    state, reward, done, info = env.step(action)</span><br><span class="line">    <span class="hljs-built_in">print</span>(done, step, info)</span><br><span class="line">    env.render()</span><br><span class="line">    step += <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line">env.close()</span><br></pre></td></tr></tbody></table></figure>
<p>游戏render效果如下</p>
<p>。。。</p>
<p>注意我们在游戏环境初始化的时候用了参数
RIGHT_ONLY，它定义成五种动作的list，表示仅使用右键的一些组合，适用于快速训练来完成Mario第一关。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">RIGHT_ONLY = [</span><br><span class="line">    [<span class="hljs-string">'NOOP'</span>],</span><br><span class="line">    [<span class="hljs-string">'right'</span>],</span><br><span class="line">    [<span class="hljs-string">'right'</span>, <span class="hljs-string">'A'</span>],</span><br><span class="line">    [<span class="hljs-string">'right'</span>, <span class="hljs-string">'B'</span>],</span><br><span class="line">    [<span class="hljs-string">'right'</span>, <span class="hljs-string">'A'</span>, <span class="hljs-string">'B'</span>],</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure>
<p>观察一些 info 输出内容，coins表示金币获得数量，flag_get
表示是否取得最后的旗子，time 剩余时间，以及 Mario 大小状态和所在的
x，y位置。 </p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">   "coins":0,</span><br><span class="line">   "flag_get":False,</span><br><span class="line">   "life":2,</span><br><span class="line">   "score":0,</span><br><span class="line">   "stage":1,</span><br><span class="line">   "status":"small",</span><br><span class="line">   "time":381,</span><br><span class="line">   "world":1,</span><br><span class="line">   "x_pos":594,</span><br><span class="line">   "y_pos":89</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="游戏图像处理">游戏图像处理</h2>
<p>Deep Reinforcement Learning 一般是 end-to-end learning，意味着游戏的
screen image
作为observation直接视为真实状态，喂给神经网络训练。于此相反的另一种做法是，通过游戏环境拿到内部状态，例如所有相关物品的位置和属性作为模型输入。这两种方式的区别有两点。第一点，用观察到的屏幕像素代替真正的状态
s，在partially observable 的环境时可能因为 non-stationarity
导致无法很好的工作，而拿内部状态利用了额外的作弊信息，在partially
observable环境中也可以工作。第二点，第一种方式屏幕像素维度比较高，输入数据量大，需要神经网络的大量训练拟合，第二种方式，内部真实状态往往维度低得多，训练起来很快，但缺点是因为除了内部状态往往还需要游戏相关规则作为输入，因此generalization能力不如前者强。</p>
<figure>
<img src="/zh/2020/rl-dqn-mario/dqn.jpg">
<figcaption>
</figcaption>
</figure>
<p>这里，我们当然采样屏幕像素的 end-to-end
方式了，自然首要任务是将游戏帧图像有效处理。超级玛丽游戏环境的屏幕输出是
(240, 256, 3) shape的 numpy
array，通过下面一系列的转换，尽可能的在不影响训练效果的情况下减小采样到的数据量。</p>
<ol type="1">
<li><p>MaxAndSkipFrameWrapper：每4个frame连在一起，采取同样的动作，降低frame数量。</p></li>
<li><p>FrameDownsampleWrapper：将原始的 (240, 256, 3) down sample 到
(84, 84, 1)</p></li>
<li><p>ImageToPyTorchWrapper：转换成适合 pytorch 的 (1, 84, 84)
shape</p></li>
<li><p>FrameBufferWrapper：保存最后4次屏幕采样</p></li>
<li><p>NormalizeFloats：Normalize 成 [0., 1.0] 的浮点值</p></li>
</ol>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wrap_environment</span>(<span class="hljs-params">env_name: <span class="hljs-built_in">str</span>, action_space: <span class="hljs-built_in">list</span></span>) -&gt; Wrapper:</span></span><br><span class="line">    env = make(env_name)</span><br><span class="line">    env = JoypadSpace(env, action_space)</span><br><span class="line">    env = MaxAndSkipFrameWrapper(env)</span><br><span class="line">    env = FrameDownsampleWrapper(env)</span><br><span class="line">    env = ImageToPyTorchWrapper(env)</span><br><span class="line">    env = FrameBufferWrapper(env, <span class="hljs-number">4</span>)</span><br><span class="line">    env = NormalizeFloats(env)</span><br><span class="line">    <span class="hljs-keyword">return</span> env</span><br></pre></td></tr></tbody></table></figure>
<h2 id="cnn-模型">CNN 模型</h2>
<p>模型比较简单，三个卷积层后做
softmax输出，输出维度数为离散动作数。act() 采用了epsilon-greedy
模式，即在epsilon小概率时采取随机动作来
explore，大于epsilon时采取估计的最可能动作来 exploit。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DQNModel</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, input_shape, num_actions</span>):</span></span><br><span class="line">        <span class="hljs-built_in">super</span>(DQNModel, self).__init__()</span><br><span class="line">        self._input_shape = input_shape</span><br><span class="line">        self._num_actions = num_actions</span><br><span class="line"></span><br><span class="line">        self.features = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_shape[<span class="hljs-number">0</span>], <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">8</span>, stride=<span class="hljs-number">4</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(self.feature_size, <span class="hljs-number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="hljs-number">512</span>, num_actions)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span></span><br><span class="line">        x = self.features(x).view(x.size()[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)</span><br><span class="line">        <span class="hljs-keyword">return</span> self.fc(x)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">act</span>(<span class="hljs-params">self, state, epsilon, device</span>):</span></span><br><span class="line">        <span class="hljs-keyword">if</span> random() &gt; epsilon:</span><br><span class="line">            state = torch.FloatTensor(np.float32(state)).unsqueeze(<span class="hljs-number">0</span>).to(device)</span><br><span class="line">            q_value = self.forward(state)</span><br><span class="line">            action = q_value.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].item()</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            action = randrange(self._num_actions)</span><br><span class="line">        <span class="hljs-keyword">return</span> action</span><br></pre></td></tr></tbody></table></figure>
<h2 id="experience-replay-缓存">Experience Replay 缓存</h2>
<p>实现采用了 Pytorch CartPole DQN 的官方代码，本质是一个最大为 capacity
的 list 保存采样的 (s, a, r, s', is_done) 五元组。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Transition = namedtuple(<span class="hljs-string">'Transition'</span>, (<span class="hljs-string">'state'</span>, <span class="hljs-string">'action'</span>, <span class="hljs-string">'reward'</span>, <span class="hljs-string">'next_state'</span>, <span class="hljs-string">'done'</span>))</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ReplayMemory</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, capacity</span>):</span></span><br><span class="line">        self.capacity = capacity</span><br><span class="line">        self.memory = []</span><br><span class="line">        self.position = <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">push</span>(<span class="hljs-params">self, *args</span>):</span></span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.memory) &lt; self.capacity:</span><br><span class="line">            self.memory.append(<span class="hljs-literal">None</span>)</span><br><span class="line">        self.memory[self.position] = Transition(*args)</span><br><span class="line">        self.position = (self.position + <span class="hljs-number">1</span>) % self.capacity</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample</span>(<span class="hljs-params">self, batch_size</span>):</span></span><br><span class="line">        <span class="hljs-keyword">return</span> random.sample(self.memory, batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.memory)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="dqnagent">DQNAgent</h2>
<p>我们将 DQN 的逻辑封装在 DQNAgent 类中。DQNAgent 成员变量包括两个
DQNModel，一个ReplayMemory。</p>
<p>train() 方法中会每隔一定时间将 Target Network
的参数同步成现行Network的参数。在td_loss_backprop()方法中采样
ReplayMemory 中的五元组，通过minimize TD error方式来改进现行 Network
参数 <span class="math inline">\(\theta\)</span>。Loss函数为：</p>
<p><span class="math display">\[
L\left(\theta_{i}\right)=\mathbb{E}_{\left(s, a, r, s^{\prime}\right)
\sim \mathrm{U}(D)}\left[\left(r+\gamma \max _{a^{\prime}}
Q_{target}\left(s^{\prime}, a^{\prime} ; \theta_{i}^{-}\right)-Q\left(s,
a ; \theta_{i}\right)\right)^{2}\right]
\]</span></p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DQNAgent</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">act</span>(<span class="hljs-params">self, state, episode_idx</span>):</span></span><br><span class="line">        self.update_epsilon(episode_idx)</span><br><span class="line">        action = self.model.act(state, self.epsilon, self.device)</span><br><span class="line">        <span class="hljs-keyword">return</span> action</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process</span>(<span class="hljs-params">self, episode_idx, state, action, reward, next_state, done</span>):</span></span><br><span class="line">        self.replay_mem.push(state, action, reward, next_state, done)</span><br><span class="line">        self.train(episode_idx)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">self, episode_idx</span>):</span></span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.replay_mem) &gt; self.initial_learning:</span><br><span class="line">            <span class="hljs-keyword">if</span> episode_idx % self.target_update_frequency == <span class="hljs-number">0</span>:</span><br><span class="line">                self.target_model.load_state_dict(self.model.state_dict())</span><br><span class="line">            self.optimizer.zero_grad()</span><br><span class="line">            self.td_loss_backprop()</span><br><span class="line">            self.optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">td_loss_backprop</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        transitions = self.replay_mem.sample(self.batch_size)</span><br><span class="line">        batch = Transition(*<span class="hljs-built_in">zip</span>(*transitions))</span><br><span class="line"></span><br><span class="line">        state = Variable(FloatTensor(np.float32(batch.state))).to(self.device)</span><br><span class="line">        action = Variable(LongTensor(batch.action)).to(self.device)</span><br><span class="line">        reward = Variable(FloatTensor(batch.reward)).to(self.device)</span><br><span class="line">        next_state = Variable(FloatTensor(np.float32(batch.next_state))).to(self.device)</span><br><span class="line">        done = Variable(FloatTensor(batch.done)).to(self.device)</span><br><span class="line"></span><br><span class="line">        q_values = self.model(state)</span><br><span class="line">        next_q_values = self.target_net(next_state)</span><br><span class="line"></span><br><span class="line">        q_value = q_values.gather(<span class="hljs-number">1</span>, action.unsqueeze(-<span class="hljs-number">1</span>)).squeeze(-<span class="hljs-number">1</span>)</span><br><span class="line">        next_q_value = next_q_values.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]</span><br><span class="line">        expected_q_value = reward + self.gamma * next_q_value * (<span class="hljs-number">1</span> - done)</span><br><span class="line"></span><br><span class="line">        loss = (q_value - expected_q_value.detach()).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>)</span><br><span class="line">        loss = loss.mean()</span><br><span class="line">        loss.backward()</span><br></pre></td></tr></tbody></table></figure>
<h2 id="外层-training-代码">外层 Training 代码</h2>
<p>最后是外层调用代码，基本和以前文章一样。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">env, args, agent</span>):</span></span><br><span class="line">    <span class="hljs-keyword">for</span> episode_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(args.num_episodes):</span><br><span class="line">        episode_reward = <span class="hljs-number">0.0</span></span><br><span class="line">        state = env.reset()</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">            action = agent.act(state, episode_idx)</span><br><span class="line">            <span class="hljs-keyword">if</span> args.render:</span><br><span class="line">                env.render()</span><br><span class="line">            next_state, reward, done, stats = env.step(action)</span><br><span class="line">            agent.process(episode_idx, state, action, reward, next_state, done)</span><br><span class="line">            state = next_state</span><br><span class="line">            episode_reward += reward</span><br><span class="line">            <span class="hljs-keyword">if</span> done:</span><br><span class="line">                <span class="hljs-built_in">print</span>(<span class="hljs-string">f'<span class="hljs-subst">{episode_idx}</span>: <span class="hljs-subst">{episode_reward}</span>'</span>)</span><br><span class="line">                <span class="hljs-keyword">break</span></span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
    
        
<nav class="pagination is-centered is-rounded" role="navigation" aria-label="pagination">
    <div class="pagination-previous is-invisible is-hidden-mobile">
        <a href="/tags/Python/page/0/">上一页</a>
    </div>
    <div class="pagination-next">
        <a href="/tags/Python/page/2/">下一页</a>
    </div>
    <ul class="pagination-list is-hidden-mobile">
        
        <li><a class="pagination-link is-current" href="/tags/Python/">1</a></li>
        
        <li><a class="pagination-link" href="/tags/Python/page/2/">2</a></li>
        
        <li><a class="pagination-link" href="/tags/Python/page/3/">3</a></li>
        
    </ul>
</nav>
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 MyEncyclopedia&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true" aria-controls="dropdown-menu7">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>简体中文</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu">
            <div class="dropdown-content">
            
                <a href="/tags/Python/" class="dropdown-item">
                    简体中文
                </a>
            
                <a href="/en/tags/Python/" class="dropdown-item">
                    English
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("zh-CN");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<style>
 .katex-display {
    overflow-x: auto;
    overflow-y: hidden;
    height: 100%;
  }
</style>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="站内搜索" />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>