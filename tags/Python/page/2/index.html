<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>标签: Python - MyEncyclopedia</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">


<link href="/en/tags/Python/page/2/" rel="alternate" hreflang="en" />
    


<meta name="description" content="">





    <meta property="og:type" content="website">
<meta property="og:title" content="MyEncyclopedia">
<meta property="og:url" content="https://myencyclopedia.github.io/tags/Python/page/2/">
<meta property="og:site_name" content="MyEncyclopedia">
<meta property="og:locale">
<meta property="article:author" content="MyEncyclopedia">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="搜索" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://myencyclopedia.github.io">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#Python</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/tsp-4-search/" itemprop="url">TSP问题从DP算法到深度学习4：概率最大状态序列算法</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-11-20T18:45:01.000Z" itemprop="datePublished">11月 21 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            17 分钟 读完 (约 2491 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>本篇是TSP问题从DP算法到深度学习系列第四篇，这一篇我们会详细举例并比较在
seq-to-seq 或者Markov
Chain中的一些常见的搜索概率最大的状态序列的算法。这些方法在深度学习的seq-to-seq
中被用作decoding。在第五篇中，我们使用强化学习时也会使用了本篇中讲到的方法。</p>
<ul>
<li><p><a href="/zh/2020/tsp-4-search/!--swig￼6--">第一篇: 递归DP方法 AC AIZU
TSP问题</a></p></li>
<li><p><a href="/zh/2020/tsp-4-search/!--swig￼7--">第二篇:
二维空间TSP数据集及其DP解法</a></p></li>
<li><p><a href="/zh/2020/tsp-4-search/!--swig￼8--">第三篇: 深度学习 Pointer Networks 的
Pytorch实现</a></p></li>
<li><p>第四篇: 搜寻最有可能路径：Viterbi算法和其他</p></li>
<li><p>第五篇: 深度强化学习无监督算法的 Pytorch实现</p></li>
</ul>
<h2 id="马尔科夫链问题">马尔科夫链问题</h2>
<p>在 seq-to-seq
问题中，我们经常会遇到需要从现有模型中找概率最大的可能状态序列。这类问题在机器学习算法和控制领域广泛存在，抽象出来可以表达成马尔可夫链模型：给定初始状态的分布和系统的状态转移方程（称为系统动力，dynamics），找寻最有可能的状态序列。</p>
<p>举个例子，假设系统有 <span class="math inline">\(n\)</span>
个状态，初始状态由 $s_0 = [0.35, 0.25, 0.4] $
指定，表示初始时三种状态的分布为 0.35，0.25和0.4。</p>
<p>状态转移矩阵由 <span class="math inline">\(T\)</span> 表达，其中 $
T[i][j]$ 表示从状态 <span class="math inline">\(i\)</span> 到状态 <span class="math inline">\(j\)</span> 的概率。注意下面的矩阵 <span class="math inline">\(T\)</span> 每行的和为
1.0，对应了从任意状态出发，下一时刻的所有可能转移概率和为1。 <span class="math display">\[
T=
\begin{matrix}
&amp; \begin{matrix}0&amp;1&amp;2\end{matrix} \\\\
\begin{matrix}0\\\\1\\\\2\end{matrix} &amp;
  \begin{bmatrix}0.3&amp;0.6&amp;0.1\\\\0.4&amp;0.2&amp;0.4\\\\0.3&amp;0.3&amp;0.4\end{bmatrix}\\\\
\end{matrix}
\]</span></p>
<p>至此，系统的所有参数都定下来了。接下去的各个时刻的状态分布可以通过矩阵乘法来算得。比如，记<span class="math inline">\(s_1\)</span> 为 <span class="math inline">\(t_1\)</span> 时刻状态分布，计算方法为 <span class="math inline">\(s_0\)</span> 乘以 <span class="math inline">\(T\)</span>，动画如下：</p>
<p><img src="/zh/2020/tsp-4-search/transition-animated.svg" title="Transition Animation"></p>
<p><span class="math inline">\(s_1\)</span> 数值计算结果如下。</p>
<p><span class="math display">\[
s_1 =  \begin{bmatrix}0.35&amp; 0.25&amp; 0.4\end{bmatrix}
\begin{matrix}
\begin{bmatrix}0.3&amp;0.6&amp;0.1\\\\0.4&amp;0.2&amp;0.4\\\\0.3&amp;0.3&amp;0.4\end{bmatrix}\\\\
\end{matrix}
= \begin{bmatrix}0.325&amp; 0.35&amp; 0.255\end{bmatrix}
\]</span>
矩阵左乘行向量可以理解为矩阵每一行的线性组合，直觉上理解为下一时刻的状态分布是上一时刻初始状态分布乘以转移关系的线性组合。
<span class="math display">\[
\begin{bmatrix}0.35&amp; 0.25&amp; 0.4\end{bmatrix}
\begin{matrix}
\begin{bmatrix}0.3&amp;0.6&amp;0.1\\\\0.4&amp;0.2&amp;0.4\\\\0.3&amp;0.3&amp;0.4\end{bmatrix}\\\\
\end{matrix}
= 0.35 \times \begin{bmatrix}0.35&amp; 0.6&amp; 0.1\end{bmatrix} + 0.25
\times \begin{bmatrix}0.4&amp; 0.2&amp; 0.4\end{bmatrix} + 0.4 \times
\begin{bmatrix}0.3&amp; 0.3&amp; 0.4\end{bmatrix}
\]</span> 同样的，后面每一个时刻都可以由上一个状态分布向量乘以 <span class="math inline">\(T\)</span>，当然这里我们假设每个时刻的转移矩阵是不变的。当然，问题也可以是每个时刻都有不同的转移矩阵来定义，例如深度学习
seq-to-seq
模型。当然，这个设定的变化不会影响搜索最可能状态序列的算法。出于简单考虑，本篇中我们假定所有时刻的状态转移矩阵都是
<span class="math inline">\(T\)</span>。</p>
<p>下面我们通过多种算法来找出由上述参数定义的系统中前三个时刻的最有可能序列，即概率最大的
<span class="math inline">\(s_0 \rightarrow s_1 \rightarrow
s_2\)</span>。</p>
<p>令 <span class="math inline">\(L\)</span> 是阶段数，<span class="math inline">\(N\)</span> 是每个阶段的状态数，则我们的例子中
<span class="math inline">\(L=N=3\)</span> 。并且，总共有 <span class="math inline">\(N^L\)</span> 种不同的路径。</p>
<h2 id="穷竭搜索">穷竭搜索</h2>
<p>若给定一条路径，计算特定路径的概率是很直接的，例如，若给定路径为
<span class="math inline">\(2(s_0) \rightarrow 1(s_1) \rightarrow
2(s_2)\)</span>，则这条路径的概率为</p>
<p><span class="math display">\[
p(2 \rightarrow 1 \rightarrow 2) = s_0[2] \times T[2][1] \times T[1][2]
= 0.4 \times 0.3 \times 0.4 = 0.048
\]</span></p>
<p>因此，我们可以通过枚举所有 <span class="math inline">\(N^L\)</span>
条路径并计算每条路径的概率来找到最有可能的状态序列。</p>
<p>下面是Python
3的穷竭搜索代码，输出为最有可能的概率及其路径。样例问题的输出为 0.084
和状态序列 <span class="math inline">\(0 \rightarrow 1 \rightarrow
2\)</span>。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_brute_force</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> combinations_with_replacement</span><br><span class="line">    v = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]</span><br><span class="line">    path_all = combinations_with_replacement(v, L)</span><br><span class="line"></span><br><span class="line">    max_prop = <span class="hljs-number">0.0</span></span><br><span class="line">    max_route = <span class="hljs-literal">None</span></span><br><span class="line">    prob = <span class="hljs-number">0.0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> path <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(path_all):</span><br><span class="line">        <span class="hljs-keyword">for</span> idx, v <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(path):</span><br><span class="line">            <span class="hljs-keyword">if</span> idx == <span class="hljs-number">0</span>:</span><br><span class="line">                prob = initial[v]  <span class="hljs-comment"># reset to initial state</span></span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                prev_v = path[idx-<span class="hljs-number">1</span>]</span><br><span class="line">                prob *= transition[prev_v][v]</span><br><span class="line">        <span class="hljs-keyword">if</span> prob &gt; max_prop:</span><br><span class="line">            max_prop = <span class="hljs-built_in">max</span>(max_prop, prob)</span><br><span class="line">            max_route = path</span><br><span class="line">    <span class="hljs-keyword">return</span> max_prop, max_route</span><br></pre></td></tr></tbody></table></figure>
<h2 id="贪心搜索">贪心搜索</h2>
<p>穷竭搜索一定会找到最有可能的状态序列，但是算法复杂度是指数级的 <span class="math inline">\(O(N^L)\)</span>。一种最简化的策略是，每一时刻都只选取下一时刻最可能的状态，显然这种策略没有考虑全局最优，只考虑下一步最优，因此称为贪心策略。当然，贪心策略虽然牺牲全局最优解但是换取了很快的时间复杂度。贪心搜索算法动画如下。</p>
<p><img src="/zh/2020/tsp-4-search/greedy-animated.svg" title="Greedy Search Animation"></p>
<p>Python 3 实现中我们利用了 numpy 类库，主要是 np.argmax()
可以让代码简洁。代码本质上是两重循环，（一层循环是np.argmax中），对应时间算法复杂度是
<span class="math inline">\(O(N\times L)\)</span>。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_greedy</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">    max_route = []</span><br><span class="line">    max_prop = <span class="hljs-number">0.0</span></span><br><span class="line">    states = np.array(initial)</span><br><span class="line"></span><br><span class="line">    prev_max_v = <span class="hljs-literal">None</span></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, L):</span><br><span class="line">        max_v = np.argmax(states)</span><br><span class="line">        max_route.append(max_v)</span><br><span class="line">        <span class="hljs-keyword">if</span> l == <span class="hljs-number">0</span>:</span><br><span class="line">            max_prop = initial[max_v]</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            max_prop = max_prop * transition[prev_max_v][max_v]</span><br><span class="line">        states = max_prop * states</span><br><span class="line">        prev_max_v = max_v</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> max_prop, max_route</span><br></pre></td></tr></tbody></table></figure>
<h2 id="beam-搜索">Beam 搜索</h2>
<p>贪心策略只考虑了下一步的最大概率状态，若我们改进一下贪心策略，将下一步的最大
<span class="math inline">\(k\)</span> 个状态保留下来就是beam
搜索了。具体来说， <span class="math inline">\(k\)</span> beam
search表示每个阶段保留 <span class="math inline">\(k\)</span>
个最大概率路径，下一阶段扩展这 <span class="math inline">\(k\)</span>
条路径至 <span class="math inline">\(k \times N\)</span>
条路径再选取最大的top k。以上例来说，选取<span class="math inline">\(k=2\)</span>，则初始 <span class="math inline">\(s_0\)</span>时选取最大概率的两种状态 0和
2，下一阶段 <span class="math inline">\(s_1\)</span>，计算以0和2开始的共
<span class="math inline">\(2 \times 3\)</span>
条路径，并保留其中最大概率的两条，如此往复。显然，beam
search也无法找到全局最优解，但是它能以线性时间复杂度探索更多的路径空间。</p>
<p><img src="/zh/2020/tsp-4-search/beam-animated.svg" title="Beam Search Animation"></p>
<p>以下是Python 3 的代码实现，利用了 PriorityQueue 选取 <span class="math inline">\(k\)</span> 路径。由于PriorityQueue
无法自定义比较关系，我们定义了 <span class="citation" data-cites="total_ordering">@total_ordering</span>
标注的类来实现比较关心。时间算法复杂度是 <span class="math inline">\(O(k\times N \times L)\)</span> 。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_beam</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span>, K: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    N = <span class="hljs-built_in">len</span>(initial)</span><br><span class="line">    <span class="hljs-keyword">from</span> queue <span class="hljs-keyword">import</span> PriorityQueue</span><br><span class="line">    current_q = PriorityQueue()</span><br><span class="line">    next_q = PriorityQueue()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> total_ordering</span><br><span class="line"><span class="hljs-meta">    @total_ordering</span></span><br><span class="line">    <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PQItem</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, prob, route</span>):</span></span><br><span class="line">            self.prob = prob</span><br><span class="line">            self.route = route</span><br><span class="line">            self.last_v = <span class="hljs-built_in">int</span>(route[-<span class="hljs-number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__eq__</span>(<span class="hljs-params">self, other</span>):</span></span><br><span class="line">            <span class="hljs-keyword">return</span> self.prob == other.prob</span><br><span class="line"></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__lt__</span>(<span class="hljs-params">self, other</span>):</span></span><br><span class="line">            <span class="hljs-keyword">return</span> self.prob &gt; other.prob</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">        next_q.put(PQItem(initial[v], <span class="hljs-built_in">str</span>(v)))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L):</span><br><span class="line">        current_q = next_q</span><br><span class="line">        next_q = PriorityQueue()</span><br><span class="line">        k = K</span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> current_q.empty() <span class="hljs-keyword">and</span> k &gt; <span class="hljs-number">0</span>:</span><br><span class="line">            item = current_q.get()</span><br><span class="line">            prob, route, prev_v = item.prob, item.route, item.last_v</span><br><span class="line">            k -= <span class="hljs-number">1</span></span><br><span class="line">            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                nextItem = PQItem(prob * transition[prev_v][v], route + <span class="hljs-built_in">str</span>(v))</span><br><span class="line">                next_q.put(nextItem)</span><br><span class="line"></span><br><span class="line">    max_item = next_q.get()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> max_item.prob, <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x), max_item.route))</span><br></pre></td></tr></tbody></table></figure>
<h2 id="viterbi-动态规划">Viterbi 动态规划</h2>
<p>和之前TSP
动态规划算法的思想一样，最有可能状态路径问题解法有可以将指数时间复杂度
<span class="math inline">\(O(N^L)\)</span> 降到多项式时间复杂度 <span class="math inline">\(O(L \times N \times N)\)</span>
的算法，就是大名鼎鼎的 Viterbi
算法（维特比算法）。核心思想是在每个阶段，用数组保存每个状态结尾路径的阶段最大概率（及其对应路径）。在不考虑优化空间的情况下，我们开一个二维数组
<span class="math inline">\(dp[][]\)</span>，第一维表示阶段序号，第二维表示状态序号。例如，<span class="math inline">\(dp[1][0]\)</span> 是 <span class="math inline">\(s_1\)</span>
阶段时以状态0结尾的所有路径中的最大概率，即 <span class="math display">\[
dp[1][0] = \max \\{s_0[0] \rightarrow s_1[0], s_0[1] \rightarrow s_1[0],
s_0[2] \rightarrow s_1[0]\\}
\]</span></p>
<p><img src="/zh/2020/tsp-4-search/viterbi-animated.svg" title="Viterbi DP Animation"></p>
<p>实现代码中没有返回路径本身而只是其概率值，目的是通过简洁的三层循环来表达算法精髓。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_dp</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">    N = <span class="hljs-built_in">len</span>(initial)</span><br><span class="line">    dp = [[<span class="hljs-number">0.0</span> <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(L)]</span><br><span class="line">    dp[<span class="hljs-number">0</span>] = initial[:]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, L):</span><br><span class="line">        <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">            <span class="hljs-keyword">for</span> prev_v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                dp[l][v] = <span class="hljs-built_in">max</span>(dp[l][v], dp[l - <span class="hljs-number">1</span>][prev_v] * transition[prev_v][v])</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(dp[L-<span class="hljs-number">1</span>])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="概率采用">概率采用</h2>
<p>以上所有的算法都是确定性的。在NLP 深度学习decoding
时候会带来一个问题：确定性容易导致生成重复的短语或者句子。比如，确定性算法很容易生成如下句子。
</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This is the best of best of best of ...</span><br></pre></td></tr></tbody></table></figure>
一种简单的方法是采用概率采用的方式回避这个问题。也就是我们不寻找确定的局部最优或者全局最优的解，而是通过局部路径或者全局路径的概率信息进行采样生成序列。例如，对于穷竭搜索的
<span class="math inline">\(N^L\)</span> 条路径计算得到对应概率，转变成
<span class="math inline">\(N^L\)</span> 个点的 categorical
分布，采样生成某条路径。也可以如下改造贪心或者beam
这类阶段性生成算法一个时刻一个时刻的输出采样的状态序列。<p></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_prob_greedy</span>(<span class="hljs-params">initial: <span class="hljs-type">List</span>, transition: <span class="hljs-type">List</span>, L: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-type">Tuple</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">import</span> random</span><br><span class="line">    N = <span class="hljs-built_in">len</span>(initial)</span><br><span class="line">    max_route = []</span><br><span class="line">    max_prop = <span class="hljs-number">0.0</span></span><br><span class="line">    vertices = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]</span><br><span class="line">    prob = initial[:]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, L):</span><br><span class="line">        v_lst = random.choices(vertices, prob)</span><br><span class="line">        v = v_lst[<span class="hljs-number">0</span>]</span><br><span class="line">        max_route.append(v)</span><br><span class="line">        max_prop = prob[v]</span><br><span class="line">        prob = [prob[v] * transition[v][v_target] <span class="hljs-keyword">for</span> v_target <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> max_prop, max_route</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/distribution-discrete-generator/" itemprop="url">从零构建统计随机变量生成器之离散基础篇</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-11-13T18:45:01.000Z" itemprop="datePublished">11月 14 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 分钟 读完 (约 1778 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>在本系列中，我们会从第一性原理出发，从零开始构建统计学中的常见分布的随机变量生成器，包括二项分布，泊松分布，高斯分布等。在实现这些基础常见分布的过程中，会展示如何使用统计模拟的通用技术，包括
inverse
CDF，Box-Muller，分布转换等。本期通过伯努利试验串联起来基础离散分布并通过代码来实现这些分布的生成函数，从零开始构建的原则是随机变量生成器实现只依赖
random() 产生 [0, 1.0] 之间的浮点数，不依赖于其他第三方API来完成。</p>
<ul>
<li><strong><a href="/zh/2020/distribution-discrete-generator/zh/distribution-discrete-generator.md">从零构建统计随机变量生成器之
离散基础篇</a></strong></li>
<li><a href="/zh/2020/distribution-discrete-generator/zh/distribution-inverse-transformation-method.md">从零构建统计随机变量生成器之
用逆变换采样方法构建随机变量生成器</a></li>
<li><a href="/zh/2020/distribution-discrete-generator/zh/leetcode-470-rand10.md">深入 LeetCode 470
拒绝采样，状态转移图求期望和一道经典统计求期望题目</a></li>
<li><a href="/zh/2020/distribution-discrete-generator/zh/distribution-normal.md">从零构建统计随机变量生成器之
正态分布 Box-Muller方法</a></li>
</ul>
<h2 id="均匀分布离散">均匀分布（离散）</h2>
<p>离散均匀分布（Discrete Uniform
Distribution）的随机变量是最为基本的，图中为 [0, 6]
七个整数的离散均匀分布。算法实现为，使用 [0, 1] 之间的随机数 u，再将 u
等比例扩展到指定的整数上下界。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_uniform.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> floor</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uniform</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> a &lt;= b</span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> a + floor((b - a + <span class="hljs-number">1</span>) * u)</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_uniform.py</p>
<h2 id="伯努利分布">伯努利分布</h2>
<p>伯努利分布（Bernoulli
Distribution）是support为0或者1的离散分布，0和1可以看成失败和成功两种可能。伯努利分布指定了成功的概率p，例如，下图是
p=0.4 的伯努利分布。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_ber.png">
<figcaption>
</figcaption>
</figure>
<p>伯努利分布随机数实现也很直接，将随机值 u 根据 p
决定成功或者失败。</p>
<h3 id="实现代码-1">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bernoulli</span>(<span class="hljs-params">p: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= p &lt;= <span class="hljs-number">1</span></span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> u &lt;= p <span class="hljs-keyword">else</span> <span class="hljs-number">0</span></span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_bernoulli.py</p>
<h2 id="类别分布">类别分布</h2>
<p>类别分布（Categorical
Distribution）是在伯努利分布的基础上扩展到了多个点，每个点同样由参数指定了其概率，因此，其参数从
p 扩展到了向量 <span class="math inline">\(\vec p\)</span>，如图所示为
$p = [0.2, 0.3, 0.1, 0.4] $ 时的类别分布。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_category.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-2">实现代码</h3>
<p>类别分布生成函数也扩展了伯努利分布的实现算法，将随机数 u
和累计概率向量作比较。在这个例子中， $p = [0.2, 0.3, 0.1, 0.4] $ 转换成
$c = [0.2, 0.5, 0.6, 1] $，再将 u 和 <span class="math inline">\(\vec
c\)</span>数组匹配，返回结果为第一个大于 u 的元素
index。实现上，我们可以以线性复杂度遍历数组，更好一点的方法是，用 python
bisect函数通过二分法找到index，将时间复杂度降到 <span class="math inline">\(O(log(n))\)</span>。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> bisect</span><br><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">categorical</span>(<span class="hljs-params">probs: <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">abs</span>(<span class="hljs-built_in">sum</span>(probs) - <span class="hljs-number">1.0</span>) &lt; <span class="hljs-number">0.001</span></span><br><span class="line">    cum = probs.copy()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(cum)):</span><br><span class="line">        cum[i] = cum[i-<span class="hljs-number">1</span>] + probs[i]</span><br><span class="line"></span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> bisect.bisect(cum, u)</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：
https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_categorical.py</p>
<h2 id="二项分布">二项分布</h2>
<p>二项分布（Binomial Distribution）有两个参数 n 和
p，表示伯努利实验做n次后成功的次数。图中为 n=6，p=0.5的二项分布。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_binomial.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-3">实现代码</h3>
<p>二项分布生成算法可以通过伯努利试验的故事来实现，即调用 n
次伯努利分布生成函数，返回总的成功次数。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">binomial</span>(<span class="hljs-params">n: <span class="hljs-built_in">int</span>, p: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(bernoulli(p) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n))</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_binomial.py</p>
<h3 id="概率质量函数pmf">概率质量函数（PMF）</h3>
<div>
<p><span class="math display">\[
\operatorname{Pr}_\text{Binomial}(X=k)=\left(\begin{array}{c}n \\
k\end{array}\right)p^{k}(1- p)^{n-k}
\]</span></p>
</div>
<h2 id="几何分布">几何分布</h2>
<p>几何分布（Geometric
Distribution）和伯努利实验的关系是：几何分布是反复伯努利实验直至第一次成功时的失败次数。如图，当成功概率
p=0.4时的几何分布。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_geometric.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-4">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> discrete_bernoulli <span class="hljs-keyword">import</span> bernoulli</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">geometric</span>(<span class="hljs-params">p: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    fail_num = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> bernoulli(p):</span><br><span class="line">        fail_num += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> fail_num</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_geometric.py</p>
<h3 id="概率质量函数pmf-1">概率质量函数（PMF）</h3>
<p><span class="math display">\[
\operatorname{Pr}_\text{Geometric}(X=k)=(1-p)^{k-1} p
\]</span></p>
<h2 id="负二项分布">负二项分布</h2>
<p>负二项分布（Negative Binomial Distribution）是尝试伯努利试验直至成功
r 次的失败次数。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_negbinomial.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-5">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> discrete_bernoulli <span class="hljs-keyword">import</span> bernoulli</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">negative_binomial</span>(<span class="hljs-params">r: <span class="hljs-built_in">int</span>, p: <span class="hljs-built_in">float</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    failures = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> r:</span><br><span class="line">        success = bernoulli(p)</span><br><span class="line">        <span class="hljs-keyword">if</span> success:</span><br><span class="line">            r -= <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            failures += <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> failures</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_nagative_binomial.py</p>
<h3 id="概率质量函数pmf-2">概率质量函数（PMF）</h3>
<div>
<p><span class="math display">\[
\operatorname{Pr}_\text{NegBinomial}(X=k)=\left(\begin{array}{c}k+r-1 \\
r-1\end{array}\right)(1-p)^{k} p^{r}
\]</span></p>
</div>
<h2 id="超几何分布">超几何分布</h2>
<p>超几何分布（HyperGeometric
Distribution）的意义是从总数为N的集合抽取n次后成功的次数。具体来说，集合由K个表示成功的元素和N-K个表示失败的元素组成，并且抽取时没有替换（without
replacement）情况下的成功次数。注意，超几何分布和二项分布的区别仅在于有无替换。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_hypergeo.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-6">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> discrete_bernoulli <span class="hljs-keyword">import</span> bernoulli</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hypergeometric</span>(<span class="hljs-params">N: <span class="hljs-built_in">int</span>, K_succ_num: <span class="hljs-built_in">int</span>, n_trial_num: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    x = N - K_succ_num</span><br><span class="line">    n_hit = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> n_trial_num:</span><br><span class="line">        hit = bernoulli(K_succ_num / (K_succ_num + x))</span><br><span class="line">        n_hit += hit</span><br><span class="line">        <span class="hljs-keyword">if</span> hit:</span><br><span class="line">            K_succ_num -= <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            x -= <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">if</span> K_succ_num == <span class="hljs-number">0</span>:</span><br><span class="line">            <span class="hljs-keyword">return</span> n_hit</span><br><span class="line">        n_trial_num -= <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> n_hit</span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：</p>
<p>https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_hypergeometric.py</p>
<h3 id="概率质量函数pmf-3">概率质量函数（PMF）</h3>
<div>
<p><span class="math display">\[
\operatorname{Pr}_\text{Hypergeo}(X=k)=\frac{\left(\begin{array}{c}K \\
k\end{array}\right)\left(\begin{array}{c}N-k \\
n-k\end{array}\right)}{\left(\begin{array}{l}N \\ n\end{array}\right)}
\]</span></p>
</div>
<h2 id="负超几何分布">负超几何分布</h2>
<p>负超几何分布（Negative Hypergeometric
Distribution）的意义是从总数为N的集合中，无替换下抽取直至 r
次失败时，成功的次数。</p>
<figure>
<img src="/zh/2020/distribution-discrete-generator/distrib_neg_hypergeometric.png">
<figcaption>
</figcaption>
</figure>
<h3 id="实现代码-7">实现代码</h3>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> discrete_bernoulli <span class="hljs-keyword">import</span> bernoulli</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">negative_hypergeometric</span>(<span class="hljs-params">N: <span class="hljs-built_in">int</span>, K_success_num: <span class="hljs-built_in">int</span>, r_fail_times: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    fail_num = N - K_success_num</span><br><span class="line">    succ_trials = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> r_fail_times:</span><br><span class="line">        success = bernoulli(K_success_num / (K_success_num + fail_num))</span><br><span class="line">        <span class="hljs-keyword">if</span> success:</span><br><span class="line">            K_success_num -= <span class="hljs-number">1</span></span><br><span class="line">            succ_trials += <span class="hljs-number">1</span></span><br><span class="line">            <span class="hljs-keyword">if</span> K_success_num == <span class="hljs-number">0</span>: <span class="hljs-comment"># no more success elements</span></span><br><span class="line">                <span class="hljs-keyword">return</span> succ_trials</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            fail_num -= <span class="hljs-number">1</span></span><br><span class="line">            r_fail_times -= <span class="hljs-number">1</span></span><br><span class="line">    <span class="hljs-keyword">return</span> succ_trials</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>Github 代码地址：
https://github.com/MyEncyclopedia/stats_simulation/blob/main/distrib_sim/discrete_negative_hypergeometric.py</p>
<h3 id="概率质量函数pmf-4">概率质量函数（PMF）</h3>
<div>
<p><span class="math display">\[
\operatorname{Pr}_\text{NegHypergeo}(X=k)=\frac{\left(\begin{array}{c}k+r-1
\\ k\end{array}\right)\left(\begin{array}{c}N-r-k \\
K-k\end{array}\right)}{\left(\begin{array}{l}N \\ K\end{array}\right)}
\quad \text{for } k=0,1,2, \ldots, K
\]</span></p>
</div>
<h2 id="伯努利试验总结">伯努利试验总结</h2>
<p>下表总结了上面四种和伯努利试验有关的离散分布的具体区别。</p>
<table>
<colgroup>
<col style="width: 17%">
<col style="width: 35%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>有替换</th>
<th>无替换</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>固定尝试次数</td>
<td>二项 Binomial</td>
<td>超几何 Hypergeometric</td>
</tr>
<tr class="even">
<td>固定成功次数</td>
<td>负二项 Negative Binomial</td>
<td>负超几何 Negative Hypergeometric</td>
</tr>
</tbody>
</table>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-qlearning-to-dqn/" itemprop="url">通过代码学Sutton强化学习：从Q-Learning 演化到 DQN</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-10-29T18:45:01.000Z" itemprop="datePublished">10月 30 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            18 分钟 读完 (约 2717 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>上一期 MyEncyclopedia公众号文章 <a href="/zh/2020/rl-qlearning-to-dqn/!--swig￼1--">SARSA、Q-Learning和Expected
SARSA时序差分算法训练CartPole</a>中，我们通过CartPole的OpenAI
Gym环境实现了Q-learning算法，这一期，我们将会分析Q-learning算法面临的maximization
bias 问题和提出double learning算法来改进。接着，我们将tabular
Q-learning算法扩展到用带参函数来近似 Q(s, a)，这就是Deepmind
在2015年Nature上发表的Deep Q Network
（DQN）思想：用神经网络结合Q-learning算法实现超越人类玩家打Atari游戏的水平。</p>
<h2 id="q-learning-回顾">Q-Learning 回顾</h2>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Q-learning (off-policy TD Control) for estimating } \pi
\approx \pi_{*} \\
&amp; \text{Algorithm parameters: step size }\alpha \in ({0,1}]\text{,
small }\epsilon &gt; 0 \\
&amp; \text{Initialize }Q(s,a),  \text{for all } s \in \mathcal{S}^{+},
a \in \mathcal{A}(s) \text{, arbitrarily except that } Q(terminal,
\cdot) = 0 \\
&amp; \text{Loop for each episode:}\\
&amp; \quad \text{Initialize }S\\
&amp; \quad \text{Loop for each step of episode:} \\
&amp; \quad \quad \text{Choose } A \text{ from } S \text{ using policy
derived from } Q \text{ (e.g., } \epsilon\text{-greedy)} \\
&amp; \quad \quad \text{Take action }A,  \text { observe } R, S^{\prime}
\\
&amp; \quad \quad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma
\max_{a}Q(S^{\prime}, a) - Q(S,A)] \\
&amp; \quad \quad S \leftarrow S^{\prime}\\
&amp; \quad \text{until }S\text{ is terminal} \\
\end{align*}
\]</span></p>
</div>
<p>在<a href="/zh/2020/rl-qlearning-to-dqn/!--swig￼2--">SARSA、Q-Learning和Expected
SARSA时序差分算法训练CartPole</a>&nbsp;中，我们实现了同样基于 <span class="math inline">\(\epsilon\)</span>-greedy
策略的Q-learning算法和SARSA算法，两者代码上的区别确实不大，但本质上Q-learning是属于
off-policy 范畴而 SARSA却属于 on-policy
范畴。一种理解方式是，Q-learning相比于SARSA少了第二次从 <span class="math inline">\(\epsilon\)</span>-greedy
策略采样出下一个action，即S, A, R', S', A'
五元组中最后一个A'，而直接通过max操作去逼近 <span class="math inline">\(q^{*}\)</span>。如此，Q-learning并没有像SARSA完成一次完整的GPI（Generalized
Policy Iteration），缺乏on-policy的策略迭代的特点，故而 Q-learning
属于off-policy方法。我们也可以从另一个角度来分析两者的区别。注意到这两个算法不是一定非要使用
<span class="math inline">\(\epsilon\)</span>-greedy
策略的。对于Q-learning来说，完全可以使用随机策略，理论上已经证明，只要保证每个action以后依然有几率会被探索下去，Q-learning
最终会收敛到最优策略。Q-learning使用 <span class="math inline">\(\epsilon\)</span>-greedy
是为了能快速收敛。对于SARSA算法来说，则无法使用随机策略，因为随机策略无法形成策略提升。而
<span class="math inline">\(\epsilon\)</span>-greedy
策略却可以形成策略迭代，完成策略提升，当然，<span class="math inline">\(\epsilon\)</span>-greedy 策略在 SARSA
算法中也可以保证快速收敛。因此，尽管两者都使用 <span class="math inline">\(\epsilon\)</span>-greedy
策略再借由环境产生reward和state，它们的作用并非完全一样。至此，我们可以体会到on-policy和off-policy本质的区别。</p>
<h3 id="收敛条件">收敛条件</h3>
Tabular Q-Learning 收敛到最佳Q函数的条件如下[2]:
<div>
<p><span class="math display">\[
\Sigma^{\infty}_{n=0} \alpha_{n} = {\infty} \quad \text{  AND  } \quad
\Sigma^{\infty}_{n=0} \alpha^2_{n} \lt {\infty}
\]</span></p>
</div>
<p>一种方式是将 <span class="math inline">\(\alpha\)</span>设置成 (s,
a)访问次数的倒数：<span class="math inline">\(\alpha_{n}(s,a) = 1/ n(s,a
)\)</span></p>
<p>则整体更新公式为</p>
<p><span class="math display">\[
Q(s,a) \leftarrow Q(s,a) + \alpha_n(s, a)[R+\gamma
\max_{a^{\prime}}Q(s^{\prime}, a^{\prime}) - Q(s, a)]
\]</span></p>
<h3 id="q-learning-最大化偏差问题">Q-Learning 最大化偏差问题</h3>
<p>Q-Learning 会产生最大化偏差问题（Maximization Bias，在Sutton
教材6.7节），它的原因是用估计值中取最大值去估计真实值中最大是有偏的。这个可以做如下试验来模拟，若有5个
[-3, 3] 的离散均匀分布 <span class="math inline">\(d_i\)</span>，<span class="math inline">\(\max(\mathbb{E}[d_i]) =
0\)</span>，但是若我们用单批采样 <span class="math inline">\(x_i \sim
d_i\)</span>来估算 <span class="math inline">\(\mathbb{E}[d_i]\)</span>在取max的话，<span class="math inline">\(\mathbb{E}[{\max(x_i)]}\)</span>
是有bias的。但是如果我们将这个过程分解成选择最大action和评估其值两步，每一步用独立的采样集合就可以做到无偏，这个改进方法称为double
learning。具体过程为第一步在<span class="math inline">\(Q_1\)</span>集合中找到最大的action，第二步在<span class="math inline">\(Q_2\)</span>中返回此action值，即：</p>
<div>
<p><span class="math display">\[
\begin{align*}
A^{\star} = \operatorname{argmax}_{a}Q_1(a) \\
Q_2(A^{\star}) = Q_2(\operatorname{argmax}_{a}Q_1(a))
\end{align*}
\]</span></p>
</div>
<p>则无限模拟后结果是无偏的：<span class="math inline">\(\mathbb{E}[Q_2(A^{\star})] = q(A^{\star})\)</span>
下面是简单模拟试验两种方法的均值比较</p>
<figure>
<img src="/zh/2020/rl-qlearning-to-dqn/double_sampling.png">
<figcaption>
Maximization Bias
</figcaption>
</figure>
<p>试验完整代码如下</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random</span><br><span class="line"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> floor</span><br><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd</span><br><span class="line"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uniform</span>(<span class="hljs-params">a: <span class="hljs-built_in">int</span>, b: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">    u = random.random()</span><br><span class="line">    <span class="hljs-keyword">return</span> a + floor((b - a + <span class="hljs-number">1</span>) * u)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:</span><br><span class="line">    total_max_bias = <span class="hljs-number">0</span></span><br><span class="line">    avgs_max_bias = []</span><br><span class="line">    total_double_sampling = <span class="hljs-number">0</span></span><br><span class="line">    avgs_double_sampling = []</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>):</span><br><span class="line">        samples = np.array([uniform(-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)])</span><br><span class="line">        max_sample = <span class="hljs-built_in">max</span>(samples)</span><br><span class="line">        total_max_bias += max_sample</span><br><span class="line">        avgs_max_bias.append(total_max_bias / e)</span><br><span class="line"></span><br><span class="line">        samples2 = np.array([uniform(-<span class="hljs-number">3</span>, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)])</span><br><span class="line">        total_double_sampling += samples2[np.argmax(samples)]</span><br><span class="line">        avgs_double_sampling.append(total_double_sampling / e)</span><br><span class="line"></span><br><span class="line">    df = pd.DataFrame({<span class="hljs-string">'Max of Samples'</span>: avgs_max_bias, <span class="hljs-string">'Double Samples'</span>: avgs_double_sampling})</span><br><span class="line">    <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line">    sns.lineplot(data=df)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p>回到Q-learning 中使用的 <span class="math inline">\(\epsilon\)</span>-greedy策略，Q-learning可以保证随着<span class="math inline">\(\epsilon\)</span> 的减小，最大化偏差会
asymptotically 趋近于真实值，但是double learning
可以更快地趋近于真实值。</p>
<figure>
<img src="/zh/2020/rl-qlearning-to-dqn/double_learning_vs_max_bias.png">
<figcaption>
Maximization Bias vs Double learning
</figcaption>
</figure>
<p>下面是Sutton 强化学习第二版6.7节中完整的Double Q-learning算法。</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Double Q-learning, for estimating } Q_1 \approx  Q_2
\approx q_{*} \\
&amp; \text{Algorithm parameters: step size }\alpha \in ({0,1}]\text{,
small }\epsilon &gt; 0 \\
&amp; \text{Initialize }Q_1(s,a), \text{ and } Q_2(s,a) \text{, for all
} s \in \mathcal{S}^{+}, a \in \mathcal{A}(s) \text{, such that }
Q(terminal, \cdot) = 0 \\
&amp; \text{Loop for each episode:}\\
&amp; \quad \text{Initialize }S\\
&amp; \quad \text{Loop for each step of episode:} \\
&amp; \quad \quad \text{Choose } A \text{ from } S \text{ using policy }
\epsilon\text{-greedy in } Q_1 + Q_2 \\
&amp; \quad \quad \text{Take action }A,  \text { observe } R, S^{\prime}
\\
&amp; \quad \quad \text{With 0.5 probability:} \\
&amp; \quad \quad \quad Q_1(S,A) \leftarrow Q_1(S,A) + \alpha \left (
R+\gamma Q_2(S^{\prime}, \operatorname{argmax}_{a}Q_1(S^{\prime}, a)) -
Q_1(S,A) \right )\\
&amp; \quad \quad \text{else:} \\
&amp; \quad \quad \quad Q_1(S,A) \leftarrow Q_1(S,A) + \alpha \left (
R+\gamma Q_2(S^{\prime}, \operatorname{argmax}_{a}Q_1(S^{\prime}, a)) -
Q_1(S,A) \right )\\
&amp; \quad \quad S \leftarrow S^{\prime}\\
&amp; \quad \text{until }S\text{ is terminal} \\
\end{align*}
\]</span></p>
</div>
<p>更详细内容，可以参考 Hado V. Hasselt 的 Double Q-learning paper
[3]。</p>
<h2 id="gradient-q-learning">Gradient Q-Learning</h2>
<p>Tabular
Q-learning由于受制于维度爆炸，无法扩展到高维状态空间，一般近似解决方案是用
approximating function来逼近Q函数。即我们将状态抽象出一组特征 <span class="math inline">\(s = \vec x= [x_1, x_2, ..., x_n]^T\)</span>，Q
用一个 x 的函数来近似表达 <span class="math inline">\(Q(s, a) \approx
g(\vec x;
\theta)\)</span>，如此，就联系起了深度神经网络。有了函数表达，深度学习还必须的元素是损失函数，这个很自然的可以用
TD
error。至此，问题转换成深度学习的几个要素均已具备，Q-learning算法改造成了深度学习中的有监督问题。</p>
<p>估计值：<span class="math inline">\(Q\left(s, a ;
\theta\right)\)</span></p>
<p>目标值：<span class="math inline">\(r+\gamma \max _{a^{\prime}}
Q\left(s^{\prime}, a^{\prime} ; \theta\right)\)</span></p>
<p>损失函数：</p>
<p><span class="math display">\[
L\left(\theta\right)=\mathbb{E}_{\left(s, a, r, s^{\prime}\right) \sim
\mathrm{U}(D)}\left[\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime},
a^{\prime} ; \theta\right)-Q\left(s, a ; \theta\right)\right)^{2}\right]
\]</span></p>
<h2 id="收敛性分析">收敛性分析</h2>
<p>首先明确一点，至此 gradient q-learning 和 tabular Q-learning
一样，都是没有记忆的，即对于一个新的环境产生的 sample 去做 stochastic
online update。</p>
<p>若Q函数是状态特征的线性函数，即 <span class="math inline">\(Q(s, a;
\theta) = \Sigma_i w_i x_i\)</span> ，那么线性Gradient
Q-learning的收敛条件和Tabular Q-learning 一样，也为</p>
<div>
<p><span class="math display">\[
\Sigma^{\infty}_{n=0} \alpha_{n} = {\infty} \quad \text{  AND  } \quad
\Sigma^{\infty}_{n=0} \alpha^2_{n} \lt {\infty}
\]</span></p>
</div>
<p>若Q函数是非线性函数，即使符合上述条件，也无法保证收敛，本质上源于改变
<span class="math inline">\(\theta\)</span> 使得 Q 值在 (s, a)
点上减小误差会影响 (s, a) 周边点的误差。</p>
<h2 id="dqn减少不收敛的两个技巧">DQN减少不收敛的两个技巧</h2>
<ol type="1">
<li><span class="math inline">\(\theta_{i-1} \rightarrow
\theta_{i}\)</span> 改变导致max中的估计值和目标值中的Q同时变化，面临着
chasing its own tail
的问题。解决的方法是使用不同的参数来parameterize两个Q，并且目标值的Q网络参数固定一段时间产生一批固定策略下的环境采样。这个技巧称为
Target Network。引入这个 trick 后深度学习的要素变成</li>
</ol>
<p>估计值：<span class="math inline">\(Q\left(s, a ;
\theta_{i}\right)\)</span></p>
<p>目标值：<span class="math inline">\(r+\gamma \max _{a^{\prime}}
Q\left(s^{\prime}, a^{\prime} ; \theta_i^{-}\right)\)</span></p>
<p>损失函数，DQN在Nature上的loss函数： <span class="math display">\[
L\left(\theta_{i}\right)=\mathbb{E}_{\left(s, a, r, s^{\prime}\right)
\sim \mathrm{U}(D)}\left[\left(r+\gamma \max _{a^{\prime}}
Q\left(s^{\prime}, a^{\prime} ; \theta_{i}^{-}\right)-Q\left(s, a ;
\theta_{i}\right)\right)^{2}\right]
\]</span></p>
<ol start="2" type="1">
<li>尽管目标值的 <span class="math inline">\(Q(;\theta^{-})\)</span>固定了，但是<span class="math inline">\(\theta_{i-1} \rightarrow \theta_{i}\)</span>
还会使得估计值的 <span class="math inline">\(Q(s, a;\theta_i)\)</span>
在变化的同时影响其他的 <span class="math inline">\(Q(s_k,
a_j;\theta_i)\)</span>，让之前训练过的 (s,
a)的点的损失值发生变化，解决的办法是将 online stochastic 改成 batch
gradient，也就是将最近的一系列采样值保存下来，这个方法称为 experience
replay。</li>
</ol>
<p>有了这两个优化，Deep Q
Network投入实战效果就容易收敛了，以下是Deepmind 发表在Nature 的
Human-level control through deep reinforcement learning [1]
的完整算法流程。</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Deep Q-learning with experience replay}\\
&amp; \text{Initialize replay memory } D\text{ to capacity } N \\
&amp; \text{Initialize action-value function } Q \text{ with random
weights } \theta \\
&amp; \text{Initialize target action-value function } \hat{Q} \text{
with weights } \theta^{-} = \theta \\
&amp; \textbf{For} \text{ episode = 1, } M \textbf{ do} \\
&amp; \text{Initialize sequences } s_1 = \{x_1\} \text{ and preprocessed
sequence } \phi_1 = \phi(s_1)\\
&amp; \quad \textbf{For } t=\text{ 1, T }\textbf{ do} \\
&amp; \quad \quad \text{With probability }\epsilon \text{ select a
random action } a_t \\
&amp; \quad \quad \text{otherwise select } a_t =
\operatorname{argmax}_{a}Q(\phi(s_t), a; \theta)\\
&amp; \quad \quad \text{Execute action } a_t \text{ in emulator and
observe reward } r_t \text{ and image  }x_{t+1}\\
&amp; \quad \quad \text{Set } s_{t+1} = s_t, a_t, x_{t+1} \text{ and
preprocess } \phi_{t+1} = \phi(s_{t+1})\\
&amp; \quad \quad \text{Store transition } (\phi_t, a_t, r_t,
\phi_{t+1}) \text{ in } D\\
&amp; \quad \quad \text{Sample random minibatch of transitions }
(\phi_j, a_j, r_j, \phi_{j+1}) \text{ from } D\\
&amp; \quad \quad \text{Set } y_j=
    \begin{cases}
      r_j \quad \quad\quad\quad\text{if episode terminates at step
j+1}\\
      r_j + \gamma \max_{a^{\prime}}\hat Q(\phi_{j+1}, a^{\prime};
\theta^{-}) \quad \text { otherwise}\\
    \end{cases}       \\
&amp; \quad \quad \text{Perform a gradient descent step on } (y_j -
Q(\phi_j, a_j; \theta))^2 \text{ with respect to the network parameters
} \theta\\
&amp; \quad \quad \text{Every C steps reset } \hat Q = Q\\
&amp; \quad \textbf{End For} \\
&amp; \textbf{End For}
\end{align*}
\]</span></p>
</div>
<h3 id="dqn-with-double-q-learning">DQN with Double Q-Learning</h3>
<p>DQN 算法和 Double Q-Learning 能不能结合起来呢？Hado van Hasselt 在
Deep Reinforcement Learning with Double Q-learning [4] 中提出参考 Double
Q-learning 将 DQN
的目标值改成如下函数，可以进一步提升最初DQN的效果。</p>
<p>目标值：<span class="math inline">\(r+\gamma Q(s^{\prime}, \max
_{a^{\prime}} Q\left(s^{\prime}, a^{\prime}; \theta_t\right);
\theta_t^{-})\)</span></p>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li><p><strong>Human-level control through deep reinforcement
learning</strong> Volodymyr Mnih, Koray Kavukcuoglu, David Silver
(2015)</p></li>
<li><p>CS885 Reinforcement Learning Lecture 4b: May 11, 2018</p></li>
<li><p><strong>Double Q-learning</strong> Hado V. Hasselt
(2010)</p></li>
<li><p><strong>Deep Reinforcement Learning with Double
Q-learning</strong> Hado van Hasselt, Arthur Guez, David Silver
(2015)</p></li>
</ol>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/tsp-3-pointer-net/" itemprop="url">TSP问题从DP算法到深度学习3：Pointer Network</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-10-24T06:45:01.000Z" itemprop="datePublished">10月 24 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 分钟 读完 (约 2000 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>本篇是TSP问题从DP算法到深度学习系列第三篇，在这一篇中，我们会开始进入深度学习领域来求近似解法。本文会介绍并实现指针网络（Pointer
Networks），一种seq-to-seq模型，它的设计目的就是为了解决TSP问题或者凸包（Convex
Hull）问题。本文代码在
https://github.com/MyEncyclopedia/blog/tree/master/tsp/ptr_net_pytorch
中。</p>
<ul>
<li><p><a href="/zh/2020/tsp-3-pointer-net/!--swig￼4--">第一篇: 递归DP方法 AC AIZU
TSP问题</a></p></li>
<li><p><a href="/zh/2020/tsp-3-pointer-net/!--swig￼5--">第二篇:
二维空间TSP数据集及其DP解法</a></p></li>
<li><p><a href="/zh/2020/tsp-3-pointer-net/!--swig￼6--">第三篇: 深度学习 Pointer Networks 的
Pytorch实现</a></p></li>
<li><p>第四篇: 搜寻最有可能路径：Viterbi算法和其他</p></li>
<li><p>第五篇: 深度强化学习无监督算法的 Pytorch实现</p></li>
</ul>
<h2 id="pointer-networks">Pointer Networks</h2>
<p>随着深度学习 seq-to-seq
模型作为概率近似模型在各领域的成功，TSP问题似乎也可以用同样的思路去解决。然而，传统的seq-to-seq
模型其输出的类别是预先固定的。例如，NLP RNN生成模型每一步会从 <span class="math inline">\(|V|\)</span> 大的词汇表中产生一个单词。
然而，有很大一类问题，譬如TSP问题、凸包（Convex
Hull）问题、Delaunay三角剖分问题，输出的类别不是事先固定的，而是随着输入而变化的。
<em>Pointer Networks </em>
的出现解决了这种限制：输出的类别可以通过指向某个输入，以此克服类别的问题，因此形象地取名为指针网络（Pointer
Networks）。先来看看原论文中提到的三个问题。</p>
<h3 id="凸包问题convex-hull">凸包问题（Convex Hull）</h3>
<p>如下图所示，需要在给定的10个点中找到若干个点，使得这些点包住了所有点。问题输入是不确定个数
n 个点的位置信息，输出是 k (k&lt;=n)个点的。
这个经典的算法问题已经被证明找出精确解等价于排序问题（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Convex_hull_algorithms">wikipedia
链接</a>），因此时间复杂度为 <span class="math inline">\(O(n*log(n))\)</span>。</p>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./convex_hull.png" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;=&amp; \left\{ P_{1}, \ldots,
P_{10} \right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp; \{2,4,3,5,6,7,2\}
\end{align*}
\]</span></p>
</div>
<h3 id="tsp-问题">TSP 问题</h3>
<p>TSP 和凸包问题很类似，输入为不确定个数的 n 个点信息，输出为这 n
个点的某序列。在。。。中，我们可以将确定解的时间复杂度从 <span class="math inline">\(O(n!)\)</span> 降到 <span class="math inline">\(O(n^2*2^n)\)</span>。</p>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./tsp.svg" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;= &amp;\left\{P_{1}, \ldots, P_{6}
\right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp; \{1,3,2,4,5,6,1\}
\end{align*}
\]</span></p>
</div>
<h3 id="delaunay三角剖分">Delaunay三角剖分</h3>
<p>Delaunay三角剖分问题是将平面上的散点集划分成三角形，使得在可能形成的三角剖分中，所形成的三角形的最小角最大。这个问题的输出是若干个集合，每个集合代表一个三角形，由输入点的编号表示。
<img src="/zh/2020/tsp-3-pointer-net/./delaunay_triangulation.png" alt="image info"></p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;=&amp; \left\{P_{1}, \ldots, P_{5}
\right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp;
\{(1,2,4),(1,4,5),(1,3,5),(1,2,3)\}
\end{align*}
\]</span></p>
</div>
<h3 id="seq-to-seq-模型">Seq-to-Seq 模型</h3>
<p>现在假设n是固定的，传统基本的seq-to-seq模型（参数部分记为 <span class="math inline">\(\theta\)</span> ），训练数据若记为<span class="math inline">\((\mathcal{P},
C^{\mathcal{P}})\)</span>，，将拟合以下条件概率：</p>
<p><span class="math display">\[
\begin{equation}
p\left(\mathcal{C}^{\mathcal{P}} | \mathcal{P} ;
\theta\right)=\prod_{i=1}^{m(\mathcal{P})} p\left(C_{i} | C_{1}, \ldots,
C_{i-1}, \mathcal{P} ; \theta\right)
\end{equation}
\]</span> 训练的方向是找到 <span class="math inline">\(\theta^{*}\)</span> 来最大化上述联合概率，即：
<span class="math display">\[
\begin{equation}
\theta^{*}=\underset{\theta}{\arg \max } \sum_{\mathcal{P},
\mathcal{C}^{\mathcal{P}}} \log p\left(\mathcal{C}^{\mathcal{P}} |
\mathcal{P} ; \theta\right)
\end{equation}
\]</span></p>
<h3 id="content-based-input-attention">Content Based Input
Attention</h3>
<p>一种增强基本seq-to-seq模型的方法是加入attention机制。记encoder和decoder隐藏状态分别是
$ (e_{1}, , e_{n}) $ 和 $ (d_{1}, , d_{m()}) $。seq-to-seq第 i 次输出了
<span class="math inline">\(d_i\)</span>，注意力机制额外计算第i步的注意力向量
<span class="math inline">\(d_i^{\prime}\)</span>，并将其和<span class="math inline">\(d_i\)</span>连接后作为隐藏状态。<span class="math inline">\(d_i^{\prime}\)</span>的计算方式如下，输入 $
(e_{1}, , e_{n}) $ 和 i 对应的权重向量 $ (a_{1}^{i}, , a_{n}^{i})
$做点乘。</p>
<p><span class="math display">\[
d_{i} = \sum_{j=1}^{n} a_{j}^{i} e_{j}
\]</span></p>
$ (a_{1}^{i}, , a_{n}^{i}) $ 是向量 $ (u_{1}^{i}, , u_{n}^{i}) $
softmax后的值， <span class="math inline">\(u_{j}^{i}\)</span> 表示
<span class="math inline">\(d_{i}\)</span> 和 <span class="math inline">\(e_{j}\)</span>的距离，Pointer
Networks论文中的距离为如下的tanh公式。
<div>
<p><span class="math display">\[
\begin{eqnarray}
u_{j}^{i} &amp;=&amp; v^{T} \tanh \left(W_{1} e_{j}+W_{2}
d_\right) \quad j \in(1, \ldots, n) \\
a_{j}^{i} &amp;=&amp; \operatorname{softmax}\left(u_{j}^{i}\right) \quad
j \in(1, \ldots, n)
\end{eqnarray}
\]</span></p>
</div>
<h3 id="更多attention计算方式">更多Attention计算方式</h3>
<p>在<em>FloydHub Blog - Attention Mechanism
</em>中，作者清楚地解释了两种经典的attention方法，第一种称为Additive
Attention，由<em>Dzmitry Bahdanau </em> 提出，也就是Pointer
Networks中通过tanh的计算方式，第二种称为 Multiplicative
Attention，由Thang Luong*提出。</p>
Luong Attention 有三种方法计算 <span class="math inline">\(d_{i}\)</span> 和 <span class="math inline">\(e_{j}\)</span>
的距离（或者可以认为向量间的对齐得分）。
<div>
<p><span class="math display">\[
\operatorname{score} \left( d_i, e_j \right)=
\begin{cases}
d_i^{\top} e_j &amp; \text { dot } \\
d_i^{\top} W_a e_j &amp; \text { general } \\
v_a^{\top} \tanh \left( W_a \left[ d_i ; e_j \right] \right) &amp; \text
{ concat }
\end{cases}
\]</span></p>
</div>
<h3 id="pointer-networks-1">Pointer Networks</h3>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./ptr_net.png" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<p>Pointer Networks 基于Additive Attention，其创新之处在于用 <span class="math inline">\(u^i_j\)</span> 作为第j个输入的评分，即第 i
次输出为1-n个输入中 <span class="math inline">\(u^i_j\)</span>
得分最高的j作为输出，这样巧妙的解决了n不是预先固定的限制。</p>
<div>
<p><span class="math display">\[
\begin{eqnarray*}
u_{j}^{i} &amp;=&amp; v^{T} \tanh \left(W_{1} e_{j}+W_{2} d_{i}\right)
\quad j \in(1, \ldots, n) \\
p\left(C_{i} | C_{1}, \ldots, C_{i-1}, \mathcal{P}\right) &amp;=&amp;
\operatorname{softmax}\left(u^{i}\right)
\end{eqnarray*}
\]</span></p>
</div>
<h2 id="pytorch-代码实现">PyTorch 代码实现</h2>
<p>在本系列第二篇 <a href="/zh/2020/tsp-3-pointer-net/!--swig￼8--">episode
2</a>，中，我们说明过TSP数据集的格式，每一行字段意义如下</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x0, y0, x1, y1, ... output 1 v1 v2 v3 ... 1</span><br></pre></td></tr></tbody></table></figure>
<h3 id="转换成pytorch-dataset">转换成PyTorch Dataset</h3>
<p>每一个case会转换成nd.ndarray，共有五个分量，分别是 (input, input_len,
output_in, output_out, output_len) 并且分装成pytorch的 Dataset类。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPDataset</span>(<span class="hljs-params">Dataset</span>):</span></span><br><span class="line">	<span class="hljs-string">"each data item of form (input, input_len, output_in, output_out, output_len)"</span></span><br><span class="line">	data: <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]</span><br><span class="line">	</span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">		<span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span></span><br><span class="line">		<span class="hljs-built_in">input</span>, input_len, output_in, output_out, output_len = self.data[index]</span><br><span class="line">		<span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>, input_len, output_in, output_out, output_len</span><br></pre></td></tr></tbody></table></figure> <img src="/zh/2020/tsp-3-pointer-net/./data_loader.svg" alt="image info"><p></p>
<h3 id="pytorch-pad_packed_sequence-优化技巧">PyTorch
pad_packed_sequence 优化技巧</h3>
<p>PyTorch 实现 seq-to-seq 模型一般会使用
<strong>pack_padded_sequence</strong> 以及
<strong>pad_packed_sequence</strong>
来减少计算量，本质上可以认为根据pad大小分批进行矩阵运算，减少被pad的矩阵元素导致的无效运算，详细的解释可以参考
https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning#decoder-1。</p>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./ex_padded_seq.jpg" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<p>对应代码如下：</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RNNEncoder</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">	rnn: <span class="hljs-type">Union</span>[nn.LSTM, nn.GRU, nn.RNN]</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, rnn_type: <span class="hljs-built_in">str</span>, bidirectional: <span class="hljs-built_in">bool</span>, num_layers: <span class="hljs-built_in">int</span>, input_size: <span class="hljs-built_in">int</span>, hidden_size: <span class="hljs-built_in">int</span>, dropout: <span class="hljs-built_in">float</span></span>):</span></span><br><span class="line">		<span class="hljs-built_in">super</span>(RNNEncoder, self).__init__()</span><br><span class="line">		<span class="hljs-keyword">if</span> bidirectional:</span><br><span class="line">			<span class="hljs-keyword">assert</span> hidden_size % <span class="hljs-number">2</span> == <span class="hljs-number">0</span></span><br><span class="line">			hidden_size = hidden_size // <span class="hljs-number">2</span></span><br><span class="line">		self.rnn = rnn_init(rnn_type, input_size=input_size, hidden_size=hidden_size, bidirectional=bidirectional,num_layers=num_layers, dropout=dropout)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, src: Tensor, src_lengths: Tensor, hidden: Tensor = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, Tensor]:</span></span><br><span class="line">		lengths = src_lengths.view(-<span class="hljs-number">1</span>).tolist()</span><br><span class="line">		packed_src = pack_padded_sequence(src, lengths)</span><br><span class="line">		memory_bank, hidden_final = self.rnn(packed_src, hidden)</span><br><span class="line">		memory_bank = pad_packed_sequence(memory_bank)[<span class="hljs-number">0</span>]</span><br><span class="line">		<span class="hljs-keyword">return</span> memory_bank, hidden_final</span><br></pre></td></tr></tbody></table></figure>
<h3 id="注意力机制相关代码">注意力机制相关代码</h3>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Attention</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">	linear_out: nn.Linear</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dim: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">		<span class="hljs-built_in">super</span>(Attention, self).__init__()</span><br><span class="line">		self.linear_out = nn.Linear(dim * <span class="hljs-number">2</span>, dim, bias=<span class="hljs-literal">False</span>)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score</span>(<span class="hljs-params">self, src: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">		batch_size, src_len, dim = src.size()</span><br><span class="line">		_, target_len, _ = target.size()</span><br><span class="line">		target_ = target</span><br><span class="line">		src_ = src.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span><br><span class="line">		<span class="hljs-keyword">return</span> torch.bmm(target_, src_)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, src: Tensor, target: Tensor, src_lengths: Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, Tensor]:</span></span><br><span class="line">		<span class="hljs-keyword">assert</span> target.dim() == <span class="hljs-number">3</span></span><br><span class="line"></span><br><span class="line">		batch_size, src_len, dim = src.size()</span><br><span class="line">		_, target_len, _ = target.size()</span><br><span class="line"></span><br><span class="line">		align_score = self.score(src, target)</span><br><span class="line"></span><br><span class="line">		mask = sequence_mask(src_lengths)</span><br><span class="line">		<span class="hljs-comment"># (batch_size, max_len) -&gt; (batch_size, 1, max_len)</span></span><br><span class="line">		mask = mask.unsqueeze(<span class="hljs-number">1</span>)</span><br><span class="line">		align_score.data.masked_fill_(~mask, -<span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>))</span><br><span class="line">		align_score = F.softmax(align_score, -<span class="hljs-number">1</span>)</span><br><span class="line"></span><br><span class="line">		c = torch.bmm(align_score, src)</span><br><span class="line"></span><br><span class="line">		concat_c = torch.cat([c, target], -<span class="hljs-number">1</span>)</span><br><span class="line">		attn_h = self.linear_out(concat_c)</span><br><span class="line"></span><br><span class="line">		<span class="hljs-keyword">return</span> attn_h, align_score</span><br></pre></td></tr></tbody></table></figure>
<h2 id="参考资料">参考资料</h2>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-sutton-cartpole-sarsa-qlearning/" itemprop="url">通过代码学Sutton强化学习：SARSA、Q-Learning和Expected SARSA时序差分算法训练CartPole</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-10-16T18:45:01.000Z" itemprop="datePublished">10月 17 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            16 分钟 读完 (约 2450 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>这一期我们进入第六章：时序差分学习（Temporal-Difference
Learning）。TD
Learning本质上是加了bootstrapping的蒙特卡洛（MC），也是model-free的方法，但实践中往往比蒙特卡洛收敛更快。我们选取OpenAI
Gym中经典的CartPole环境来讲解TD。更多相关内容，欢迎关注 <strong>本公众号
MyEncyclopedia</strong>。</p>
<h2 id="cartpole-openai-环境">CartPole OpenAI 环境</h2>
<p>如图所示，小车上放了一根杆，杆会根据物理系统定理因重力而倒下，我们可以控制小车往左或者往右，目的是尽可能地让杆保持树立状态。</p>
<figure>
<img src="/zh/2020/rl-sutton-cartpole-sarsa-qlearning/cartpole_intro.gif">
<figcaption>
CartPole OpenAI Gym
</figcaption>
</figure>
<p>CartPole
观察到的状态是四维的float值，分别是车位置，车速度，杆角度和杆角速度。下表为四个维度的值范围。给到小车的动作，即action
space，只有两种：0，表示往左推；1，表示往右推。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Min</th>
<th>Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cart Position</td>
<td>-4.8</td>
<td>4.8</td>
</tr>
<tr class="even">
<td>Cart Velocity</td>
<td>-Inf</td>
<td>Inf</td>
</tr>
<tr class="odd">
<td>Pole Angle</td>
<td>-0.418 rad (-24 deg)</td>
<td>0.418 rad (24 deg)</td>
</tr>
<tr class="even">
<td>Pole Angular Velocity</td>
<td>-Inf</td>
<td>Inf</td>
</tr>
</tbody>
</table>
<h3 id="离散化连续状态">离散化连续状态</h3>
<p>从上所知，CartPole step()
函数返回了4维ndarray，类型为float32的连续状态空间。对于传统的tabular方法来说第一步必须离散化状态，目的是可以作为Q
table的主键来查找。下面定义的State类型是离散化后的具体类型，另外 Action
类型已经是0和1，不需要做离散化处理。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">State = <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>]</span><br><span class="line">Action = <span class="hljs-built_in">int</span></span><br></pre></td></tr></tbody></table></figure>
<p>离散化处理时需要考虑的一个问题是如何设置每个维度的分桶策略。分桶策略会决定性地影响训练的效果。原则上必须将和action以及reward强相关的维度做细粒度分桶，弱相关或者无关的维度做粗粒度分桶。举个例子，小车位置本身并不能影响Agent采取的下一动作，当给定其他三维状态的前提下，因此我们对小车位置这一维度仅设置一个桶（bucket
size=1）。而杆的角度和角速度是决定下一动作的关键因素，因此我们分别设置成6个和12个。</p>
<p>以下是离散化相关代码，四个维度的 buckets=(1, 2, 6,
12)。self.q是action value的查找表，具体类型是shape 为 (1, 2, 6, 12, 2)
的ndarray。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CartPoleAbstractAgent</span>(<span class="hljs-params">metaclass=abc.ABCMeta</span>):</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, buckets=(<span class="hljs-params"><span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">12</span></span>), discount=<span class="hljs-number">0.98</span>, lr_min=<span class="hljs-number">0.1</span>, epsilon_min=<span class="hljs-number">0.1</span></span>):</span></span><br><span class="line">        self.env = gym.make(<span class="hljs-string">'CartPole-v0'</span>)</span><br><span class="line"></span><br><span class="line">        env = self.env</span><br><span class="line">        <span class="hljs-comment"># [position, velocity, angle, angular velocity]</span></span><br><span class="line">        self.dims_config = [(env.observation_space.low[<span class="hljs-number">0</span>], env.observation_space.high[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>),</span><br><span class="line">                            (-<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">1</span>),</span><br><span class="line">                            (env.observation_space.low[<span class="hljs-number">2</span>], env.observation_space.high[<span class="hljs-number">2</span>], <span class="hljs-number">6</span>),</span><br><span class="line">                            (-math.radians(<span class="hljs-number">50</span>) / <span class="hljs-number">1.</span>, math.radians(<span class="hljs-number">50</span>) / <span class="hljs-number">1.</span>, <span class="hljs-number">12</span>)]</span><br><span class="line">        self.q = np.zeros(buckets + (self.env.action_space.n,))</span><br><span class="line">        self.pi = np.zeros_like(self.q)</span><br><span class="line">        self.pi[:] = <span class="hljs-number">1.0</span> / env.action_space.n</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">to_bin_idx</span>(<span class="hljs-params">self, val: <span class="hljs-built_in">float</span>, lower: <span class="hljs-built_in">float</span>, upper: <span class="hljs-built_in">float</span>, bucket_num: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        percent = (val + <span class="hljs-built_in">abs</span>(lower)) / (upper - lower)</span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-built_in">min</span>(bucket_num - <span class="hljs-number">1</span>, <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">int</span>(<span class="hljs-built_in">round</span>((bucket_num - <span class="hljs-number">1</span>) * percent))))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">discretize</span>(<span class="hljs-params">self, obs: np.ndarray</span>) -&gt; State:</span></span><br><span class="line">        discrete_states = <span class="hljs-built_in">tuple</span>([self.to_bin_idx(obs[d], *self.dims_config[d]) <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(obs))])</span><br><span class="line">        <span class="hljs-keyword">return</span> discrete_states</span><br></pre></td></tr></tbody></table></figure>
<p>train() 方法串联起来 agent 和 env 交互的流程，包括从 env
得到连续状态转换成离散状态，更新 Agent 的 Q table 甚至
Agent的执行policy，choose_action会根据执行 policy 选取action。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">self, num_episodes=<span class="hljs-number">2000</span></span>):</span></span><br><span class="line">    <span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_episodes):</span><br><span class="line">        <span class="hljs-built_in">print</span>(e)</span><br><span class="line">        s: State = self.discretize(self.env.reset())</span><br><span class="line"></span><br><span class="line">        self.adjust_learning_rate(e)</span><br><span class="line">        self.adjust_epsilon(e)</span><br><span class="line">        done = <span class="hljs-literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:</span><br><span class="line">            action: Action = self.choose_action(s)</span><br><span class="line">            obs, reward, done, _ = self.env.step(action)</span><br><span class="line">            s_next: State = self.discretize(obs)</span><br><span class="line">            a_next = self.choose_action(s_next)</span><br><span class="line">            self.update_q(s, action, reward, s_next, a_next)</span><br><span class="line">            s = s_next</span><br></pre></td></tr></tbody></table></figure>
<p>choose_action 的默认实现为基于现有 Q table 的 <span class="math inline">\(\epsilon\)</span>-greedy 策略。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">choose_action</span>(<span class="hljs-params">self, state</span>) -&gt; Action:</span></span><br><span class="line">    <span class="hljs-keyword">if</span> np.random.random() &lt; self.epsilon:</span><br><span class="line">        <span class="hljs-keyword">return</span> self.env.action_space.sample()</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        <span class="hljs-keyword">return</span> np.argmax(self.q[state])</span><br></pre></td></tr></tbody></table></figure>
<p>抽象出公共的基类代码 CartPoleAbstractAgent
之后，SARSA、Q-Learning和Expected SARSA只需要复写 update_q
抽象方法即可。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CartPoleAbstractAgent</span>(<span class="hljs-params">metaclass=abc.ABCMeta</span>):</span></span><br><span class="line"><span class="hljs-meta">    @abc.abstractmethod</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_q</span>(<span class="hljs-params">self, s: State, a: Action, r, s_next: State, a_next: Action</span>):</span></span><br><span class="line">        <span class="hljs-keyword">pass</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="td-learning的精髓">TD Learning的精髓</h2>
<p>在上一期，本公众号 MyEncyclopedia 的<a href="/zh/2020/rl-sutton-cartpole-sarsa-qlearning/!--swig￼8--">21点游戏的蒙特卡洛On-Policy控制</a>介绍了Monte
Carlo方法，知道MC需要在环境中模拟直至最终结局。若记<span class="math inline">\(G_t\)</span>为t步以后的最终return，则 MC online
update 版本更新为：</p>
<p><span class="math display">\[
V(S_t) \leftarrow V(S_t) + \alpha[G_{t} - V(S_t)]
\]</span></p>
<p>可以认为 <span class="math inline">\(V(S_t)\)</span> 向着目标为 <span class="math inline">\(G_t\)</span> 更新了一小步。</p>
<p>而TD方法可以只模拟下一步，得到 <span class="math inline">\(R_{t+1}\)</span>，而余下步骤的return，<span class="math inline">\(G_t - R_{t+1}\)</span> 用已有的 <span class="math inline">\(V(S_{t+1})\)</span>
来估计，或者统计上称作bootstrapping。这样 TD 的更新目标值变成 <span class="math inline">\(R_{t+1} + \gamma V(S_{t+1})\)</span>，整体online
update 公式则为： <span class="math display">\[
V(S_t) \leftarrow V(S_t) + \alpha[R_{t+1} + \gamma V(S_{t+1})- V(S_t)]
\]</span></p>
<p>概念上，如果只使用下一步 <span class="math inline">\(R_{t+1}\)</span>
值然后bootstrap称为
TD(0)，用于区分使用多步后的reward的TD方法。另外，变化的数值 <span class="math inline">\(R_{t+1} + \gamma V(S_{t+1})- V(S_t)\)</span>
称为TD error。</p>
<p>另外一个和Monte Carlo的区别在于一般TD方法保存更精细的Q值，<span class="math inline">\(Q(S_t,
A_t)\)</span>，并用Q值来boostrap，而MC一般用V值也可用Q值。</p>
<h2 id="sarsa-on-policy-td-控制">SARSA: On-policy TD 控制</h2>
<p>SARSA的命名源于一次迭代产生了五元组 <span class="math inline">\(S_t，A_t，R_{t+1}，S_{t+1}，A_{t+1}\)</span>。SARSA利用五个值做
action-value的 online update：</p>
<p><span class="math display">\[
Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha[R_{t+1}+\gamma Q(S_{t+1},
A_{t+1}) - Q(S_t,A_t)]
\]</span></p>
<p>对应的Q table更新实现为： </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SarsaAgent</span>(<span class="hljs-params">CartPoleAbstractAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_q</span>(<span class="hljs-params">self, s: State, a: Action, r, s_next: State, a_next: Action</span>):</span></span><br><span class="line">        self.q[s][a] += self.lr * (r + self.discount * (self.q[s_next][a_next]) - self.q[s][a])</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>SARSA 在执行policy
后的Q值更新是对于针对于同一个policy的，完成了一次策略迭代（policy
iteration），这个特点区分于后面的Q-learning算法，这也是SARSA 被称为
On-policy 的原因。下面是完整算法伪代码。</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Sarsa (on-policy TD Control) for estimating } Q \approx
q_{*} \\
&amp; \text{Algorithm parameters: step size }\alpha \in ({0,1}]\text{,
small }\epsilon &gt; 0 \\
&amp; \text{Initialize }Q(s,a),  \text{for all } s \in \mathcal{S}^{+},
a \in \mathcal{A}(s) \text{, arbitrarily except that } Q(terminal,
\cdot) = 0 \\
&amp; \text{Loop for each episode:}\\
&amp; \quad \text{Initialize }S\\
&amp; \quad \text{Choose } A \text{ from } S \text{ using policy derived
from } Q \text{ (e.g., } \epsilon\text{-greedy)} \\
&amp; \quad \text{Loop for each step of episode:} \\
&amp; \quad \quad \text{Take action }A,  \text { observe } R, S^{\prime}
\\
&amp; \quad \quad \text{Choose  }A^{\prime} \text { from  } S^{\prime}
\text{ using policy derived from } Q \text{ (e.g., }
\epsilon\text{-greedy)} \\
&amp; \quad \quad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma
Q(S^{\prime}, A^{\prime}) - Q(S,A)] \\
&amp; \quad \quad S \leftarrow S^{\prime}; A \leftarrow A^{\prime} \\
&amp; \quad \text{until }S\text{ is terminal} \\
\end{align*}
\]</span></p>
</div>
<h3 id="sarsa-训练分析">SARSA 训练分析</h3>
<p>SARSA收敛较慢，1000次episode后还无法持久稳定，后面的Q-learning 和
Expected Sarsa 都可以在1000次episode学习长时间保持不倒的状态。</p>
<figure>
<img src="/zh/2020/rl-sutton-cartpole-sarsa-qlearning/cartpole_sarsa_1000.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="q-learning-off-policy-td-控制">Q-Learning: Off-policy TD
控制</h2>
<p>Q-Learning 是深度学习时代前强化学习领域中的著名算法，它的 online
update 公式为： <span class="math display">\[
Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha[R_{t+1}+\gamma
\max_{a}Q(S_{t+1}, a) - Q(S_t,A_t)]
\]</span></p>
<p>对应的 update_q() 方法具体实现 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QLearningAgent</span>(<span class="hljs-params">CartPoleAbstractAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_q</span>(<span class="hljs-params">self, s: State, a: Action, r, s_next: State, a_next: Action</span>):</span></span><br><span class="line">        self.q[s][a] += self.lr * (r + self.discount * np.<span class="hljs-built_in">max</span>(self.q[s_next]) - self.q[s][a])</span><br></pre></td></tr></tbody></table></figure><p></p>
本质上用现有的Q table中最好的action来bootrap 对应的最佳Q值，推导如下：
<div>
<p><span class="math display">\[
\begin{aligned}
q_{*}(s, a) &amp;=\mathbb{E}\left[R_{t+1}+\gamma \max _{a^{\prime}}
q_{*}\left(S_{t+1}, a^{\prime}\right) \mid S_{t}=s, A_{t}=a\right] \\
&amp;=\mathbb{E}[R \mid S_{t}=s, A_{t}=a] + \gamma\sum_{s^{\prime}}
p\left(s^{\prime}\mid s, a\right)\max _{a^{\prime}}
q_{*}\left(s^{\prime}, a^{\prime}\right) \\
&amp;\approx r + \gamma \max _{a^{\prime}} q_{*}\left(s^{\prime},
a^{\prime}\right)
\end{aligned}
\]</span></p>
</div>
<p>Q-Learning 被称为 off-policy 的原因是它并没有完成一次policy
iteration，而是直接用已有的 Q 来不断近似 <span class="math inline">\(Q_{*}\)</span>。</p>
<p>对比下面的Q-Learning 伪代码和之前的 SARSA
版本可以发现，Q-Learning少了一次模拟后的 <span class="math inline">\(A_{t+1}\)</span>，这也是Q-Learning
中执行policy和预估Q值（即off-policy）分离的一个特征。</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Q-learning (off-policy TD Control) for estimating } \pi
\approx \pi_{*} \\
&amp; \text{Algorithm parameters: step size }\alpha \in ({0,1}]\text{,
small }\epsilon &gt; 0 \\
&amp; \text{Initialize }Q(s,a),  \text{for all } s \in \mathcal{S}^{+},
a \in \mathcal{A}(s) \text{, arbitrarily except that } Q(terminal,
\cdot) = 0 \\
&amp; \text{Loop for each episode:}\\
&amp; \quad \text{Initialize }S\\
&amp; \quad \text{Loop for each step of episode:} \\
&amp; \quad \quad \text{Choose } A \text{ from } S \text{ using policy
derived from } Q \text{ (e.g., } \epsilon\text{-greedy)} \\
&amp; \quad \quad \text{Take action }A,  \text { observe } R, S^{\prime}
\\
&amp; \quad \quad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma
\max_{a}Q(S^{\prime}, a) - Q(S,A)] \\
&amp; \quad \quad S \leftarrow S^{\prime}\\
&amp; \quad \text{until }S\text{ is terminal} \\
\end{align*}
\]</span></p>
</div>
<h3 id="q-learning-训练分析">Q-Learning 训练分析</h3>
<p>Q-Learning 1000次episode就可以持久稳定住。</p>
<figure>
<img src="/zh/2020/rl-sutton-cartpole-sarsa-qlearning/cartpole_exp_sarsa_1000.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="sarsa-改进版-expected-sarsa">SARSA 改进版 Expected SARSA</h2>
<p>Expected SARSA 改进了 SARSA
的地方在于考虑到了在某一状态下的现有策略动作分布，以此来减少variance，加快收敛，具体更新规则为：</p>
<div>
<p><span class="math display">\[
\begin{aligned}
Q(S_t,A_t) &amp;\leftarrow Q(S_t,A_t) + \alpha[R_{t+1}+\gamma
\mathbb{E}_{\pi}[Q(S_{t+1}, A_{t+1} \mid S_{t+1})] - Q(S_t,A_t)] \\
&amp;\leftarrow Q(S_t,A_t) + \alpha[R_{t+1}+\gamma \sum_{a}
\pi\left(a\mid S_{t+1}\right) Q(S_{t+1}, a) - Q(S_t,A_t)] \\
\end{aligned}
\]</span></p>
</div>
<p>注意在实现中，update_q() 不仅更新了Q table，还显示更新了执行policy
<span class="math inline">\(\pi\)</span>。 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ExpectedSarsaAgent</span>(<span class="hljs-params">CartPoleAbstractAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_q</span>(<span class="hljs-params">self, s: State, a: Action, r, s_next: State, a_next: Action</span>):</span></span><br><span class="line">        self.q[s][a] = self.q[s][a] + self.lr * (r + self.discount * np.dot(self.pi[s_next], self.q[s_next]) - self.q[s][a])</span><br><span class="line">        <span class="hljs-comment"># update pi[s]</span></span><br><span class="line">        best_a = np.random.choice(np.where(self.q[s] == <span class="hljs-built_in">max</span>(self.q[s]))[<span class="hljs-number">0</span>])</span><br><span class="line">        n_actions = self.env.action_space.n</span><br><span class="line">        self.pi[s][:] = self.epsilon / n_actions</span><br><span class="line">        self.pi[s][best_a] = <span class="hljs-number">1</span> - (n_actions - <span class="hljs-number">1</span>) * (self.epsilon / n_actions)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>同样的，Expected SARSA 1000次迭代也能比较好的学到最佳policy。</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/leetcode-matrix-power/" itemprop="url">Leetcode矩阵快速幂运算解法</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-10-06T18:45:01.000Z" itemprop="datePublished">10月 7 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            15 分钟 读完 (约 2259 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>快速幂运算是一种利用位运算和DP思想求的<span class="math inline">\(x^n\)</span>的数值算法，它将时间复杂度<span class="math inline">\(O(n)\)</span>降到<span class="math inline">\(O(log(n))\)</span>。快速幂运算结合矩阵乘法，可以巧解不少DP问题。本篇会由浅入深，从最基本的快速幂运算算法，到应用矩阵快速幂运算解DP问题，结合三道Leetcode题目来具体讲解。</p>
<h2 id="leetcode-50.-powx-n-medium">Leetcode 50. Pow(x, n) (Medium)</h2>
<p><a target="_blank" rel="noopener" href="https://leetcode.com/problems/powx-n/">Leetcode 50. Pow(x,
n)</a> 是实数的快速幂运算问题，题目如下。</p>
<p>Implement <a target="_blank" rel="noopener" href="http://www.cplusplus.com/reference/valarray/pow/">pow(<em>x</em>,
<em>n</em>)</a>, which calculates <em>x</em> raised to the power
<em>n</em> (i.e. <span class="math inline">\(x^n\)</span>).</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: x = 2.00000, n = 10</span><br><span class="line">Output: 1024.00000</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 2:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: x = 2.10000, n = 3</span><br><span class="line">Output: 9.26100</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 3:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: x = 2.00000, n = -2</span><br><span class="line">Output: 0.25000</span><br><span class="line">Explanation: 2-2 = 1/22 = 1/4 = 0.25</span><br></pre></td></tr></tbody></table></figure>
<h3 id="快速幂运算解法分析">快速幂运算解法分析</h3>
<p>假设n是32位的int类型，将n写成二进制形式，那么n可以写成最多32个某位为
1（第k位为1则值为<span class="math inline">\(2^k\)</span>）的和。那么<span class="math inline">\(x^n\)</span>最多可以由32个 <span class="math inline">\(x^{2^k}\)</span>的乘积组合，例如：</p>
<div>
<p><span class="math display">\[
x^{\text{10011101}_{2}} = x^{1} \times x^{\text{100}_{2}} \times
x^{\text{1000}_{2}} \times x^{\text{10000}_{2}} \times
x^{\text{10000000}_{2}}
\]</span></p>
</div>
<p>快速幂运算的特点就是通过32次循环，每次循环根据上轮<span class="math inline">\(x^{2^k}\)</span>的值进行平方后得出这一轮的值：<span class="math inline">\(x^{2^k} \times x^{2^k} =
x^{2^{k+1}}\)</span>，即循环计算出如下数列</p>
<div>
<p><span class="math display">\[
x^{1}, x^2=x^{\text{10}_{2}}, x^4=x^{\text{100}_{2}},
x^8=x^{\text{1000}_{2}}, x^{16}=x^{\text{10000}_{2}}, ..., x^{128} =
x^{\text{10000000}_{2}}
\]</span></p>
</div>
<p>在循环时，如果n的二进制形式在本轮对应的位的值是1，则将这次结果累乘计入最终结果。</p>
<p>下面是python 3 的代码，由于循环为32次，所以容易看出算法复杂度为 <span class="math inline">\(O(log(n))\)</span>。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 32 ms, faster than 54.28% of Python3 online submissions for Pow(x, n).</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 14.2 MB, less than 5.04% of Python3 online submissions for Pow(x, n).</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">myPow</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">float</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">        ret = <span class="hljs-number">1.0</span></span><br><span class="line">        i = <span class="hljs-built_in">abs</span>(n)</span><br><span class="line">        <span class="hljs-keyword">while</span> i != <span class="hljs-number">0</span>:</span><br><span class="line">            <span class="hljs-keyword">if</span> i &amp; <span class="hljs-number">1</span>:</span><br><span class="line">                ret *= x</span><br><span class="line">            x *= x</span><br><span class="line">            i = i &gt;&gt; <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span> / ret <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> ret</span><br></pre></td></tr></tbody></table></figure>
<p>对应的 Java 的代码。</p>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">// AC</span></span><br><span class="line"><span class="hljs-comment">// Runtime: 1 ms, faster than 42.98% of Java online submissions for Pow(x, n).</span></span><br><span class="line"><span class="hljs-comment">// Memory Usage: 38.7 MB, less than 48.31% of Java online submissions for Pow(x, n).</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> </span>{</span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">double</span> <span class="hljs-title">myPow</span><span class="hljs-params">(<span class="hljs-keyword">double</span> x, <span class="hljs-keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">double</span> ret = <span class="hljs-number">1.0</span>;</span><br><span class="line">        <span class="hljs-keyword">long</span> i = Math.abs((<span class="hljs-keyword">long</span>) n);</span><br><span class="line">        <span class="hljs-keyword">while</span> (i != <span class="hljs-number">0</span>) {</span><br><span class="line">            <span class="hljs-keyword">if</span> ((i &amp; <span class="hljs-number">1</span>) &gt; <span class="hljs-number">0</span>) {</span><br><span class="line">                ret *= x;</span><br><span class="line">            }</span><br><span class="line">            x *= x;</span><br><span class="line">            i = i &gt;&gt; <span class="hljs-number">1</span>;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> n &lt; <span class="hljs-number">0</span> ? <span class="hljs-number">1.0</span> / ret : ret;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="矩阵快速幂运算">矩阵快速幂运算</h2>
<p>快速幂运算也可以应用到计算矩阵的幂，即上面的x从实数变为方形矩阵。实现上，矩阵的幂需要矩阵乘法：$
A_{r c} B_{c p}$ ，Python中可以用numpy的 np.matmul(A,
B)来完成，而Java版本中我们手动实现简单的矩阵相乘算法，从三重循环看出其算法复杂度为<span class="math inline">\(O(r \times c \times p)\)</span>。</p>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span>[][] matrixProd(<span class="hljs-keyword">int</span>[][] A, <span class="hljs-keyword">int</span>[][] B) {</span><br><span class="line">    <span class="hljs-keyword">int</span> R = A.length;</span><br><span class="line">    <span class="hljs-keyword">int</span> C = B[<span class="hljs-number">0</span>].length;</span><br><span class="line">    <span class="hljs-keyword">int</span> P = A[<span class="hljs-number">0</span>].length;</span><br><span class="line">    <span class="hljs-keyword">int</span>[][] ret = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[R][C];</span><br><span class="line">    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> r = <span class="hljs-number">0</span>; r &lt; R; r++) {</span><br><span class="line">        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> c = <span class="hljs-number">0</span>; c &lt; C; c++) {</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> p = <span class="hljs-number">0</span>; p &lt; P; p++) {</span><br><span class="line">                ret[r][c] += A[r][p] * B[p][c];</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="hljs-keyword">return</span> ret;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="leetcode-509.-fibonacci-number-easy">Leetcode 509. Fibonacci
Number (Easy)</h2>
<p>有了快速矩阵幂运算，我们来看看如何具体解题。<a target="_blank" rel="noopener" href="https://leetcode.com/problems/fibonacci-number/">Fibonacci问题</a>作为最基本的DP问题，在上一篇<a target="_blank" rel="noopener" href="https://myencyclopedia.top/blog/zh/post/leetcode-679-24-game/">Leetcode
679 24 Game 的 Python
函数式实现</a>中我们用python独有的yield来巧解，这次再拿它来做演示。</p>
<p>The <strong>Fibonacci numbers</strong>, commonly denoted F(n) form a
sequence, called the <strong>Fibonacci sequence</strong>, such that each
number is the sum of the two preceding ones, starting from 0 and 1. That
is,</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">F(0) = 0,   F(1) = 1</span><br><span class="line">F(N) = F(N - 1) + F(N - 2), for N &gt; 1.</span><br></pre></td></tr></tbody></table></figure>
<p>Given N, calculate F(N).</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: 2</span><br><span class="line">Output: 1</span><br><span class="line">Explanation: F(2) = F(1) + F(0) = 1 + 0 = 1.</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 2:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: 3</span><br><span class="line">Output: 2</span><br><span class="line">Explanation: F(3) = F(2) + F(1) = 1 + 1 = 2.</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 3:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: 4</span><br><span class="line">Output: 3</span><br><span class="line">Explanation: F(4) = F(3) + F(2) = 2 + 1 = 3.</span><br></pre></td></tr></tbody></table></figure>
<h3 id="转换为矩阵幂运算">转换为矩阵幂运算</h3>
Fibonacci的二阶递推式如下：
<div>
<p><span class="math display">\[
\begin{align*}
F(n) =&amp; F(n-1) + F(n-2) \\
F(n-1) =&amp; F(n-1)
\end{align*}
\]</span></p>
</div>
等价的矩阵递推形式为：
<div>
<p><span class="math display">\[
\begin{bmatrix}F(n)\\F(n-1)\end{bmatrix} = \begin{bmatrix}1 &amp; 1\\1
&amp; 0\end{bmatrix} \begin{bmatrix}F(n-1)\\F(n-2)\end{bmatrix}
\]</span></p>
</div>
也就是每轮左乘一个2维矩阵。其循环形式为，即矩阵幂的形式：
<div>
<p><span class="math display">\[
\begin{bmatrix}F(n)\\F(n-1)\end{bmatrix} = \begin{bmatrix}1 &amp; 1\\1
&amp; 0\end{bmatrix}^{n-1} \begin{bmatrix}F(1)\\F(0)\end{bmatrix}
\]</span></p>
</div>
<h3 id="ac代码">AC代码</h3>
<p>有了上面的矩阵幂公式，代码稍作改动即可。Java 版本代码。</p>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">/**</span></span><br><span class="line"><span class="hljs-comment"> * AC</span></span><br><span class="line"><span class="hljs-comment"> * Runtime: 0 ms, faster than 100.00% of Java online submissions for Fibonacci Number.</span></span><br><span class="line"><span class="hljs-comment"> * Memory Usage: 37.9 MB, less than 18.62% of Java online submissions for Fibonacci Number.</span></span><br><span class="line"><span class="hljs-comment"> *</span></span><br><span class="line"><span class="hljs-comment"> * Method: Matrix Fast Power Exponentiation</span></span><br><span class="line"><span class="hljs-comment"> * Time Complexity: O(log(N))</span></span><br><span class="line"><span class="hljs-comment"> **/</span></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> </span>{</span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">fib</span><span class="hljs-params">(<span class="hljs-keyword">int</span> N)</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">if</span> (N &lt;= <span class="hljs-number">1</span>) {</span><br><span class="line">            <span class="hljs-keyword">return</span> N;</span><br><span class="line">        }</span><br><span class="line">        <span class="hljs-keyword">int</span>[][] M = {{<span class="hljs-number">1</span>, <span class="hljs-number">1</span>}, {<span class="hljs-number">1</span>, <span class="hljs-number">0</span>}};</span><br><span class="line">        <span class="hljs-comment">// powers = M^(N-1)</span></span><br><span class="line">        N--;</span><br><span class="line">        <span class="hljs-keyword">int</span>[][] powerDouble = M;</span><br><span class="line">        <span class="hljs-keyword">int</span>[][] powers = {{<span class="hljs-number">1</span>, <span class="hljs-number">0</span>}, {<span class="hljs-number">0</span>, <span class="hljs-number">1</span>}};</span><br><span class="line">        <span class="hljs-keyword">while</span> (N &gt; <span class="hljs-number">0</span>) {</span><br><span class="line">            <span class="hljs-keyword">if</span> (N % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>) {</span><br><span class="line">                powers = matrixProd(powers, powerDouble);</span><br><span class="line">            }</span><br><span class="line">            powerDouble = matrixProd(powerDouble, powerDouble);</span><br><span class="line">            N = N / <span class="hljs-number">2</span>;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> powers[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span>[][] matrixProd(<span class="hljs-keyword">int</span>[][] A, <span class="hljs-keyword">int</span>[][] B) {</span><br><span class="line">        <span class="hljs-keyword">int</span> R = A.length;</span><br><span class="line">        <span class="hljs-keyword">int</span> C = B[<span class="hljs-number">0</span>].length;</span><br><span class="line">        <span class="hljs-keyword">int</span> P = A[<span class="hljs-number">0</span>].length;</span><br><span class="line">        <span class="hljs-keyword">int</span>[][] ret = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[R][C];</span><br><span class="line">        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> r = <span class="hljs-number">0</span>; r &lt; R; r++) {</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> c = <span class="hljs-number">0</span>; c &lt; C; c++) {</span><br><span class="line">                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> p = <span class="hljs-number">0</span>; p &lt; P; p++) {</span><br><span class="line">                    ret[r][c] += A[r][p] * B[p][c];</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="hljs-keyword">return</span> ret;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>Python 3的numpy.matmul() 版本代码。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 256 ms, faster than 26.21% of Python3 online submissions for Fibonacci Number.</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 29.4 MB, less than 5.25% of Python3 online submissions for Fibonacci Number.</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fib</span>(<span class="hljs-params">self, N: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-keyword">if</span> N &lt;= <span class="hljs-number">1</span>:</span><br><span class="line">            <span class="hljs-keyword">return</span> N</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">        F = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])</span><br><span class="line"></span><br><span class="line">        N -= <span class="hljs-number">1</span></span><br><span class="line">        powerDouble = F</span><br><span class="line">        powers = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]])</span><br><span class="line">        <span class="hljs-keyword">while</span> N &gt; <span class="hljs-number">0</span>:</span><br><span class="line">            <span class="hljs-keyword">if</span> N % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:</span><br><span class="line">                powers = np.matmul(powers, powerDouble)</span><br><span class="line">            powerDouble = np.matmul(powerDouble, powerDouble)</span><br><span class="line">            N = N // <span class="hljs-number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> powers[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure>
<p>或者也可以直接调用numpy.matrix_power() 代替手动的快速矩阵幂运算。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 116 ms, faster than 26.25% of Python3 online submissions for Fibonacci Number.</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 29.2 MB, less than 5.25% of Python3 online submissions for Fibonacci Number.</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fib</span>(<span class="hljs-params">self, N: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-keyword">if</span> N &lt;= <span class="hljs-number">1</span>:</span><br><span class="line">            <span class="hljs-keyword">return</span> N</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">from</span> numpy.linalg <span class="hljs-keyword">import</span> matrix_power</span><br><span class="line">        <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line">        F = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])</span><br><span class="line">        F = matrix_power(F, N - <span class="hljs-number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> F[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="leetcode-1411.-number-of-ways-to-paint-n-3-grid-hard">Leetcode
1411. Number of Ways to Paint N × 3 Grid (Hard)</h2>
<p>下面来看一道稍难一点的DP问题，<a target="_blank" rel="noopener" href="https://leetcode.com/problems/number-of-ways-to-paint-n-3-grid/">1411.
Number of Ways to Paint N × 3 Grid</a>。</p>
<p>You have a <code>grid</code> of size <code>n x 3</code> and you want
to paint each cell of the grid with exactly one of the three colours:
<strong>Red</strong>, <strong>Yellow</strong> or <strong>Green</strong>
while making sure that no two adjacent cells have the same colour (i.e
no two cells that share vertical or horizontal sides have the same
colour).</p>
<p>You are given <code>n</code> the number of rows of the grid.</p>
<p>Return <em>the number of ways</em> you can paint this
<code>grid</code>. As the answer may grow large, the answer <strong>must
be</strong> computed modulo <code>10^9 + 7</code>.</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: n = 1</span><br><span class="line">Output: 12</span><br><span class="line">Explanation: There are 12 possible way to paint the grid as shown:</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2020/leetcode-matrix-power/1411_ex.png">
<figcaption>
</figcaption>
</figure>
<p><strong>Example 2:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: n = 2</span><br><span class="line">Output: 54</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 3:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: n = 3</span><br><span class="line">Output: 246</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 4:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: n = 7</span><br><span class="line">Output: 106494</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Example 5:</strong></p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: n = 5000</span><br><span class="line">Output: 30228214</span><br></pre></td></tr></tbody></table></figure>
<h3 id="标准dp解法">标准DP解法</h3>
<p>分析题目容易发现第i行的状态只取决于第i-1行的状态，第i行会有两种不同状态：三种颜色都有或者只有两种颜色。这个问题容易识别出是经典的双状态DP问题，那么我们定义dp2[i]为第i行只有两种颜色的数量，dp3[i]为第i行有三种颜色的数量。</p>
<p>先考虑dp3[i]和i-1行的关系。假设第i行包含3种颜色，即dp3[i]，假设具体颜色为红，绿，黄，若i-1行包含两种颜色（即dp2[i-1]），此时dp2[i-1]只有以下2种可能：</p>
<figure>
<img src="/zh/2020/leetcode-matrix-power/f_3_2.png">
<figcaption>
dp2[i-1] -&gt; dp3[i]
</figcaption>
</figure>
还是dp3[i]
红，绿，黄情况，若i-1行包含三种颜色（从dp3[i-1]转移过来），此时dp3[i-1]也只有以下2种可能：
<figure>
<img src="/zh/2020/leetcode-matrix-power/f_3_3.png">
<figcaption>
dp3[i-1] -&gt; dp3[i]
</figcaption>
</figure>
<p>因此，dp3[i]= dp2[i-1] * 2 + dp3[i-1] * 2。</p>
<p>同理，若第i行包含两种颜色，即dp2[i]，假设具体颜色为绿，黄，绿，若i-1行是两种颜色（dp2[i-1]），此时dp2[i-1]有如下3种可能：</p>
<figure>
<img src="/zh/2020/leetcode-matrix-power/f_2_2.png">
<figcaption>
dp2[i-1] -&gt; dp2[i]
</figcaption>
</figure>
dp2[i]的另一种情况是由dp3[i-1]转移过来，则dp3[i-1]有2种可能，枚举如下：
<figure>
<img src="/zh/2020/leetcode-matrix-power/f_2_3.png">
<figcaption>
dp3[i-1] -&gt; dp2[i]
</figcaption>
</figure>
<p>因此，dp2[i] = dp2[i-1] * 3 + dp3[i-1] * 2。 初始值dp2[1] = 6，dp3[1]
= 6，最终答案为dp2[i] + dp3[i]。</p>
<p>很容易写出普通DP版本的Python 3代码，时间复杂度为<span class="math inline">\(O(n)\)</span>。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 36 ms, faster than 98.88% of Python3 online submissions for Number of Ways to Paint N × 3 Grid.</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 13.9 MB, less than 58.66% of Python3 online submissions for Number of Ways to Paint N × 3 Grid.</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numOfWays</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        MOD = <span class="hljs-number">10</span> ** <span class="hljs-number">9</span> + <span class="hljs-number">7</span></span><br><span class="line">        dp2, dp3 = <span class="hljs-number">6</span>, <span class="hljs-number">6</span></span><br><span class="line">        n -= <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">while</span> n &gt; <span class="hljs-number">0</span>:</span><br><span class="line">            dp2, dp3 = (dp2 * <span class="hljs-number">3</span> + dp3 * <span class="hljs-number">2</span>) % MOD, (dp2 * <span class="hljs-number">2</span> + dp3 * <span class="hljs-number">2</span>) % MOD</span><br><span class="line">            n -= <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">return</span> (dp2 + dp3) % MOD</span><br></pre></td></tr></tbody></table></figure>
<h3 id="快速矩阵幂运算解法">快速矩阵幂运算解法</h3>
和Fibonacci一样，我们将DP状态转移方程转换成矩阵乘法：
<div>
<p><span class="math display">\[
\begin{bmatrix}dp2(n)\\dp3(n)\end{bmatrix} = \begin{bmatrix}3 &amp; 2\\2
&amp; 2\end{bmatrix} \begin{bmatrix}dp2(n-1)\\dp3(n-1)\end{bmatrix}
\]</span></p>
</div>
代入初始值，转换成矩阵幂形式
<div>
<p><span class="math display">\[
\begin{bmatrix}dp2(n)\\dp3(n)\end{bmatrix} = \begin{bmatrix}3 &amp; 2\\2
&amp; 2\end{bmatrix}^{n-1}\begin{bmatrix}6\\6\end{bmatrix}
\]</span></p>
</div>
<p>代码几乎和Fibonacci一模一样，仅仅多了mod 计算。下面是Java版本。</p>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="hljs-comment">/**</span></span><br><span class="line"><span class="hljs-comment">AC</span></span><br><span class="line"><span class="hljs-comment">Runtime: 0 ms, faster than 100.00% of Java online submissions for Number of Ways to Paint N × 3 Grid.</span></span><br><span class="line"><span class="hljs-comment">Memory Usage: 35.7 MB, less than 97.21% of Java online submissions for Number of Ways to Paint N × 3 Grid.</span></span><br><span class="line"><span class="hljs-comment">**/</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> </span>{</span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">numOfWays</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">long</span> MOD = (<span class="hljs-keyword">long</span>) (<span class="hljs-number">1e9</span> + <span class="hljs-number">7</span>);</span><br><span class="line">        <span class="hljs-keyword">long</span>[][] ret = {{<span class="hljs-number">6</span>, <span class="hljs-number">6</span>}};</span><br><span class="line">        <span class="hljs-keyword">long</span>[][] m = {{<span class="hljs-number">3</span>, <span class="hljs-number">2</span>}, {<span class="hljs-number">2</span>, <span class="hljs-number">2</span>}};</span><br><span class="line">        n -= <span class="hljs-number">1</span>;</span><br><span class="line">        <span class="hljs-keyword">while</span>(n &gt; <span class="hljs-number">0</span>) {</span><br><span class="line">            <span class="hljs-keyword">if</span> ((n &amp; <span class="hljs-number">1</span>) &gt; <span class="hljs-number">0</span>) {</span><br><span class="line">                ret = matrixProd(ret, m, MOD);</span><br><span class="line">            }</span><br><span class="line">            m = matrixProd(m, m, MOD);</span><br><span class="line">            n &gt;&gt;= <span class="hljs-number">1</span>;</span><br><span class="line">        }</span><br><span class="line">        <span class="hljs-keyword">return</span> (<span class="hljs-keyword">int</span>) ((ret[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] + ret[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]) % MOD);</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span>[][] matrixProd(<span class="hljs-keyword">long</span>[][] A, <span class="hljs-keyword">long</span>[][] B, <span class="hljs-keyword">long</span> MOD) {</span><br><span class="line">        <span class="hljs-keyword">int</span> R = A.length;</span><br><span class="line">        <span class="hljs-keyword">int</span> C = B[<span class="hljs-number">0</span>].length;</span><br><span class="line">        <span class="hljs-keyword">int</span> P = A[<span class="hljs-number">0</span>].length;</span><br><span class="line">        <span class="hljs-keyword">long</span>[][] ret = <span class="hljs-keyword">new</span> <span class="hljs-keyword">long</span>[R][C];</span><br><span class="line">        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> r = <span class="hljs-number">0</span>; r &lt; R; r++) {</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> c = <span class="hljs-number">0</span>; c &lt; C; c++) {</span><br><span class="line">                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> p = <span class="hljs-number">0</span>; p &lt; P; p++) {</span><br><span class="line">                    ret[r][c] += A[r][p] * B[p][c];</span><br><span class="line">                    ret[r][c] = ret[r][c] % MOD;</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        <span class="hljs-keyword">return</span> ret;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>Python 3实现为</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># AC</span></span><br><span class="line"><span class="hljs-comment"># Runtime: 88 ms, faster than 39.07% of Python3 online submissions for Number of Ways to Paint N × 3 Grid.</span></span><br><span class="line"><span class="hljs-comment"># Memory Usage: 30.2 MB, less than 11.59% of Python3 online submissions for Number of Ways to Paint N × 3 Grid.</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numOfWays</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"></span><br><span class="line">        MOD = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e9</span> + <span class="hljs-number">7</span>)</span><br><span class="line">        ret = np.array([[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>]])</span><br><span class="line">        m = np.array([[<span class="hljs-number">3</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]])</span><br><span class="line"></span><br><span class="line">        n -= <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-keyword">while</span> n &gt; <span class="hljs-number">0</span>:</span><br><span class="line">            <span class="hljs-keyword">if</span> n % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:</span><br><span class="line">                ret = np.matmul(ret, m) % MOD</span><br><span class="line">            m = np.matmul(m, m) % MOD</span><br><span class="line">            n = n // <span class="hljs-number">2</span></span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-built_in">int</span>((ret[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] + ret[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]) % MOD)</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-sutton-blackjack-2/" itemprop="url">通过代码学Sutton强化学习4：21点游戏的蒙特卡洛On-Policy控制</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-09-29T18:45:01.000Z" itemprop="datePublished">9月 30 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            15 分钟 读完 (约 2204 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>这期继续Sutton强化学习第二版，第五章蒙特卡洛方法。在上期<a href="/zh/2020/rl-sutton-blackjack-2/!--swig￼5--">21点游戏的策略蒙特卡洛值预测</a>学习了如何用Monte
Carlo来预估给定策略 <span class="math inline">\(\pi\)</span> 的 <span class="math inline">\(V_{\pi}\)</span> 值之后，这一期我们用Monte
Carlo方法来解得21点游戏最佳策略 <span class="math inline">\(\pi_{*}\)</span>。</p>
<h2 id="蒙特卡洛策略提升">蒙特卡洛策略提升</h2>
<p>回顾一下，在<a href="/zh/2020/rl-sutton-blackjack-2/!--swig￼6--">Grid World
策略迭代和值迭代</a>中由于存在Policy Improvement
Theorem，我们可以利用环境dynamics信息计算出策略v值，再选取最greedy
action的方式改进策略，形成策略提示最终能够不断逼近最佳策略。 <span class="math display">\[
\pi_{0} \stackrel{\mathrm{E}}{\longrightarrow} v_{\pi_{0}}
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{1}
\stackrel{\mathrm{E}}{\longrightarrow} v_{\pi_{1}}
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{2}
\stackrel{\mathrm{E}}{\longrightarrow} \cdots
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{*}
\stackrel{\mathrm{E}}{\longrightarrow} v_{*}
\]</span> Monte Carlo Control方法搜寻最佳策略 <span class="math inline">\(\pi{*}\)</span>，是否也能沿用同样的思路呢？答案是可行的。不过，不同于第四章中我们已知环境MDP就知道状态的前后依赖关系，进而从v值中能推断出策略
<span class="math inline">\(\pi\)</span>，在Monte
Carlo方法中，环境MDP是未知的，因而我们只能从action-value中下手，通过海量Monte
Carlo试验来近似 <span class="math inline">\(q_{\pi}\)</span>。有了策略 Q
值，再和MDP策略迭代方法一样，选取最greedy
action的策略，这种策略提示方式理论上被证明了最终能够不断逼近最佳策略。
<span class="math display">\[
\pi_{0} \stackrel{\mathrm{E}}{\longrightarrow} q_{\pi_{0}}
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{1}
\stackrel{\mathrm{E}}{\longrightarrow} q_{\pi_{1}}
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{2}
\stackrel{\mathrm{E}}{\longrightarrow} \cdots
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{*}
\stackrel{\mathrm{E}}{\longrightarrow} q_{*}
\]</span></p>
<p>但是此方法有一个前提要满足，由于数据是依据策略 <span class="math inline">\(\pi_{i}\)</span>
生成的，理论上需要保证在无限次的模拟过程中，每个状态都必须被无限次访问到，才能保证最终每个状态的Q估值收敛到真实的
<span class="math inline">\(q_{*}\)</span>。满足这个前提的一个简单实现是强制随机环境初始状态，保证每个状态都能有一定概率被生成。这个思路就是
Monte Carlo Control with Exploring Starts算法，伪代码如下：</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Monte Carlo ES (Exploring Starts), for estimating } \pi
\approx \pi_{*} \\
&amp; \text{Initialize:} \\
&amp; \quad \pi(s) \in \mathcal A(s) \text{ arbitrarily for all }s \in
\mathcal{S} \\
&amp; \quad Q(s, a) \in \mathbb R \text{, arbitrarily, for all }s \in
\mathcal{S}, a \in \mathcal A(s) \\
&amp; \quad Returns(s, a) \leftarrow \text{ an empty list, for all }s
\in \mathcal{S}, a \in \mathcal A(s)\\
&amp; \\
&amp; \text{Loop forever (for episode):}\\
&amp; \quad \text{Choose } S_0\in \mathcal{S}, A_0 \in \mathcal A(S_0)
\text{ randomly such that all pairs have probability &gt; 0} \\
&amp; \quad \text{Generate an episode from } S_0, A_0 \text{, following
} \pi : S_0, A_0, R_1, S_1, A_1, R_2, ..., S_{T-1}, A_{T-1}, R_T\\
&amp; \quad G \leftarrow 0\\
&amp; \quad \text{Loop for each step of episode, } t = T-1, T-2, ...,
0:\\
&amp; \quad \quad \quad G \leftarrow \gamma G + R_{t+1}\\
&amp; \quad \quad \quad \text{Unless the pair } S_t, A_t \text{ appears
in } S_0, A_0, S_1, A_1, ..., S_{t-1}, A_{t-1}\\
&amp; \quad \quad \quad \quad \text{Append } G \text { to }Returns(S_t,
A_t) \\
&amp; \quad \quad \quad \quad Q(S_t, A_t) \leftarrow
\operatorname{average}(Returns(S_t, A_t))\\
&amp; \quad \quad \quad \quad \pi(S_t) \leftarrow
\operatorname{argmax}_a Q(S_t, a)\\
\end{align*}
\]</span></p>
</div>
<p>下面我们实现21点游戏的Monte Carlo ES
算法。21点游戏只有200个有效的状态，可以满足算法要求的生成episode前先随机选择某一状态的前提条件。</p>
<p>相对于上一篇，我们增加 ActionValue和Policy的类型定义，ActionValue表示
<span class="math inline">\(q(s, a)\)</span>
，是一个State到动作分布的Dict，Policy
类型也一样。Actions为一维ndarray，维数是离散动作数量。 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">State = <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>, <span class="hljs-built_in">bool</span>]</span><br><span class="line">Action = <span class="hljs-built_in">bool</span></span><br><span class="line">Reward = <span class="hljs-built_in">float</span></span><br><span class="line">Actions = np.ndarray</span><br><span class="line">ActionValue = <span class="hljs-type">Dict</span>[State, Actions]</span><br><span class="line">Policy = <span class="hljs-type">Dict</span>[State, Actions]</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>下面代码示例如何给定
Policy后，依据指定状态state的动作分布采样，决定下一动作。
</p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">policy: Policy</span><br><span class="line">A: ActionValue = policy[state]</span><br><span class="line">action = np.random.choice([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], p=A/<span class="hljs-built_in">sum</span>(A))</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>整个算法的 python 代码实现如下：</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mc_control_exploring_starts</span>(<span class="hljs-params">env: BlackjackEnv, num_episodes, discount_factor=<span class="hljs-number">1.0</span></span>) \</span></span><br><span class="line"><span class="hljs-function">        -&gt; <span class="hljs-type">Tuple</span>[ActionValue, Policy]:</span></span><br><span class="line">    states = <span class="hljs-built_in">list</span>(product(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>, <span class="hljs-number">22</span>), <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>), (<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>)))</span><br><span class="line">    policy = {s: np.ones(env.action_space.n) * <span class="hljs-number">1.0</span> / env.action_space.n <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> states}</span><br><span class="line">    Q = defaultdict(<span class="hljs-keyword">lambda</span>: np.zeros(env.action_space.n))</span><br><span class="line">    returns_sum = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line">    returns_count = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> episode_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_episodes + <span class="hljs-number">1</span>):</span><br><span class="line">        s0 = random.choice(states)</span><br><span class="line">        reset_env_with_s0(env, s0)</span><br><span class="line">        episode_history = gen_custom_s0_stochastic_episode(policy, env, s0)</span><br><span class="line"></span><br><span class="line">        G = <span class="hljs-number">0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(episode_history) - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):</span><br><span class="line">            s, a, r = episode_history[t]</span><br><span class="line">            G = discount_factor * G + r</span><br><span class="line">            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(s_a_r[<span class="hljs-number">0</span>] == s <span class="hljs-keyword">and</span> s_a_r[<span class="hljs-number">1</span>] == a <span class="hljs-keyword">for</span> s_a_r <span class="hljs-keyword">in</span> episode_history[<span class="hljs-number">0</span>: t]):</span><br><span class="line">                returns_sum[s, a] += G</span><br><span class="line">                returns_count[s, a] += <span class="hljs-number">1.0</span></span><br><span class="line">                Q[s][a] = returns_sum[s, a] / returns_count[s, a]</span><br><span class="line">                best_a = np.argmax(Q[s])</span><br><span class="line">                policy[s][best_a] = <span class="hljs-number">1.0</span></span><br><span class="line">                policy[s][<span class="hljs-number">1</span>-best_a] = <span class="hljs-number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> Q, policy</span><br></pre></td></tr></tbody></table></figure>
<p>在MC Exploring Starts
算法中，我们需要指定环境初始状态，一种做法是env.reset()时接受初始状态，但是考虑到不去修改第三方实现的
BlackjackEnv类，采用一个取巧的办法，在调用reset()后直接改写env
的私有变量，这个逻辑封装在 reset_env_with_s0 方法中。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reset_env_with_s0</span>(<span class="hljs-params">env: BlackjackEnv, s0: State</span>) -&gt; BlackjackEnv:</span></span><br><span class="line">    env.reset()</span><br><span class="line">    player_sum = s0[<span class="hljs-number">0</span>]</span><br><span class="line">    oppo_sum = s0[<span class="hljs-number">1</span>]</span><br><span class="line">    has_usable = s0[<span class="hljs-number">2</span>]</span><br><span class="line"></span><br><span class="line">    env.dealer[<span class="hljs-number">0</span>] = oppo_sum</span><br><span class="line">    <span class="hljs-keyword">if</span> has_usable:</span><br><span class="line">        env.player[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span></span><br><span class="line">        env.player[<span class="hljs-number">1</span>] = player_sum - <span class="hljs-number">11</span></span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        <span class="hljs-keyword">if</span> player_sum &gt; <span class="hljs-number">11</span>:</span><br><span class="line">            env.player[<span class="hljs-number">0</span>] = <span class="hljs-number">10</span></span><br><span class="line">            env.player[<span class="hljs-number">1</span>] = player_sum - <span class="hljs-number">10</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            env.player[<span class="hljs-number">0</span>] = <span class="hljs-number">2</span></span><br><span class="line">            env.player[<span class="hljs-number">1</span>] = player_sum - <span class="hljs-number">2</span></span><br><span class="line">    <span class="hljs-keyword">return</span> env</span><br></pre></td></tr></tbody></table></figure>
<h2 id="算法结果的可视化和理论对比">算法结果的可视化和理论对比</h2>
下图是有Usable Ace情况下的理论最优策略。
<figure>
<img src="/zh/2020/rl-sutton-blackjack-2/optimal_policy_usable.png">
<figcaption>
理论最佳策略（有Ace）
</figcaption>
</figure>
Monte
Carlo方法策略提示的收敛是比较慢的，下图是运行10,000,000次episode后有Usable
Ace时的策略 <span class="math inline">\(\pi_{*}^{\prime}\)</span>。对比理论最优策略，MC
ES在不少的状态下还未收敛到理论最优解。
<figure>
<img src="/zh/2020/rl-sutton-blackjack-2/mc_es_usable_policy.png">
<figcaption>
MC ES 10M的最佳策略（有Ace）
</figcaption>
</figure>
同样的，下两张图是无Usable Ace情况下的理论最优策略和试验结果的对比。
<figure>
<img src="/zh/2020/rl-sutton-blackjack-2/optimal_policy_no_usable.png">
<figcaption>
理论最佳策略（无Ace）
</figcaption>
</figure>
<figure>
<img src="/zh/2020/rl-sutton-blackjack-2/mc_es_no_usable_policy.png">
<figcaption>
MC ES 10M的最佳策略（无Ace）
</figcaption>
</figure>
下面的两张图画出了运行代码10,000,000次episode后 <span class="math inline">\(\pi{*}\)</span>的V值图。
<figure>
<img src="/zh/2020/rl-sutton-blackjack-2/mc_es_10m_usable.png">
<figcaption>
MC ES 10M的最佳V值（有Ace）
</figcaption>
</figure>
<figure>
<img src="/zh/2020/rl-sutton-blackjack-2/mc_es_10m_no_usable.png">
<figcaption>
MC ES 10M的最佳V值（无Ace）
</figcaption>
</figure>
<h2 id="exploring-starts-蒙特卡洛控制改进">Exploring Starts
蒙特卡洛控制改进</h2>
<p>为了避免Monte Carlo ES
Control在初始时必须访问到任意状态的限制，教材中介绍了一种改进算法，On-policy
first-visit MC control for <span class="math inline">\(\epsilon
\text{-soft policies}\)</span> ，它同样基于Monte Carlo 预估Q值，但用
<span class="math inline">\(\epsilon \text{-soft}\)</span>
策略来代替最有可能的action策略作为下一次迭代策略，<span class="math inline">\(\epsilon \text{-soft}\)</span>
本质上来说就是对于任意动作都保留 <span class="math inline">\(\epsilon\)</span>
小概率的访问可能，权衡了exploration和exploitation，由于每个动作都可能被无限次访问到，Explorting
Starts中的强制随机初始状态就可以去除了。Monte Carlo ES Control 和
On-policy first-visit MC control for <span class="math inline">\(\epsilon \text{-soft policies}\)</span>
都属于on-policy算法，其区别于off-policy的本质在于预估 <span class="math inline">\(q_{\pi}(s,a)\)</span>时是否从同策略<span class="math inline">\(\pi\)</span>生成的数据来计算。一个比较subtle的例子是著名的Q-Learning，因为根据这个定义，Q-Learning属于off-policy。</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{On-policy first-visit MC control (for }\epsilon
\textbf{-soft policies), estimating } \pi \approx \pi_{*} \\
&amp; \text{Algorithm parameter: small } \epsilon &gt; 0 \\
&amp; \text{Initialize:} \\
&amp; \quad \pi \leftarrow \text{ an arbitrary } \epsilon \text{-soft
policy} \\
&amp; \quad Q(s, a) \in \mathbb R \text{, arbitrarily, for all }s \in
\mathcal{S}, a \in \mathcal A(s) \\
&amp; \quad Returns(s, a) \leftarrow \text{ an empty list, for all }s
\in \mathcal{S}, a \in \mathcal A(s)\\
&amp; \\
&amp; \text{Repeat forever (for episode):}\\
&amp; \quad \text{Generate an episode following } \pi : S_0, A_0, R_1,
S_1, A_1, R_2, ..., S_{T-1}, A_{T-1}, R_T\\
&amp; \quad G \leftarrow 0\\
&amp; \quad \text{Loop for each step of episode, } t = T-1, T-2, ...,
0:\\
&amp; \quad \quad \quad G \leftarrow \gamma G + R_{t+1}\\
&amp; \quad \quad \quad \text{Unless the pair } S_t, A_t \text{ appears
in } S_0, A_0, S_1, A_1, ..., S_{t-1}, A_{t-1}\\
&amp; \quad \quad \quad \quad \text{Append } G \text { to }Returns(S_t,
A_t) \\
&amp; \quad \quad \quad \quad Q(S_t, A_t) \leftarrow
\operatorname{average}(Returns(S_t, A_t))\\
&amp; \quad \quad \quad \quad A^{*} \leftarrow \operatorname{argmax}_a
Q(S_t, a)\\
&amp; \quad \quad \quad \quad \text{For all } a \in \mathcal A(S_t):\\
&amp; \quad \quad \quad \quad \quad \pi(a|S_t) \leftarrow
    \begin{cases}
      1 - \epsilon + \epsilon / |\mathcal A(S_t)| &amp; \text{ if } a =
A^{*}\\
      \epsilon / |\mathcal A(S_t)| &amp; \text{ if } a \neq A^{*}\\
    \end{cases}       \\
\end{align*}
\]</span></p>
</div>
<p>伪代码对应的 Python 实现如下。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mc_control_epsilon_greedy</span>(<span class="hljs-params">env: BlackjackEnv, num_episodes, discount_factor=<span class="hljs-number">1.0</span>, epsilon=<span class="hljs-number">0.1</span></span>) \</span></span><br><span class="line"><span class="hljs-function">        -&gt; <span class="hljs-type">Tuple</span>[ActionValue, Policy]:</span></span><br><span class="line">    returns_sum = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line">    returns_count = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    states = <span class="hljs-built_in">list</span>(product(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>, <span class="hljs-number">22</span>), <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>), (<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>)))</span><br><span class="line">    policy = {s: np.ones(env.action_space.n) * <span class="hljs-number">1.0</span> / env.action_space.n <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> states}</span><br><span class="line">    Q = defaultdict(<span class="hljs-keyword">lambda</span>: np.zeros(env.action_space.n))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update_epsilon_greedy_policy</span>(<span class="hljs-params">policy: Policy, Q: ActionValue, s: State</span>):</span></span><br><span class="line">        policy[s] = np.ones(env.action_space.n, dtype=<span class="hljs-built_in">float</span>) * epsilon / env.action_space.n</span><br><span class="line">        best_action = np.argmax(Q[s])</span><br><span class="line">        policy[s][best_action] += (<span class="hljs-number">1.0</span> - epsilon)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> episode_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_episodes + <span class="hljs-number">1</span>):</span><br><span class="line">        episode_history = gen_stochastic_episode(policy, env)</span><br><span class="line"></span><br><span class="line">        G = <span class="hljs-number">0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(episode_history) - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):</span><br><span class="line">            s, a, r = episode_history[t]</span><br><span class="line">            G = discount_factor * G + r</span><br><span class="line">            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(s_a_r[<span class="hljs-number">0</span>] == s <span class="hljs-keyword">and</span> s_a_r[<span class="hljs-number">1</span>] == a <span class="hljs-keyword">for</span> s_a_r <span class="hljs-keyword">in</span> episode_history[<span class="hljs-number">0</span>: t]):</span><br><span class="line">                returns_sum[s, a] += G</span><br><span class="line">                returns_count[s, a] += <span class="hljs-number">1.0</span></span><br><span class="line">                Q[s][a] = returns_sum[s, a] / returns_count[s, a]</span><br><span class="line">                update_epsilon_greedy_policy(policy, Q, s)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> Q, policy</span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-sutton-blackjack-1/" itemprop="url">通过代码学Sutton强化学习3：21点游戏的策略蒙特卡洛值预测</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-09-25T18:45:01.000Z" itemprop="datePublished">9月 26 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            19 分钟 读完 (约 2814 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>从这期开始我们进入Sutton强化学习第二版，第五章蒙特卡洛方法。蒙特卡洛方法是一种在工程各领域都存在的基本方法，在强化领域中，其特点是无需知道环境的dynamics，只需不断模拟记录并分析数据即可逼近理论真实值。蒙特卡洛方法本篇将会用21点游戏作为示例来具体讲解其原理和代码实现。</p>
<h2 id="点游戏问题">21点游戏问题</h2>
<p>21点游戏是一个经典的赌博游戏。大致规则是玩家和庄家各发两张牌，一张明牌，一张暗牌。玩家和庄家可以决定加牌或停止加牌，新加的牌均为暗牌，最后比较两个玩家的牌面和，更接近21点的获胜。游戏的变化因素是牌Ace，既可以作为11也可以作为1来计算，算作11的时候称作usable。</p>
<p>Sutton教材中的21点游戏规则简化了几个方面用于控制问题状态数：</p>
<ul>
<li>已发的牌的无状态性：和一副牌的21点游戏不同的是，游戏环境简化为牌是可以无穷尽被补充的，一副牌的某一张被派发后，同样的牌会被补充进来，或者可以认为每次发放的牌都是从一副新牌中抽出的。统计学中的术语称为重复采样（sample
with replacement）。这种规则下极端情况下，玩家可以拥有
5个A或者5个2。另外，这会导致玩家无法通过开局看到的3张牌的信息推断后续发牌的概率，如此就大规模减小了游戏状态数。</li>
<li>庄家和玩家独立游戏，无需按轮次要牌。开局给定4张牌后，玩家先行动，加牌直至超21点或者停止要牌，如果超21点，玩家输，否则，等待庄家行动，庄家加牌直至超21点或者停止要牌，如果超21点，庄家输，否则比较两者的总点数。这种方式可以认为当玩家和庄家看到初始的三张牌后独立做一系列决策，最后比较结果，避免了交互模式下因为能观察到每一轮后对方牌数变化产生额外的信息而导致的游戏状态数爆炸。</li>
</ul>
<p>有以上两个规则的简化，21点游戏问题的总状态数有下面三个维度</p>
<ul>
<li><p>自己手中的点数和（12到21）</p></li>
<li><p>庄家明牌的点数（A到10)</p></li>
<li><p>庄家明牌是否有 A（True, False）。</p></li>
</ul>
<p>状态总计总数为三个维度的乘积 10 * 10 * 2 = 200。</p>
<p>关于游戏状态有几个比较subtle的假设或者要素。首先，玩家初始时能看到三张牌，这三张牌确定了状态的三个维度的值，当然也就确定了Agent的初始状态，随后按照独立游戏的规则进行，玩家根据初始状态依照某种策略决策要牌还是结束要牌，新拿的牌更新了游戏状态，玩家转移到新状态下继续做决策。举个例子，假设初始时玩家明牌为8，暗牌为6，庄家明牌为7，则游戏状态为Tuple
(14, 7,
False)。若玩家的策略为教材中的固定规则策略：没到20或者21继续要牌。下一步玩家拿到牌3，则此时新状态为
(17, 7, False)，按照策略继续要牌。</p>
<p>第二个方面是游戏的状态完全等价于玩家观察到的信息。比如尽管初始时有4张牌，真正的状态是这四张牌的值，但是出于简化目的，不考虑partially
observable
的情况，即不将暗牌纳入游戏状态中。另外，庄家做决策的时候也无法得知玩家的手中的总牌数。</p>
<p>第三个方面是关于玩家点数。考虑玩家初始时的两张牌为2，3，总点数是5，那么为何不将5加入到游戏状态中呢？原则上是可以将初始总和为2到11都加入到游戏状态，但是意义不大，原因在于我们已经假设了已发牌的无状态性，拿到的这两张牌并不会改变后续补充的牌的出现概率。当玩家初始总和为2到11时一定会追加牌，因为无论第三张牌是什么，都不会超过21点，只会增加获胜概率。若后续第三张牌为8，总和变成13，就进入了有效的游戏状态，因为此时如果继续要牌，获得10，则游戏输掉。因此，我们关心的游戏状态并不完全等价于所有可能的游戏状态。</p>
<h2 id="点游戏-openai-gym环境">21点游戏 OpenAI Gym环境</h2>
<p>OpenAI Gym
已经实现了Sutton版本的21点游戏环境，并按上述规则来进行。在安装完OpenAI
Gym包之后 import BlackjackEnv即可使用。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> gym.envs.toy_text <span class="hljs-keyword">import</span> BlackjackEnv</span><br></pre></td></tr></tbody></table></figure>
<p>根据这个游戏环境，我们先来定义一些类型，可以令代码更具可读性和抽象化。State
上文说过是由三个分量组成的Tuple。Action 为bool类型
表示是否继续要牌。Reward 为+1或者-1，玩家叫牌过程中为0。StateValue
为书中的 <span class="math inline">\(V_{\pi}\)</span>，实现上是一个Dict。DeterministicPolicy
为一个函数，输入是某一状态，输出是唯一的决策动作。 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">State = <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>, <span class="hljs-built_in">bool</span>]</span><br><span class="line">Action = <span class="hljs-built_in">bool</span></span><br><span class="line">Reward = <span class="hljs-built_in">float</span></span><br><span class="line">StateValue = <span class="hljs-type">Dict</span>[State, <span class="hljs-built_in">float</span>]</span><br><span class="line">DeterministicPolicy = <span class="hljs-type">Callable</span>[[State], Action]</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>以下代码是 BlackjackEnv 核心代码，step
方法的输入为玩家的决策动作（叫牌还是结束），并输出State, Reward,
is_done。简单解释一下代码逻辑，当玩家继续加牌时，需要判断是否超21点，如果没有超过的话，返回下一状态，同时reward
为0，等待下一step方法。若玩家停止叫牌，则按照庄家策略：小于17时叫牌。游戏终局时产生+1表示玩家获胜，-1表示庄家获胜。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BlackjackEnv</span>(<span class="hljs-params">gym.Env</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self, action</span>):</span></span><br><span class="line">        <span class="hljs-keyword">assert</span> self.action_space.contains(action)</span><br><span class="line">        <span class="hljs-keyword">if</span> action:  <span class="hljs-comment"># hit: add a card to players hand and return</span></span><br><span class="line">            self.player.append(draw_card(self.np_random))</span><br><span class="line">            <span class="hljs-keyword">if</span> is_bust(self.player):</span><br><span class="line">                done = <span class="hljs-literal">True</span></span><br><span class="line">                reward = -<span class="hljs-number">1.</span></span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                done = <span class="hljs-literal">False</span></span><br><span class="line">                reward = <span class="hljs-number">0.</span></span><br><span class="line">        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># stick: play out the dealers hand, and score</span></span><br><span class="line">            done = <span class="hljs-literal">True</span></span><br><span class="line">            <span class="hljs-keyword">while</span> sum_hand(self.dealer) &lt; <span class="hljs-number">17</span>:</span><br><span class="line">                self.dealer.append(draw_card(self.np_random))</span><br><span class="line">            reward = cmp(score(self.player), score(self.dealer))</span><br><span class="line">            <span class="hljs-keyword">if</span> self.natural <span class="hljs-keyword">and</span> is_natural(self.player) <span class="hljs-keyword">and</span> reward == <span class="hljs-number">1.</span>:</span><br><span class="line">                reward = <span class="hljs-number">1.5</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self._get_obs(), reward, done, {}</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_obs</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">        <span class="hljs-keyword">return</span> (sum_hand(self.player), self.dealer[<span class="hljs-number">0</span>], usable_ace(self.player))</span><br></pre></td></tr></tbody></table></figure>
<p>下面示例如何调用step方法生成一个episode的数据集。数据集的类型为
List[Tuple[State, Action, Reward]]。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_episode_data</span>(<span class="hljs-params">policy: DeterministicPolicy, env: BlackjackEnv</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[State, Action, Reward]]:</span></span><br><span class="line">    episode_history = []</span><br><span class="line">    state = env.reset()</span><br><span class="line">    done = <span class="hljs-literal">False</span></span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:</span><br><span class="line">        action = policy(state)</span><br><span class="line">        next_state, reward, done, _ = env.step(action)</span><br><span class="line">        episode_history.append((state, action, reward))</span><br><span class="line">        state = next_state</span><br><span class="line">    <span class="hljs-keyword">return</span> episode_history</span><br></pre></td></tr></tbody></table></figure>
<h2 id="策略的蒙特卡洛值预测">策略的蒙特卡洛值预测</h2>
<p>Monte Carlo Prediction解决如下问题：当给定Agent 策略<span class="math inline">\(\pi\)</span>时，反复试验来预估策略的 <span class="math inline">\(V_{\pi}\)</span>
值。具体来说，产生一系列的episode数据之后，对于出现了的所有状态分别计算其Return，再通过
average 某一状态 s 的Return来估计 <span class="math inline">\(V_{\pi}(s)\)</span>，理论上，依据大数定理（Law of
large numbers），在可以无限模拟的情况下，Monte Carlo prediction
一定会收敛到真实的 <span class="math inline">\(V_{\pi}\)</span>。算法实现上有两个略微不同的版本，一个版本称为
First-visit，另一个版本称为 Every-visit，区别在于如何计算出现的状态 s 的
Return值。</p>
<p>对于 First-visit 来说，当状态 s 第一次出现时计算一次
Returns，若继续出现状态 s 不再重复计算。对于Every-visit来说，每次出现 s
计算一次 Returns(s)。举个例子，某episode 数据如下： <span class="math display">\[
S_1, R_1, S_2, R_2, S_1, R_3, S_3, R_4
\]</span> First-visit 对于状态S1的Returns计算为</p>
<p><span class="math display">\[
Returns(S_1) = R_1 + R_2 + R_3 + R_4
\]</span></p>
<p>Every-visit 对于状态S1的Returns计算了两次，因为S1出现了两次。 <span class="math display">\[
\begin{align*}
Returns(S_1) = \frac{Return_1(S_1) + Return_2(S_1)}2 \\
= \frac{(R_1 + R_2 + R_3 + R_4) + (R_3 + R_4)} 2
\end{align*}
\]</span></p>
<p>下面用Monte
Carlo来模拟解得书中示例玩家固定策略的V值，策略具体为：加牌直到手中点数&gt;=20，代码为</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fixed_policy</span>(<span class="hljs-params">observation</span>):</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    sticks if the player score is &gt;= 20 and hits otherwise.</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    score, dealer_score, usable_ace = observation</span><br><span class="line">    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> score &gt;= <span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="first-visit-mc-predicition">First-visit MC Predicition</h3>
伪代码如下，注意考虑到实现上的高效性，在遍历episode序列数据时是从后向前扫的，这样可以边扫边更新G。
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{First-visit MC prediction, for estimating } V \approx
v_{\pi} \\
&amp; \text{Input: a policy } \pi \text{ to be evaluated} \\
&amp; \text{Initialize} \\
&amp; \quad V(s) \in \mathbb R \text{, arbitrarily, for all }s \in
\mathcal{S} \\
&amp; \quad Returns(s) \leftarrow \text{ an empty list, arbitrarily, for
all }s \in \mathcal{S} \\
&amp; \\
&amp; \text{Loop forever (for episode):}\\
&amp; \quad \text{Generate an episode following } \pi: S_0, A_0, R_1,
S_1, A_1, R_2, ..., S_{T-1}, A_{T-1}, R_T\\
&amp; \quad G \leftarrow 0\\
&amp; \quad \text{Loop for each step of episode, } t = T-1, T-2, ...,
0:\\
&amp; \quad \quad \quad G \leftarrow \gamma G + R_{t+1}\\
&amp; \quad \quad \quad \text{Unless } S_t \text{ appears in } S_0, S_1,
..., S_{t-1}\\
&amp; \quad \quad \quad \quad \text{Append } G \text { to }Returns(S_t)
\\
&amp; \quad \quad \quad \quad V(S_t) \leftarrow
\operatorname{average}(Returns(S_t))\\
\end{align*}
\]</span></p>
</div>
<p>对应的 python 实现</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mc_prediction_first_visit</span>(<span class="hljs-params">policy: DeterministicPolicy, env: BlackjackEnv,</span></span></span><br><span class="line"><span class="hljs-params"><span class="hljs-function">                              num_episodes, discount_factor=<span class="hljs-number">1.0</span></span>) -&gt; StateValue:</span></span><br><span class="line">    returns_sum = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line">    returns_count = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> episode_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_episodes + <span class="hljs-number">1</span>):</span><br><span class="line">        episode_history = gen_episode_data(policy, env)</span><br><span class="line"></span><br><span class="line">        G = <span class="hljs-number">0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(episode_history) - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):</span><br><span class="line">            s, a, r = episode_history[t]</span><br><span class="line">            G = discount_factor * G + r</span><br><span class="line">            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(s_a_r[<span class="hljs-number">0</span>] == s <span class="hljs-keyword">for</span> s_a_r <span class="hljs-keyword">in</span> episode_history[<span class="hljs-number">0</span>: t]):</span><br><span class="line">                returns_sum[s] += G</span><br><span class="line">                returns_count[s] += <span class="hljs-number">1.0</span></span><br><span class="line"></span><br><span class="line">    V = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line">    V.update({s: returns_sum[s] / returns_count[s] <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> returns_sum.keys()})</span><br><span class="line">    <span class="hljs-keyword">return</span> V</span><br></pre></td></tr></tbody></table></figure>
<h3 id="every-visit-mc-prediciton">Every-visit MC Prediciton</h3>
<p>Every-visit 代码实现相对更简单一些，t
从后往前遍历时更新对应s的状态变量。如下所示</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mc_prediction_every_visit</span>(<span class="hljs-params">policy: DeterministicPolicy, env: BlackjackEnv,</span></span></span><br><span class="line"><span class="hljs-params"><span class="hljs-function">                              num_episodes, discount_factor=<span class="hljs-number">1.0</span></span>) -&gt; StateValue:</span></span><br><span class="line">    returns_sum = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line">    returns_count = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> episode_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_episodes + <span class="hljs-number">1</span>):</span><br><span class="line">        episode_history = gen_episode_data(policy, env)</span><br><span class="line"></span><br><span class="line">        G = <span class="hljs-number">0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(episode_history) - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):</span><br><span class="line">            s, a, r = episode_history[t]</span><br><span class="line">            G = discount_factor * G + r</span><br><span class="line">            returns_sum[s] += G</span><br><span class="line">            returns_count[s] += <span class="hljs-number">1.0</span></span><br><span class="line"></span><br><span class="line">    V = defaultdict(<span class="hljs-built_in">float</span>)</span><br><span class="line">    V.update({s: returns_sum[s] / returns_count[s] <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> returns_sum.keys()})</span><br><span class="line">    <span class="hljs-keyword">return</span> V</span><br></pre></td></tr></tbody></table></figure>
<h2 id="策略-v值-3d-可视化">策略 V值 3D 可视化</h2>
<p>运行first-visit
算法，模拟10000次episode，fixed_policy的V值的3D图为下面两张图，分别是不含usable
Ace和包含usable
Ace。总的说来，一旦玩家能到达20点或21点获胜概率极大，到达13-17获胜概率较小，在11-13时有一定获胜概率，比较符合经验直觉。</p>
<figure>
<img src="/zh/2020/rl-sutton-blackjack-1/mc_v_first_visit_10000_no_usable.png">
<figcaption>
first-visit MC 10000次没有usable A的V值
</figcaption>
</figure>
<figure>
<img src="/zh/2020/rl-sutton-blackjack-1/mc_v_first_visit_10000_usable.png">
<figcaption>
first-visit MC 10000次含有usable A的V值
</figcaption>
</figure>
<p>同样运行every-visit
算法，模拟10000次的V值图。对比两种方法结果比较接近。</p>
<figure>
<img src="/zh/2020/rl-sutton-blackjack-1/mc_v_every_visit_10000_no_usable.png">
<figcaption>
every-visit MC 10000次没有usable A的V值
</figcaption>
</figure>
<figure>
<img src="/zh/2020/rl-sutton-blackjack-1/mc_v_every_visit_10000_usable.png">
<figcaption>
every-visit MC 10000次含有usable A的V值
</figcaption>
</figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/tsp-2-dp-tour/" itemprop="url">TSP问题从DP算法到深度学习2：欧氏空间数据集的DP解</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-09-19T18:45:01.000Z" itemprop="datePublished">9月 20 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 分钟 读完 (约 1761 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>本篇是TSP问题从DP算法到深度学习系列第二篇。</p>
<ul>
<li><p><a href="/zh/2020/tsp-2-dp-tour/!--swig￼11--">第一篇: 递归DP方法 AC AIZU
TSP问题</a></p></li>
<li><p><strong><a href="/zh/2020/tsp-2-dp-tour/!--swig￼12--">第二篇:
二维空间TSP数据集及其DP解法</a></strong></p></li>
<li><p>第三篇: 深度学习 Pointer Networks 的 Pytorch实现</p></li>
<li><p>第四篇: 搜寻最有可能路径：Viterbi算法和其他</p></li>
<li><p>第五篇: 深度强化学习无监督算法的 Pytorch实现</p></li>
</ul>
<h2 id="aizu-tsp-自底向上迭代dp解">AIZU TSP 自底向上迭代DP解</h2>
<p>上一篇中，我们用Python 3和Java
8完成了自顶向下递归版本的DP解。我们继续改进代码，将它转换成标准DP方式：自底向上的迭代DP版本。下图是3个点TSP问题的递归调用图。</p>
<p><img src="/zh/2020/tsp-2-dp-tour/ver3-top-down.svg" title="3点TSP递归调用图"></p>
<p>将这个图反过来检查状态的依赖关系，可以很容易发现规律：首先计算状态位含有一个1的点，接着是两个1的节点，最后是状态位三个1的点。简而言之，在计算状态位为n+1个1的节点时需要用到n个1的节点的计算结果，如果能依照这样的
topological 顺序来的话，就可以去除递归，写成迭代（循环）版本的DP。</p>
<p><img src="/zh/2020/tsp-2-dp-tour/ver3-bottom-up.svg" title="3点TSP状态依赖"></p>
<p>迭代算法的Java 伪代码如下</p>
<figure class="highlight java hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> bitset_num = N; bitset_num &gt;=<span class="hljs-number">0</span>; bitset_num++) {</span><br><span class="line">	<span class="hljs-keyword">while</span>(hasNextCombination(bitset_num)) {</span><br><span class="line">		<span class="hljs-keyword">int</span> state = nextCombination(bitset_num);</span><br><span class="line">		<span class="hljs-comment">// compute dp[state][v], v-th bit is set in state</span></span><br><span class="line">		<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> v = <span class="hljs-number">0</span>; v &lt; n; v++) {</span><br><span class="line">			<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; n; u++) {</span><br><span class="line">				<span class="hljs-comment">// for each u not reached by this state</span></span><br><span class="line">				<span class="hljs-keyword">if</span> (!include(state, u)) {</span><br><span class="line">					dp[state][v] = min(dp[state][v], </span><br><span class="line">						dp[new_state_include_u][u] + dist[v][u]);</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>举例来说，dp[00010][1] 是从顶点0出发，刚经过顶点1的最小距离 <span class="math inline">\(0 \rightarrow 1 \rightarrow ? \rightarrow ?
\rightarrow ? \rightarrow 0\)</span>。</p>
<p>为了找到最小距离值，就必须遍历所有可能的下一个可能的顶点u
（第一个问号位置）。 <span class="math display">\[
(0 \rightarrow 1) +
\begin{align*}
  \min \left\lbrace
  \begin{array}{r@{}l}
    2 \rightarrow ? \rightarrow ? \rightarrow 0 + dist(1,2)
\qquad\text{    new_state=[00110][2] } \qquad\\\\
    3 \rightarrow ? \rightarrow ?  \rightarrow 0 + dist(1,3)
\qquad\text{    new_state=[01010][3] } \qquad\\\\
    4 \rightarrow ? \rightarrow ?  \rightarrow 0 + dist(1,4)
\qquad\text{    new_state=[10010][4] } \qquad
  \end{array}
  \right.
\end{align*}
\]</span></p>
<h3 id="迭代dp-ac代码">迭代DP AC代码</h3>
<p>以下是AC 的Java 算法核心代码。完整代码在 github/MyEncyclopedia 的<a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_aizu/Main_loop.java">tsp/alg_aizu/Main_loop.java</a>。</p>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span> </span>{</span><br><span class="line">	<span class="hljs-keyword">int</span> N = g.V_NUM;</span><br><span class="line">	<span class="hljs-keyword">long</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-keyword">long</span>[<span class="hljs-number">1</span> &lt;&lt; N][N];</span><br><span class="line">	<span class="hljs-comment">// init dp[][] with MAX</span></span><br><span class="line">	<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; dp.length; i++) {</span><br><span class="line">		Arrays.fill(dp[i], Integer.MAX_VALUE);</span><br><span class="line">	}</span><br><span class="line">	dp[(<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> state = (<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">2</span>; state &gt;= <span class="hljs-number">0</span>; state--) {</span><br><span class="line">		<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> v = <span class="hljs-number">0</span>; v &lt; N; v++) {</span><br><span class="line">			<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; N; u++) {</span><br><span class="line">				<span class="hljs-keyword">if</span> (((state &gt;&gt; u) &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>) {</span><br><span class="line">					dp[state][v] = Math.min(dp[state][v], dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + g.edges[v][u]);</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">	<span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] == Integer.MAX_VALUE ? -<span class="hljs-number">1</span> : dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>很显然，时间算法复杂度对应了三重 for 循环，为 O(<span class="math inline">\(2^n * n * n\)</span>) = O(<span class="math inline">\(2^n*n^2\)</span> )。</p>
<p>类似的，Python 3 AC 代码如下。完整代码在 github/MyEncyclopedia 的<a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_aizu/TSP_loop.py">tsp/alg_aizu/TSP_loop.py</a>。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPSolver</span>:</span></span><br><span class="line">    g: Graph</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, g: Graph</span>):</span></span><br><span class="line">        self.g = g</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        :param v:</span></span><br><span class="line"><span class="hljs-string">        :param state:</span></span><br><span class="line"><span class="hljs-string">        :return: -1 means INF</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        N = self.g.v_num</span><br><span class="line">        dp = [[INT_INF <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span> &lt;&lt; N)]</span><br><span class="line"></span><br><span class="line">        dp[(<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">for</span> state <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):</span><br><span class="line">            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                    <span class="hljs-keyword">if</span> ((state &gt;&gt; u) &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>:</span><br><span class="line">                        <span class="hljs-keyword">if</span> dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] != INT_INF <span class="hljs-keyword">and</span> self.g.edges[v][u] != INT_INF:</span><br><span class="line">                            <span class="hljs-keyword">if</span> dp[state][v] == INT_INF:</span><br><span class="line">                                dp[state][v] = dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + self.g.edges[v][u]</span><br><span class="line">                            <span class="hljs-keyword">else</span>:</span><br><span class="line">                                dp[state][v] = <span class="hljs-built_in">min</span>(dp[state][v], dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + self.g.edges[v][u])</span><br><span class="line">        <span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure>
<h2 id="一个欧式空间tsp数据集">一个欧式空间TSP数据集</h2>
<p>至此，TSP的DP解法全部讲解完毕。接下去，我们引入一个二维欧式空间的TSP数据集
<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/0B2fg8yPGn2TCMzBtS0o4Q2RJaEU">PTR_NET
on Google Drive</a> ，这个数据集是 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.03134">Pointer Networks</a> 的作者
Oriol Vinyals 用于模型的训练测试而引入的。</p>
<p>数据集的每一行格式如下：</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x1, y1, x2, y2, ... output 1 v1 v2 v3 ... 1</span><br></pre></td></tr></tbody></table></figure>
<p>一行开始为n个点的x， y坐标，接着是
output，再接着是1，表示从顶点1出发，经v1，v2，...，返回1，注意顶点编号从1开始。</p>
<p>十个顶点数据集的一些数据示例如下：</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0.607122 0.664447 0.953593 0.021519 0.757626 0.921024 0.586376 0.433565 0.786837 0.052959 0.016088 0.581436 0.496714 0.633571 0.227777 0.971433 0.665490 0.074331 0.383556 0.104392 output 1 3 8 6 10 9 5 2 4 7 1 </span><br><span class="line">0.930534 0.747036 0.277412 0.938252 0.794592 0.794285 0.961946 0.261223 0.070796 0.384302 0.097035 0.796306 0.452332 0.412415 0.341413 0.566108 0.247172 0.890329 0.429978 0.232970 output 1 3 2 9 6 5 8 7 10 4 1 </span><br><span class="line">0.686712 0.087942 0.443054 0.277818 0.494769 0.985289 0.559706 0.861138 0.532884 0.351913 0.712561 0.199273 0.554681 0.657214 0.909986 0.277141 0.931064 0.639287 0.398927 0.406909 output 1 5 2 10 7 4 3 9 8 6 1 </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>画出第一个例子的全部顶点和边。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line">points=<span class="hljs-string">'0.607122 0.664447 0.953593 0.021519 0.757626 0.921024 0.586376 0.433565 0.786837 0.052959 0.016088 0.581436 0.496714 0.633571 0.227777 0.971433 0.665490 0.074331 0.383556 0.104392'</span></span><br><span class="line">float_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">float</span>(x), points.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"></span><br><span class="line">x,y = [],[]</span><br><span class="line"><span class="hljs-keyword">for</span> idx, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(float_list):</span><br><span class="line">  <span class="hljs-keyword">if</span> idx % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:</span><br><span class="line">    x.append(p)</span><br><span class="line">  <span class="hljs-keyword">else</span>:</span><br><span class="line">    y.append(p)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x)):</span><br><span class="line">  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x)):</span><br><span class="line">    <span class="hljs-keyword">if</span> i == j:</span><br><span class="line">      <span class="hljs-keyword">continue</span></span><br><span class="line">    plt.plot((x[i],x[j]),(y[i],y[j]))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2020/tsp-2-dp-tour/tsp10_full.png">
<figcaption>
全连接的图
</figcaption>
</figure>
<p>这个例子的最短TSP旅程为 <span class="math display">\[
1 \rightarrow 3 \rightarrow 8 \rightarrow 6 \rightarrow 10 \rightarrow 9
\rightarrow 5 \rightarrow 2 \rightarrow 4 \rightarrow 7 \rightarrow 1
\]</span></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tour_str = <span class="hljs-string">'1 3 8 6 10 9 5 2 4 7 1'</span></span><br><span class="line">tour = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x), tour_str.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tour)-<span class="hljs-number">1</span>):</span><br><span class="line">  p1 = tour[i] - <span class="hljs-number">1</span></span><br><span class="line">  p2 = tour[i + <span class="hljs-number">1</span>] - <span class="hljs-number">1</span></span><br><span class="line">  plt.plot((x[p1],x[p2]),(y[p1],y[p2]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2020/tsp-2-dp-tour/tsp10_tour.png">
<figcaption>
最短路径
</figcaption>
</figure>
<h2 id="ptr_net-tsp-的python代码">PTR_NET TSP 的Python代码</h2>
<h3 id="初始化init-graph-edges">初始化Init Graph Edges</h3>
<p>在之前的自顶向下的递归版本中，需要做一些改动。首先，是图的初始化，我们依然延续之前的邻接矩阵来表示，由于这次的图是无向图，对于任意两个顶点，需要初始化双向的边。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">g: Graph = Graph(N)</span><br><span class="line"><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">	<span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">		diff_x = coordinates[v][<span class="hljs-number">0</span>] - coordinates[u][<span class="hljs-number">0</span>]</span><br><span class="line">		diff_y = coordinates[v][<span class="hljs-number">1</span>] - coordinates[u][<span class="hljs-number">1</span>]</span><br><span class="line">		dist: <span class="hljs-built_in">float</span> = math.sqrt(diff_x * diff_x + diff_y * diff_y)</span><br><span class="line">		g.setDist(u, v, dist)</span><br><span class="line">		g.setDist(v, u, dist)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="辅助变量记录父节点">辅助变量记录父节点</h3>
<p>另一大改动是需要在遍历过程中保存的顶点关联信息，以便在最终找到最短路径值时可以回溯对应的完整路径。在下面代码中，使用parent[bitstate][v]
来保存此状态下最小路径对应的顶点u。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ret: <span class="hljs-built_in">float</span> = FLOAT_INF</span><br><span class="line">u_min: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span></span><br><span class="line">	<span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num):</span><br><span class="line">		<span class="hljs-keyword">if</span> (state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>:</span><br><span class="line">			s: <span class="hljs-built_in">float</span> = self._recurse(u, state | <span class="hljs-number">1</span> &lt;&lt; u)</span><br><span class="line">				<span class="hljs-keyword">if</span> s + edges[v][u] &lt; ret:</span><br><span class="line">					ret = s + edges[v][u]</span><br><span class="line">					u_min = u</span><br><span class="line">	dp[state][v] = ret</span><br><span class="line">	self.parent[state][v] = u_min</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>当最终最短行程确定后，根据parent的信息可以按图索骥找到完整的行程顶点信息。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_form_tour</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">	self.tour = [<span class="hljs-number">0</span>]</span><br><span class="line">	bit = <span class="hljs-number">0</span></span><br><span class="line">	v = <span class="hljs-number">0</span></span><br><span class="line">	<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num - <span class="hljs-number">1</span>):</span><br><span class="line">		v = self.parent[bit][v]</span><br><span class="line">		self.tour.append(v)</span><br><span class="line">		bit = bit | (<span class="hljs-number">1</span> &lt;&lt; v)</span><br><span class="line">	self.tour.append(<span class="hljs-number">0</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>需要注意的是，有可能存在多个最短行程，它们的距离值是一致的。这种情况下，代码输出的最短路径可能和数据集output后行程路径不一致，但是的两者的总距离是一致的。下面的代码验证了这一点。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tsp: TSPSolver = TSPSolver(g)</span><br><span class="line">tsp.solve()</span><br><span class="line"></span><br><span class="line">output_dist: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span></span><br><span class="line">output_tour = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x) - <span class="hljs-number">1</span>, output.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(output_tour)):</span><br><span class="line">	pre_v = output_tour[v-<span class="hljs-number">1</span>]</span><br><span class="line">	curr_v = output_tour[v]</span><br><span class="line">	diff_x = coordinates[pre_v][<span class="hljs-number">0</span>] - coordinates[curr_v][<span class="hljs-number">0</span>]</span><br><span class="line">	diff_y = coordinates[pre_v][<span class="hljs-number">1</span>] - coordinates[curr_v][<span class="hljs-number">1</span>]</span><br><span class="line">	dist: <span class="hljs-built_in">float</span> = math.sqrt(diff_x * diff_x + diff_y * diff_y)</span><br><span class="line">	output_dist += dist</span><br><span class="line"></span><br><span class="line">	passed = <span class="hljs-built_in">abs</span>(tsp.dist - output_dist) &lt; <span class="hljs-number">10e-5</span></span><br><span class="line">	<span class="hljs-keyword">if</span> passed:</span><br><span class="line">		<span class="hljs-built_in">print</span>(<span class="hljs-string">f'passed dist=<span class="hljs-subst">{tsp.tour}</span>'</span>)</span><br><span class="line">	<span class="hljs-keyword">else</span>:</span><br><span class="line">		<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Min Tour Distance = <span class="hljs-subst">{output_dist}</span>, Computed Tour Distance = <span class="hljs-subst">{tsp.dist}</span>, Expected Tour = <span class="hljs-subst">{output_tour}</span>, Result = <span class="hljs-subst">{tsp.tour}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>本文所有代码在 github/MyEncyclopedia tsp/alg_plane 中。</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/rl-sutton-gridworld-2/" itemprop="url">通过代码学Sutton强化学习2：Grid World 策略迭代和值迭代</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-09-11T18:45:01.000Z" itemprop="datePublished">9月 12 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            15 分钟 读完 (约 2285 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>上一期 <a href="/zh/2020/rl-sutton-gridworld-2/!--swig￼6--">通过代码学Sutton强化学习1：Grid World
OpenAI环境和策略评价算法</a>，我们引入了 Grid World
问题，实现了对应的OpenAI Gym
环境，也分析了其最佳策略和对应的V值。这一期中，继续通过这个例子详细讲解策略提升（Policy
Improvment）、策略迭代（Policy Iteration）、值迭代（Value
Iteration）和异步迭代方法。</p>
<h2 id="回顾-grid-world-问题">回顾 Grid World 问题</h2>
<figure>
<img src="/zh/2020/rl-sutton-gridworld-2/grid_world.png">
<figcaption>
Grid World 问题
</figcaption>
</figure>
在Grid World 中，Agent初始可以出现在编号1-14的网格中，Agent
每往四周走一步得到 -1
reward，因此需要尽快走到两个出口。当然最佳策略是以最小步数往出口逃离，如下所示。
<figure>
<img src="/zh/2020/rl-sutton-gridworld-2/optimal_policy.png">
<figcaption>
Grid World 最佳策略
</figcaption>
</figure>
<p>最佳策略对应的状态V值和3D heatmap如下 </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[ <span class="hljs-number">0.</span> -<span class="hljs-number">1.</span> -<span class="hljs-number">2.</span> -<span class="hljs-number">3.</span>]</span><br><span class="line"> [-<span class="hljs-number">1.</span> -<span class="hljs-number">2.</span> -<span class="hljs-number">3.</span> -<span class="hljs-number">2.</span>]</span><br><span class="line"> [-<span class="hljs-number">2.</span> -<span class="hljs-number">3.</span> -<span class="hljs-number">2.</span> -<span class="hljs-number">1.</span>]</span><br><span class="line"> [-<span class="hljs-number">3.</span> -<span class="hljs-number">2.</span> -<span class="hljs-number">1.</span>  <span class="hljs-number">0.</span>]]</span><br></pre></td></tr></tbody></table></figure><p></p>
<figure>
<img src="/zh/2020/rl-sutton-gridworld-2/value_3d.png">
<figcaption>
Grid World V值 3D heatmap
</figcaption>
</figure>
<h2 id="策略迭代">策略迭代</h2>
<p>上一篇中，我们知道如何evaluate 给定policy <span class="math inline">\(\pi\)</span> 的 <span class="math inline">\(v_{\pi}\)</span>值，那么是否可能在此基础上改进生成更好的策略
<span class="math inline">\(\pi^{\prime}\)</span>。如果可以，能否最终找到最佳策略<span class="math inline">\({\pi}_{*}\)</span>？答案是肯定的，因为存在策略提升定理（Policy
Improvement Theorem）。</p>
<h3 id="策略提升定理">策略提升定理</h3>
<p>在 4.2 节 Policy Improvement Theorem 可以证明，利用 <span class="math inline">\(v_{\pi}\)</span> 信息对于每个状态采取最 greedy 的
action （又称exploitation）能够保证生成的新 <span class="math inline">\({\pi}^{\prime}\)</span> 是不差于旧的policy <span class="math inline">\({\pi}\)</span>，即</p>
<div>
<p><span class="math display">\[
q_{\pi}(s, {\pi}^{\prime}(s)) \gt v_{\pi}(s)
\]</span></p>
</div>
<div>
<p><span class="math display">\[
v_{\pi^{\prime}}(s) \gt v_{\pi}(s)
\]</span></p>
</div>
因此，可以通过在当前policy求得v值，再选取最greedy
action的方式形成如下迭代，就能够不断逼近最佳策略。
<div>
<p><span class="math display">\[
\pi_{0} \stackrel{\mathrm{E}}{\longrightarrow} v_{\pi_{0}}
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{1}
\stackrel{\mathrm{E}}{\longrightarrow} v_{\pi_{1}}
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{2}
\stackrel{\mathrm{E}}{\longrightarrow} \cdots
\stackrel{\mathrm{I}}{\longrightarrow} \pi_{*}
\stackrel{\mathrm{E}}{\longrightarrow} v_{*}
\]</span></p>
</div>
<h3 id="策略迭代算法">策略迭代算法</h3>
以下为书中4.3的policy iteration伪代码。其中policy
evaluation的算法在上一篇中已经实现。Policy improvement
的精髓在于一次遍历所有状态后，通过policy
的最大Q值找到该状态的最佳action，并更新成最新policy，循环直至没有 action
变更。
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Policy Iteration (using iterative policy evaluation) for
estimating } \pi\approx {\pi}_{*} \\
&amp;1. \quad \text{Initialization} \\
&amp; \quad \quad V(s) \in \mathbb R\text{ and } \pi(s) \in \mathcal
A(s) \text{ arbitrarily for all }s \in \mathcal{S} \\
&amp; \\
&amp;2. \quad \text{Policy Evaluation} \\
&amp; \quad \quad \text{Loop:}\\
&amp; \quad \quad \Delta \leftarrow 0\\
&amp; \quad \quad \text{Loop for each } s \in \mathcal{S}:\\
&amp; \quad \quad \quad \quad v \leftarrow V(s) \\
&amp; \quad \quad \quad \quad V(s) \leftarrow \sum_{s^{\prime}, r}
p\left(s^{\prime}, r \mid s, a\right)\left[r+\gamma
V\left(s^{\prime}\right)\right] \\
&amp; \quad \quad \quad \quad \Delta \leftarrow \max(\Delta, |v-V(s)|)
\\
&amp; \quad \quad \text{until } \Delta &lt; \theta \text{ (a small
positive number determining the accuracy of estimation)}\\
&amp; \\
&amp;3. \quad \text{Policy Improvement} \\
&amp; \quad \quad policy\text{-}stable\leftarrow true \\
&amp; \quad \quad \text{Loop for each } s \in \mathcal{S}:\\
&amp; \quad \quad \quad \quad old\text{-}action\leftarrow \pi(s) \\
&amp; \quad \quad \quad \quad \pi(s) \leftarrow
\operatorname{argmax}_{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid
s, a\right)\left[r+\gamma V\left(s^{\prime}\right)\right] \\
&amp; \quad \quad \quad \quad \text{If } old\text{-}action \neq
\pi\text{,then }policy\text{-}stable\leftarrow false \\
&amp; \quad \quad \text{If } policy\text{-}stable \text{, then stop and
return }V \approx v_{*} \text{ and } \pi\approx {\pi}_{*}\text{; else go
to 2}
\end{align*}
\]</span></p>
</div>
<p>注意到状态Q值 <span class="math inline">\(q_{\pi}(s, a)\)</span>
会被多处调用，将其封装为单独的函数。</p>
<div>
<p><span class="math display">\[
\begin{aligned}
q_{\pi}(s, a) &amp;=\sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid s,
a\right)\left[r+\gamma v_{\pi}\left(s^{\prime}\right)\right]
\end{aligned}
\]</span></p>
</div>
<p>Q值函数实现如下： </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">action_value</span>(<span class="hljs-params">env: GridWorldEnv, state: State, V: StateValue, gamma=<span class="hljs-number">1.0</span></span>) -&gt; ActionValue:</span></span><br><span class="line">    q = np.zeros(env.nA)</span><br><span class="line">    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(env.nA):</span><br><span class="line">        <span class="hljs-keyword">for</span> prob, next_state, reward, done <span class="hljs-keyword">in</span> env.P[state][a]:</span><br><span class="line">            q[a] += prob * (reward + gamma * V[next_state])</span><br><span class="line">    <span class="hljs-keyword">return</span> q</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>有了 action_value 和上期的 policy_evaluate，policy iteration
实现完全对应上面的伪代码。 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">policy_improvement</span>(<span class="hljs-params">env: GridWorldEnv, policy: Policy, V: StateValue, gamma=<span class="hljs-number">1.0</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span></span><br><span class="line">    policy_stable = <span class="hljs-literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(env.nS):</span><br><span class="line">        old_action = np.argmax(policy[s])</span><br><span class="line">        Q_s = action_value(env, s, V)</span><br><span class="line">        best_action = np.argmax(Q_s)</span><br><span class="line">        policy[s] = np.eye(env.nA)[best_action]</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">if</span> old_action != best_action:</span><br><span class="line">            policy_stable = <span class="hljs-literal">False</span></span><br><span class="line">    <span class="hljs-keyword">return</span> policy_stable</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">policy_iteration</span>(<span class="hljs-params">env: GridWorldEnv, policy: Policy, gamma=<span class="hljs-number">1.0</span></span>) -&gt; <span class="hljs-type">Tuple</span>[Policy, StateValue]:</span></span><br><span class="line">    <span class="hljs-built_in">iter</span> = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">        V = policy_evaluate(policy, env, gamma)</span><br><span class="line">        policy_stable = policy_improvement(env, policy, V)</span><br><span class="line">        <span class="hljs-built_in">iter</span> += <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">if</span> policy_stable:</span><br><span class="line">            <span class="hljs-keyword">return</span> policy, V</span><br></pre></td></tr></tbody></table></figure><p></p>
Grid World
例子通过两轮迭代就可以收敛，以下是初始时随机策略的V值和第一次迭代后的V值。
<figure>
<img src="/zh/2020/rl-sutton-gridworld-2/policy_iter_0.png">
<figcaption>
初始随机策略 V 值
</figcaption>
</figure>
<figure>
<img src="/zh/2020/rl-sutton-gridworld-2/policy_iter_1.png">
<figcaption>
第一次迭代后的 V 值
</figcaption>
</figure>
<h2 id="值迭代">值迭代</h2>
<p>值迭代（ Value Iteration）的本质是，将policy iteration中的policy
evaluation过程从不断循环到收敛直至小于theta，改成只执行一遍，并直接用最佳Q值更新到状态V值，如此可以不用显示地算出<span class="math inline">\({\pi}\)</span>
而直接在V值上迭代。具体迭代公式如下：</p>
<div>
<p><span class="math display">\[
\begin{aligned}
v_{k+1}(s) &amp; \doteq \max _{a} \mathbb{E}\left[R_{t+1}+\gamma
v_{k}\left(S_{t+1}\right) \mid S_{t}=s, A_{t}=a\right] \\
&amp;=\max_{a}  q_{\pi_k}(s, a) \\
&amp;=\max _{a} \sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid s,
a\right)\left[r+\gamma v_{k}\left(s^{\prime}\right)\right]
\end{aligned}
\]</span></p>
</div>
<p>完整的伪代码为：</p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\textbf{Value Iteration, for estimating } \pi\approx \pi_{*} \\
&amp; \text{Algorithm parameter: a small threshold } \theta &gt; 0
\text{ determining accuracy of estimation} \\
&amp; \text{Initialize } V(s), \text{for all } s \in \mathcal{S}^{+}
\text{, arbitrarily except that } V (terminal) = 0\\
&amp; \\
&amp;1: \text{Loop:}\\
&amp;2: \quad \quad \Delta \leftarrow 0\\
&amp;3: \quad \quad \text{Loop for each } s \in \mathcal{S}:\\
&amp;4: \quad \quad \quad \quad v \leftarrow V(s) \\
&amp;5: \quad \quad \quad \quad V(s) \leftarrow \operatorname{max}_{a}
\sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid s, a\right)\left[r+\gamma
V\left(s^{\prime}\right)\right] \\
&amp;6: \quad \quad \quad \quad \Delta \leftarrow \max(\Delta, |v-V(s)|)
\\
&amp;7: \text{until } \Delta &lt; \theta \\
&amp; \\
&amp; \text{Output a deterministic policy, }\pi\approx \pi_{*} \text{,
such that} \\
&amp; \quad \quad \pi(s) \leftarrow \operatorname{argmax}_{a}
\sum_{s^{\prime}, r} p\left(s^{\prime}, r \mid s, a\right)\left[r+\gamma
V\left(s^{\prime}\right)\right]
\end{align*}
\]</span></p>
</div>
<p>代码实现也比较直接，可以复用上面已经实现的 action_value 函数。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">value_iteration</span>(<span class="hljs-params">env:GridWorldEnv, gamma=<span class="hljs-number">1.0</span>, theta=<span class="hljs-number">0.0001</span></span>) -&gt; <span class="hljs-type">Tuple</span>[Policy, StateValue]:</span></span><br><span class="line">    V = np.zeros(env.nS)</span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">        delta = <span class="hljs-number">0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(env.nS):</span><br><span class="line">            action_values = action_value(env, s, V, gamma=gamma)</span><br><span class="line">            best_action_value = np.<span class="hljs-built_in">max</span>(action_values)</span><br><span class="line">            delta = <span class="hljs-built_in">max</span>(delta, np.<span class="hljs-built_in">abs</span>(best_action_value - V[s]))</span><br><span class="line">            V[s] = best_action_value</span><br><span class="line">        <span class="hljs-keyword">if</span> delta &lt; theta:</span><br><span class="line">            <span class="hljs-keyword">break</span></span><br><span class="line"></span><br><span class="line">    policy = np.zeros([env.nS, env.nA])</span><br><span class="line">    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(env.nS):</span><br><span class="line">        action_values = action_value(env, s, V, gamma=gamma)</span><br><span class="line">        best_action = np.argmax(action_values)</span><br><span class="line">        policy[s, best_action] = <span class="hljs-number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> policy, V</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="异步迭代">异步迭代</h2>
<p>在第4.5节中提到了DP迭代方式的改进版：异步方式迭代（Asychronous
Iteration）。这里的异步是指每一轮无需全部扫一遍所有状态，而是根据上一轮变化的状态决定下一轮需要最多计算的状态数，类似于Dijkstra最短路径算法中用
heap
来维护更新节点集合，减少运算量。下面我们通过异步值迭代来演示异步迭代的工作方式。</p>
<p>下图表示状态的变化方向，若上一轮 <span class="math inline">\(V(s)\)</span> 发生更新，那么下一轮就要考虑状态 s
可能会影响到上游状态的集合（
p1，p2），避免下一轮必须遍历所有状态的V值计算。</p>
<figure>
<img src="/zh/2020/rl-sutton-gridworld-2/async_propa.png">
<figcaption>
Async 反向传播
</figcaption>
</figure>
<p>要做到部分更新就必须知道每个状态可能影响到的上游状态集合，上图对应的映射关系可以表示为</p>
<div>
<p><span class="math display">\[
\begin{align*}
s'_1 &amp;\rightarrow \{s\} \\
s'_2 &amp;\rightarrow \{s\} \\
s &amp;\rightarrow \{p_1, p_2\}
\end{align*}
\]</span></p>
</div>
<p>建立映射关系的代码如下，build_reverse_mapping 返回类型为 Dict[State,
Set[State]]。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_reverse_mapping</span>(<span class="hljs-params">env:GridWorldEnv</span>) -&gt; <span class="hljs-type">Dict</span>[State, <span class="hljs-type">Set</span>[State]]:</span></span><br><span class="line">    MAX_R, MAX_C = env.shape[<span class="hljs-number">0</span>], env.shape[<span class="hljs-number">1</span>]</span><br><span class="line">    mapping = {s: <span class="hljs-built_in">set</span>() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, MAX_R * MAX_C)}</span><br><span class="line">    action_delta = {Action.UP: (-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>), Action.DOWN: (<span class="hljs-number">1</span>, <span class="hljs-number">0</span>), Action.LEFT: (<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>), Action.RIGHT: (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)}</span><br><span class="line">    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, MAX_R * MAX_C):</span><br><span class="line">        r = s // MAX_R</span><br><span class="line">        c = s % MAX_R</span><br><span class="line">        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(Action):</span><br><span class="line">            neighbor_r = <span class="hljs-built_in">min</span>(MAX_R - <span class="hljs-number">1</span>, <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, r + action_delta[a][<span class="hljs-number">0</span>]))</span><br><span class="line">            neighbor_c = <span class="hljs-built_in">min</span>(MAX_C - <span class="hljs-number">1</span>, <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, c + action_delta[a][<span class="hljs-number">1</span>]))</span><br><span class="line">            s_ = neighbor_r * MAX_R + neighbor_c</span><br><span class="line">            mapping[s_].add(s)</span><br><span class="line">    <span class="hljs-keyword">return</span> mapping</span><br></pre></td></tr></tbody></table></figure>
<p>有了描述状态依赖的映射 dict 后，代码也比较简洁，changed_state_set
变量保存了这轮必须计算的状态集合。新的一轮迭代时，将下一轮需要计算的状态保存到
changed_state_set_ 中，本轮结束后，changed_state_set
更新成changed_state_set_，开始下一轮循环直至没有状态需要更新。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">value_iteration_async</span>(<span class="hljs-params">env:GridWorldEnv, gamma=<span class="hljs-number">1.0</span>, theta=<span class="hljs-number">0.0001</span></span>) -&gt; <span class="hljs-type">Tuple</span>[Policy, StateValue]:</span></span><br><span class="line">    mapping = build_reverse_mapping(env)</span><br><span class="line"></span><br><span class="line">    V = np.zeros(env.nS)</span><br><span class="line">    changed_state_set = <span class="hljs-built_in">set</span>(s <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(env.nS))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-built_in">iter</span> = <span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(changed_state_set) &gt; <span class="hljs-number">0</span>:</span><br><span class="line">        changed_state_set_ = <span class="hljs-built_in">set</span>()</span><br><span class="line">        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> changed_state_set:</span><br><span class="line">            action_values = action_value(env, s, V, gamma=gamma)</span><br><span class="line">            best_action_value = np.<span class="hljs-built_in">max</span>(action_values)</span><br><span class="line">            v_diff = np.<span class="hljs-built_in">abs</span>(best_action_value - V[s])</span><br><span class="line">            <span class="hljs-keyword">if</span> v_diff &gt; theta:</span><br><span class="line">                changed_state_set_.update(mapping[s])</span><br><span class="line">                V[s] = best_action_value</span><br><span class="line">        changed_state_set = changed_state_set_</span><br><span class="line">        <span class="hljs-built_in">iter</span> += <span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line">    policy = np.zeros([env.nS, env.nA])</span><br><span class="line">    <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(env.nS):</span><br><span class="line">        action_values = action_value(env, s, V, gamma=gamma)</span><br><span class="line">        best_action = np.argmax(action_values)</span><br><span class="line">        policy[s, best_action] = <span class="hljs-number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">return</span> policy, V</span><br></pre></td></tr></tbody></table></figure>
比较值迭代和异步值迭代方法后发现，值迭代用了4次循环，每次涉及所有状态，总计算状态数为
4 x 16 = 64。异步值迭代也用了4次循环，但是总计更新了54个状态。由于Grid
World
的状态数很少，异步值迭代优势并不明显，但是对于状态数众多并且迭代最终集中在少部分状态的环境下，节省的计算量还是很可观的。<p></p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
    
        
<nav class="pagination is-centered is-rounded" role="navigation" aria-label="pagination">
    <div class="pagination-previous">
        <a href="/tags/Python/">上一页</a>
    </div>
    <div class="pagination-next">
        <a href="/tags/Python/page/3/">下一页</a>
    </div>
    <ul class="pagination-list is-hidden-mobile">
        
        <li><a class="pagination-link" href="/tags/Python/">1</a></li>
        
        <li><a class="pagination-link is-current" href="/tags/Python/page/2/">2</a></li>
        
        <li><a class="pagination-link" href="/tags/Python/page/3/">3</a></li>
        
    </ul>
</nav>
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 MyEncyclopedia&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true" aria-controls="dropdown-menu7">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>简体中文</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu">
            <div class="dropdown-content">
            
                <a href="/tags/Python/page/2/" class="dropdown-item">
                    简体中文
                </a>
            
                <a href="/en/tags/Python/page/2/" class="dropdown-item">
                    English
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("zh-CN");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<style>
 .katex-display {
    overflow-x: auto;
    overflow-y: hidden;
    height: 100%;
  }
</style>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="站内搜索" />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>