<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>标签: Deep Learning - MyEncyclopedia</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">


<link href="/en/tags/Deep-Learning/page/2/" rel="alternate" hreflang="en" />
    


<meta name="description" content="">





    <meta property="og:type" content="website">
<meta property="og:title" content="MyEncyclopedia">
<meta property="og:url" content="https://myencyclopedia.github.io/tags/Deep-Learning/page/2/">
<meta property="og:site_name" content="MyEncyclopedia">
<meta property="og:locale">
<meta property="article:author" content="MyEncyclopedia">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="搜索" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://myencyclopedia.github.io">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#Deep Learning</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/tsp-3-pointer-net/" itemprop="url">TSP问题从DP算法到深度学习3：Pointer Network</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-10-24T06:45:01.000Z" itemprop="datePublished">10月 24 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 分钟 读完 (约 2000 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>本篇是TSP问题从DP算法到深度学习系列第三篇，在这一篇中，我们会开始进入深度学习领域来求近似解法。本文会介绍并实现指针网络（Pointer
Networks），一种seq-to-seq模型，它的设计目的就是为了解决TSP问题或者凸包（Convex
Hull）问题。本文代码在
https://github.com/MyEncyclopedia/blog/tree/master/tsp/ptr_net_pytorch
中。</p>
<ul>
<li><p><a href="/zh/2020/tsp-3-pointer-net/!--swig￼4--">第一篇: 递归DP方法 AC AIZU
TSP问题</a></p></li>
<li><p><a href="/zh/2020/tsp-3-pointer-net/!--swig￼5--">第二篇:
二维空间TSP数据集及其DP解法</a></p></li>
<li><p><a href="/zh/2020/tsp-3-pointer-net/!--swig￼6--">第三篇: 深度学习 Pointer Networks 的
Pytorch实现</a></p></li>
<li><p>第四篇: 搜寻最有可能路径：Viterbi算法和其他</p></li>
<li><p>第五篇: 深度强化学习无监督算法的 Pytorch实现</p></li>
</ul>
<h2 id="pointer-networks">Pointer Networks</h2>
<p>随着深度学习 seq-to-seq
模型作为概率近似模型在各领域的成功，TSP问题似乎也可以用同样的思路去解决。然而，传统的seq-to-seq
模型其输出的类别是预先固定的。例如，NLP RNN生成模型每一步会从 <span class="math inline">\(|V|\)</span> 大的词汇表中产生一个单词。
然而，有很大一类问题，譬如TSP问题、凸包（Convex
Hull）问题、Delaunay三角剖分问题，输出的类别不是事先固定的，而是随着输入而变化的。
<em>Pointer Networks </em>
的出现解决了这种限制：输出的类别可以通过指向某个输入，以此克服类别的问题，因此形象地取名为指针网络（Pointer
Networks）。先来看看原论文中提到的三个问题。</p>
<h3 id="凸包问题convex-hull">凸包问题（Convex Hull）</h3>
<p>如下图所示，需要在给定的10个点中找到若干个点，使得这些点包住了所有点。问题输入是不确定个数
n 个点的位置信息，输出是 k (k&lt;=n)个点的。
这个经典的算法问题已经被证明找出精确解等价于排序问题（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Convex_hull_algorithms">wikipedia
链接</a>），因此时间复杂度为 <span class="math inline">\(O(n*log(n))\)</span>。</p>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./convex_hull.png" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;=&amp; \left\{ P_{1}, \ldots,
P_{10} \right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp; \{2,4,3,5,6,7,2\}
\end{align*}
\]</span></p>
</div>
<h3 id="tsp-问题">TSP 问题</h3>
<p>TSP 和凸包问题很类似，输入为不确定个数的 n 个点信息，输出为这 n
个点的某序列。在。。。中，我们可以将确定解的时间复杂度从 <span class="math inline">\(O(n!)\)</span> 降到 <span class="math inline">\(O(n^2*2^n)\)</span>。</p>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./tsp.svg" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;= &amp;\left\{P_{1}, \ldots, P_{6}
\right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp; \{1,3,2,4,5,6,1\}
\end{align*}
\]</span></p>
</div>
<h3 id="delaunay三角剖分">Delaunay三角剖分</h3>
<p>Delaunay三角剖分问题是将平面上的散点集划分成三角形，使得在可能形成的三角剖分中，所形成的三角形的最小角最大。这个问题的输出是若干个集合，每个集合代表一个三角形，由输入点的编号表示。
<img src="/zh/2020/tsp-3-pointer-net/./delaunay_triangulation.png" alt="image info"></p>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;\text{Input:  } \mathcal{P} &amp;=&amp; \left\{P_{1}, \ldots, P_{5}
\right\} \\
&amp;\text{Output:  } C^{\mathcal{P}} &amp;=&amp;
\{(1,2,4),(1,4,5),(1,3,5),(1,2,3)\}
\end{align*}
\]</span></p>
</div>
<h3 id="seq-to-seq-模型">Seq-to-Seq 模型</h3>
<p>现在假设n是固定的，传统基本的seq-to-seq模型（参数部分记为 <span class="math inline">\(\theta\)</span> ），训练数据若记为<span class="math inline">\((\mathcal{P},
C^{\mathcal{P}})\)</span>，，将拟合以下条件概率：</p>
<p><span class="math display">\[
\begin{equation}
p\left(\mathcal{C}^{\mathcal{P}} | \mathcal{P} ;
\theta\right)=\prod_{i=1}^{m(\mathcal{P})} p\left(C_{i} | C_{1}, \ldots,
C_{i-1}, \mathcal{P} ; \theta\right)
\end{equation}
\]</span> 训练的方向是找到 <span class="math inline">\(\theta^{*}\)</span> 来最大化上述联合概率，即：
<span class="math display">\[
\begin{equation}
\theta^{*}=\underset{\theta}{\arg \max } \sum_{\mathcal{P},
\mathcal{C}^{\mathcal{P}}} \log p\left(\mathcal{C}^{\mathcal{P}} |
\mathcal{P} ; \theta\right)
\end{equation}
\]</span></p>
<h3 id="content-based-input-attention">Content Based Input
Attention</h3>
<p>一种增强基本seq-to-seq模型的方法是加入attention机制。记encoder和decoder隐藏状态分别是
$ (e_{1}, , e_{n}) $ 和 $ (d_{1}, , d_{m()}) $。seq-to-seq第 i 次输出了
<span class="math inline">\(d_i\)</span>，注意力机制额外计算第i步的注意力向量
<span class="math inline">\(d_i^{\prime}\)</span>，并将其和<span class="math inline">\(d_i\)</span>连接后作为隐藏状态。<span class="math inline">\(d_i^{\prime}\)</span>的计算方式如下，输入 $
(e_{1}, , e_{n}) $ 和 i 对应的权重向量 $ (a_{1}^{i}, , a_{n}^{i})
$做点乘。</p>
<p><span class="math display">\[
d_{i} = \sum_{j=1}^{n} a_{j}^{i} e_{j}
\]</span></p>
$ (a_{1}^{i}, , a_{n}^{i}) $ 是向量 $ (u_{1}^{i}, , u_{n}^{i}) $
softmax后的值， <span class="math inline">\(u_{j}^{i}\)</span> 表示
<span class="math inline">\(d_{i}\)</span> 和 <span class="math inline">\(e_{j}\)</span>的距离，Pointer
Networks论文中的距离为如下的tanh公式。
<div>
<p><span class="math display">\[
\begin{eqnarray}
u_{j}^{i} &amp;=&amp; v^{T} \tanh \left(W_{1} e_{j}+W_{2}
d_\right) \quad j \in(1, \ldots, n) \\
a_{j}^{i} &amp;=&amp; \operatorname{softmax}\left(u_{j}^{i}\right) \quad
j \in(1, \ldots, n)
\end{eqnarray}
\]</span></p>
</div>
<h3 id="更多attention计算方式">更多Attention计算方式</h3>
<p>在<em>FloydHub Blog - Attention Mechanism
</em>中，作者清楚地解释了两种经典的attention方法，第一种称为Additive
Attention，由<em>Dzmitry Bahdanau </em> 提出，也就是Pointer
Networks中通过tanh的计算方式，第二种称为 Multiplicative
Attention，由Thang Luong*提出。</p>
Luong Attention 有三种方法计算 <span class="math inline">\(d_{i}\)</span> 和 <span class="math inline">\(e_{j}\)</span>
的距离（或者可以认为向量间的对齐得分）。
<div>
<p><span class="math display">\[
\operatorname{score} \left( d_i, e_j \right)=
\begin{cases}
d_i^{\top} e_j &amp; \text { dot } \\
d_i^{\top} W_a e_j &amp; \text { general } \\
v_a^{\top} \tanh \left( W_a \left[ d_i ; e_j \right] \right) &amp; \text
{ concat }
\end{cases}
\]</span></p>
</div>
<h3 id="pointer-networks-1">Pointer Networks</h3>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./ptr_net.png" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<p>Pointer Networks 基于Additive Attention，其创新之处在于用 <span class="math inline">\(u^i_j\)</span> 作为第j个输入的评分，即第 i
次输出为1-n个输入中 <span class="math inline">\(u^i_j\)</span>
得分最高的j作为输出，这样巧妙的解决了n不是预先固定的限制。</p>
<div>
<p><span class="math display">\[
\begin{eqnarray*}
u_{j}^{i} &amp;=&amp; v^{T} \tanh \left(W_{1} e_{j}+W_{2} d_{i}\right)
\quad j \in(1, \ldots, n) \\
p\left(C_{i} | C_{1}, \ldots, C_{i-1}, \mathcal{P}\right) &amp;=&amp;
\operatorname{softmax}\left(u^{i}\right)
\end{eqnarray*}
\]</span></p>
</div>
<h2 id="pytorch-代码实现">PyTorch 代码实现</h2>
<p>在本系列第二篇 <a href="/zh/2020/tsp-3-pointer-net/!--swig￼8--">episode
2</a>，中，我们说明过TSP数据集的格式，每一行字段意义如下</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x0, y0, x1, y1, ... output 1 v1 v2 v3 ... 1</span><br></pre></td></tr></tbody></table></figure>
<h3 id="转换成pytorch-dataset">转换成PyTorch Dataset</h3>
<p>每一个case会转换成nd.ndarray，共有五个分量，分别是 (input, input_len,
output_in, output_out, output_len) 并且分装成pytorch的 Dataset类。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPDataset</span>(<span class="hljs-params">Dataset</span>):</span></span><br><span class="line">	<span class="hljs-string">"each data item of form (input, input_len, output_in, output_out, output_len)"</span></span><br><span class="line">	data: <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]]</span><br><span class="line">	</span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">		<span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span></span><br><span class="line">		<span class="hljs-built_in">input</span>, input_len, output_in, output_out, output_len = self.data[index]</span><br><span class="line">		<span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>, input_len, output_in, output_out, output_len</span><br></pre></td></tr></tbody></table></figure> <img src="/zh/2020/tsp-3-pointer-net/./data_loader.svg" alt="image info"><p></p>
<h3 id="pytorch-pad_packed_sequence-优化技巧">PyTorch
pad_packed_sequence 优化技巧</h3>
<p>PyTorch 实现 seq-to-seq 模型一般会使用
<strong>pack_padded_sequence</strong> 以及
<strong>pad_packed_sequence</strong>
来减少计算量，本质上可以认为根据pad大小分批进行矩阵运算，减少被pad的矩阵元素导致的无效运算，详细的解释可以参考
https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning#decoder-1。</p>
<figure>
<img src="/zh/2020/tsp-3-pointer-net/./ex_padded_seq.jpg" alt="image info">
<figcaption aria-hidden="true">image info</figcaption>
</figure>
<p>对应代码如下：</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RNNEncoder</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">	rnn: <span class="hljs-type">Union</span>[nn.LSTM, nn.GRU, nn.RNN]</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, rnn_type: <span class="hljs-built_in">str</span>, bidirectional: <span class="hljs-built_in">bool</span>, num_layers: <span class="hljs-built_in">int</span>, input_size: <span class="hljs-built_in">int</span>, hidden_size: <span class="hljs-built_in">int</span>, dropout: <span class="hljs-built_in">float</span></span>):</span></span><br><span class="line">		<span class="hljs-built_in">super</span>(RNNEncoder, self).__init__()</span><br><span class="line">		<span class="hljs-keyword">if</span> bidirectional:</span><br><span class="line">			<span class="hljs-keyword">assert</span> hidden_size % <span class="hljs-number">2</span> == <span class="hljs-number">0</span></span><br><span class="line">			hidden_size = hidden_size // <span class="hljs-number">2</span></span><br><span class="line">		self.rnn = rnn_init(rnn_type, input_size=input_size, hidden_size=hidden_size, bidirectional=bidirectional,num_layers=num_layers, dropout=dropout)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, src: Tensor, src_lengths: Tensor, hidden: Tensor = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, Tensor]:</span></span><br><span class="line">		lengths = src_lengths.view(-<span class="hljs-number">1</span>).tolist()</span><br><span class="line">		packed_src = pack_padded_sequence(src, lengths)</span><br><span class="line">		memory_bank, hidden_final = self.rnn(packed_src, hidden)</span><br><span class="line">		memory_bank = pad_packed_sequence(memory_bank)[<span class="hljs-number">0</span>]</span><br><span class="line">		<span class="hljs-keyword">return</span> memory_bank, hidden_final</span><br></pre></td></tr></tbody></table></figure>
<h3 id="注意力机制相关代码">注意力机制相关代码</h3>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Attention</span>(<span class="hljs-params">nn.Module</span>):</span></span><br><span class="line">	linear_out: nn.Linear</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, dim: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">		<span class="hljs-built_in">super</span>(Attention, self).__init__()</span><br><span class="line">		self.linear_out = nn.Linear(dim * <span class="hljs-number">2</span>, dim, bias=<span class="hljs-literal">False</span>)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score</span>(<span class="hljs-params">self, src: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">		batch_size, src_len, dim = src.size()</span><br><span class="line">		_, target_len, _ = target.size()</span><br><span class="line">		target_ = target</span><br><span class="line">		src_ = src.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span><br><span class="line">		<span class="hljs-keyword">return</span> torch.bmm(target_, src_)</span><br><span class="line"></span><br><span class="line">	<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, src: Tensor, target: Tensor, src_lengths: Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[Tensor, Tensor]:</span></span><br><span class="line">		<span class="hljs-keyword">assert</span> target.dim() == <span class="hljs-number">3</span></span><br><span class="line"></span><br><span class="line">		batch_size, src_len, dim = src.size()</span><br><span class="line">		_, target_len, _ = target.size()</span><br><span class="line"></span><br><span class="line">		align_score = self.score(src, target)</span><br><span class="line"></span><br><span class="line">		mask = sequence_mask(src_lengths)</span><br><span class="line">		<span class="hljs-comment"># (batch_size, max_len) -&gt; (batch_size, 1, max_len)</span></span><br><span class="line">		mask = mask.unsqueeze(<span class="hljs-number">1</span>)</span><br><span class="line">		align_score.data.masked_fill_(~mask, -<span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>))</span><br><span class="line">		align_score = F.softmax(align_score, -<span class="hljs-number">1</span>)</span><br><span class="line"></span><br><span class="line">		c = torch.bmm(align_score, src)</span><br><span class="line"></span><br><span class="line">		concat_c = torch.cat([c, target], -<span class="hljs-number">1</span>)</span><br><span class="line">		attn_h = self.linear_out(concat_c)</span><br><span class="line"></span><br><span class="line">		<span class="hljs-keyword">return</span> attn_h, align_score</span><br></pre></td></tr></tbody></table></figure>
<h2 id="参考资料">参考资料</h2>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/tsp-2-dp-tour/" itemprop="url">TSP问题从DP算法到深度学习2：欧氏空间数据集的DP解</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-09-19T18:45:01.000Z" itemprop="datePublished">9月 20 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 分钟 读完 (约 1761 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>本篇是TSP问题从DP算法到深度学习系列第二篇。</p>
<ul>
<li><p><a href="/zh/2020/tsp-2-dp-tour/!--swig￼11--">第一篇: 递归DP方法 AC AIZU
TSP问题</a></p></li>
<li><p><strong><a href="/zh/2020/tsp-2-dp-tour/!--swig￼12--">第二篇:
二维空间TSP数据集及其DP解法</a></strong></p></li>
<li><p>第三篇: 深度学习 Pointer Networks 的 Pytorch实现</p></li>
<li><p>第四篇: 搜寻最有可能路径：Viterbi算法和其他</p></li>
<li><p>第五篇: 深度强化学习无监督算法的 Pytorch实现</p></li>
</ul>
<h2 id="aizu-tsp-自底向上迭代dp解">AIZU TSP 自底向上迭代DP解</h2>
<p>上一篇中，我们用Python 3和Java
8完成了自顶向下递归版本的DP解。我们继续改进代码，将它转换成标准DP方式：自底向上的迭代DP版本。下图是3个点TSP问题的递归调用图。</p>
<p><img src="/zh/2020/tsp-2-dp-tour/ver3-top-down.svg" title="3点TSP递归调用图"></p>
<p>将这个图反过来检查状态的依赖关系，可以很容易发现规律：首先计算状态位含有一个1的点，接着是两个1的节点，最后是状态位三个1的点。简而言之，在计算状态位为n+1个1的节点时需要用到n个1的节点的计算结果，如果能依照这样的
topological 顺序来的话，就可以去除递归，写成迭代（循环）版本的DP。</p>
<p><img src="/zh/2020/tsp-2-dp-tour/ver3-bottom-up.svg" title="3点TSP状态依赖"></p>
<p>迭代算法的Java 伪代码如下</p>
<figure class="highlight java hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> bitset_num = N; bitset_num &gt;=<span class="hljs-number">0</span>; bitset_num++) {</span><br><span class="line">	<span class="hljs-keyword">while</span>(hasNextCombination(bitset_num)) {</span><br><span class="line">		<span class="hljs-keyword">int</span> state = nextCombination(bitset_num);</span><br><span class="line">		<span class="hljs-comment">// compute dp[state][v], v-th bit is set in state</span></span><br><span class="line">		<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> v = <span class="hljs-number">0</span>; v &lt; n; v++) {</span><br><span class="line">			<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; n; u++) {</span><br><span class="line">				<span class="hljs-comment">// for each u not reached by this state</span></span><br><span class="line">				<span class="hljs-keyword">if</span> (!include(state, u)) {</span><br><span class="line">					dp[state][v] = min(dp[state][v], </span><br><span class="line">						dp[new_state_include_u][u] + dist[v][u]);</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>举例来说，dp[00010][1] 是从顶点0出发，刚经过顶点1的最小距离 <span class="math inline">\(0 \rightarrow 1 \rightarrow ? \rightarrow ?
\rightarrow ? \rightarrow 0\)</span>。</p>
<p>为了找到最小距离值，就必须遍历所有可能的下一个可能的顶点u
（第一个问号位置）。 <span class="math display">\[
(0 \rightarrow 1) +
\begin{align*}
  \min \left\lbrace
  \begin{array}{r@{}l}
    2 \rightarrow ? \rightarrow ? \rightarrow 0 + dist(1,2)
\qquad\text{    new_state=[00110][2] } \qquad\\\\
    3 \rightarrow ? \rightarrow ?  \rightarrow 0 + dist(1,3)
\qquad\text{    new_state=[01010][3] } \qquad\\\\
    4 \rightarrow ? \rightarrow ?  \rightarrow 0 + dist(1,4)
\qquad\text{    new_state=[10010][4] } \qquad
  \end{array}
  \right.
\end{align*}
\]</span></p>
<h3 id="迭代dp-ac代码">迭代DP AC代码</h3>
<p>以下是AC 的Java 算法核心代码。完整代码在 github/MyEncyclopedia 的<a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_aizu/Main_loop.java">tsp/alg_aizu/Main_loop.java</a>。</p>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span> </span>{</span><br><span class="line">	<span class="hljs-keyword">int</span> N = g.V_NUM;</span><br><span class="line">	<span class="hljs-keyword">long</span>[][] dp = <span class="hljs-keyword">new</span> <span class="hljs-keyword">long</span>[<span class="hljs-number">1</span> &lt;&lt; N][N];</span><br><span class="line">	<span class="hljs-comment">// init dp[][] with MAX</span></span><br><span class="line">	<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; dp.length; i++) {</span><br><span class="line">		Arrays.fill(dp[i], Integer.MAX_VALUE);</span><br><span class="line">	}</span><br><span class="line">	dp[(<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> state = (<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">2</span>; state &gt;= <span class="hljs-number">0</span>; state--) {</span><br><span class="line">		<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> v = <span class="hljs-number">0</span>; v &lt; N; v++) {</span><br><span class="line">			<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; N; u++) {</span><br><span class="line">				<span class="hljs-keyword">if</span> (((state &gt;&gt; u) &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>) {</span><br><span class="line">					dp[state][v] = Math.min(dp[state][v], dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + g.edges[v][u]);</span><br><span class="line">				}</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">	<span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] == Integer.MAX_VALUE ? -<span class="hljs-number">1</span> : dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>很显然，时间算法复杂度对应了三重 for 循环，为 O(<span class="math inline">\(2^n * n * n\)</span>) = O(<span class="math inline">\(2^n*n^2\)</span> )。</p>
<p>类似的，Python 3 AC 代码如下。完整代码在 github/MyEncyclopedia 的<a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/blob/master/tsp/alg_aizu/TSP_loop.py">tsp/alg_aizu/TSP_loop.py</a>。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPSolver</span>:</span></span><br><span class="line">    g: Graph</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, g: Graph</span>):</span></span><br><span class="line">        self.g = g</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        :param v:</span></span><br><span class="line"><span class="hljs-string">        :param state:</span></span><br><span class="line"><span class="hljs-string">        :return: -1 means INF</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        N = self.g.v_num</span><br><span class="line">        dp = [[INT_INF <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span> &lt;&lt; N)]</span><br><span class="line"></span><br><span class="line">        dp[(<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">for</span> state <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((<span class="hljs-number">1</span> &lt;&lt; N) - <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):</span><br><span class="line">            <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">                    <span class="hljs-keyword">if</span> ((state &gt;&gt; u) &amp; <span class="hljs-number">1</span>) == <span class="hljs-number">0</span>:</span><br><span class="line">                        <span class="hljs-keyword">if</span> dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] != INT_INF <span class="hljs-keyword">and</span> self.g.edges[v][u] != INT_INF:</span><br><span class="line">                            <span class="hljs-keyword">if</span> dp[state][v] == INT_INF:</span><br><span class="line">                                dp[state][v] = dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + self.g.edges[v][u]</span><br><span class="line">                            <span class="hljs-keyword">else</span>:</span><br><span class="line">                                dp[state][v] = <span class="hljs-built_in">min</span>(dp[state][v], dp[state | <span class="hljs-number">1</span> &lt;&lt; u][u] + self.g.edges[v][u])</span><br><span class="line">        <span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure>
<h2 id="一个欧式空间tsp数据集">一个欧式空间TSP数据集</h2>
<p>至此，TSP的DP解法全部讲解完毕。接下去，我们引入一个二维欧式空间的TSP数据集
<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/0B2fg8yPGn2TCMzBtS0o4Q2RJaEU">PTR_NET
on Google Drive</a> ，这个数据集是 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.03134">Pointer Networks</a> 的作者
Oriol Vinyals 用于模型的训练测试而引入的。</p>
<p>数据集的每一行格式如下：</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x1, y1, x2, y2, ... output 1 v1 v2 v3 ... 1</span><br></pre></td></tr></tbody></table></figure>
<p>一行开始为n个点的x， y坐标，接着是
output，再接着是1，表示从顶点1出发，经v1，v2，...，返回1，注意顶点编号从1开始。</p>
<p>十个顶点数据集的一些数据示例如下：</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0.607122 0.664447 0.953593 0.021519 0.757626 0.921024 0.586376 0.433565 0.786837 0.052959 0.016088 0.581436 0.496714 0.633571 0.227777 0.971433 0.665490 0.074331 0.383556 0.104392 output 1 3 8 6 10 9 5 2 4 7 1 </span><br><span class="line">0.930534 0.747036 0.277412 0.938252 0.794592 0.794285 0.961946 0.261223 0.070796 0.384302 0.097035 0.796306 0.452332 0.412415 0.341413 0.566108 0.247172 0.890329 0.429978 0.232970 output 1 3 2 9 6 5 8 7 10 4 1 </span><br><span class="line">0.686712 0.087942 0.443054 0.277818 0.494769 0.985289 0.559706 0.861138 0.532884 0.351913 0.712561 0.199273 0.554681 0.657214 0.909986 0.277141 0.931064 0.639287 0.398927 0.406909 output 1 5 2 10 7 4 3 9 8 6 1 </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>画出第一个例子的全部顶点和边。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line">points=<span class="hljs-string">'0.607122 0.664447 0.953593 0.021519 0.757626 0.921024 0.586376 0.433565 0.786837 0.052959 0.016088 0.581436 0.496714 0.633571 0.227777 0.971433 0.665490 0.074331 0.383556 0.104392'</span></span><br><span class="line">float_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">float</span>(x), points.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"></span><br><span class="line">x,y = [],[]</span><br><span class="line"><span class="hljs-keyword">for</span> idx, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(float_list):</span><br><span class="line">  <span class="hljs-keyword">if</span> idx % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:</span><br><span class="line">    x.append(p)</span><br><span class="line">  <span class="hljs-keyword">else</span>:</span><br><span class="line">    y.append(p)</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x)):</span><br><span class="line">  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x)):</span><br><span class="line">    <span class="hljs-keyword">if</span> i == j:</span><br><span class="line">      <span class="hljs-keyword">continue</span></span><br><span class="line">    plt.plot((x[i],x[j]),(y[i],y[j]))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2020/tsp-2-dp-tour/tsp10_full.png">
<figcaption>
全连接的图
</figcaption>
</figure>
<p>这个例子的最短TSP旅程为 <span class="math display">\[
1 \rightarrow 3 \rightarrow 8 \rightarrow 6 \rightarrow 10 \rightarrow 9
\rightarrow 5 \rightarrow 2 \rightarrow 4 \rightarrow 7 \rightarrow 1
\]</span></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tour_str = <span class="hljs-string">'1 3 8 6 10 9 5 2 4 7 1'</span></span><br><span class="line">tour = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x), tour_str.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(tour)-<span class="hljs-number">1</span>):</span><br><span class="line">  p1 = tour[i] - <span class="hljs-number">1</span></span><br><span class="line">  p2 = tour[i + <span class="hljs-number">1</span>] - <span class="hljs-number">1</span></span><br><span class="line">  plt.plot((x[p1],x[p2]),(y[p1],y[p2]))</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<figure>
<img src="/zh/2020/tsp-2-dp-tour/tsp10_tour.png">
<figcaption>
最短路径
</figcaption>
</figure>
<h2 id="ptr_net-tsp-的python代码">PTR_NET TSP 的Python代码</h2>
<h3 id="初始化init-graph-edges">初始化Init Graph Edges</h3>
<p>在之前的自顶向下的递归版本中，需要做一些改动。首先，是图的初始化，我们依然延续之前的邻接矩阵来表示，由于这次的图是无向图，对于任意两个顶点，需要初始化双向的边。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">g: Graph = Graph(N)</span><br><span class="line"><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">	<span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N):</span><br><span class="line">		diff_x = coordinates[v][<span class="hljs-number">0</span>] - coordinates[u][<span class="hljs-number">0</span>]</span><br><span class="line">		diff_y = coordinates[v][<span class="hljs-number">1</span>] - coordinates[u][<span class="hljs-number">1</span>]</span><br><span class="line">		dist: <span class="hljs-built_in">float</span> = math.sqrt(diff_x * diff_x + diff_y * diff_y)</span><br><span class="line">		g.setDist(u, v, dist)</span><br><span class="line">		g.setDist(v, u, dist)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="辅助变量记录父节点">辅助变量记录父节点</h3>
<p>另一大改动是需要在遍历过程中保存的顶点关联信息，以便在最终找到最短路径值时可以回溯对应的完整路径。在下面代码中，使用parent[bitstate][v]
来保存此状态下最小路径对应的顶点u。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ret: <span class="hljs-built_in">float</span> = FLOAT_INF</span><br><span class="line">u_min: <span class="hljs-built_in">int</span> = -<span class="hljs-number">1</span></span><br><span class="line">	<span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num):</span><br><span class="line">		<span class="hljs-keyword">if</span> (state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>:</span><br><span class="line">			s: <span class="hljs-built_in">float</span> = self._recurse(u, state | <span class="hljs-number">1</span> &lt;&lt; u)</span><br><span class="line">				<span class="hljs-keyword">if</span> s + edges[v][u] &lt; ret:</span><br><span class="line">					ret = s + edges[v][u]</span><br><span class="line">					u_min = u</span><br><span class="line">	dp[state][v] = ret</span><br><span class="line">	self.parent[state][v] = u_min</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>当最终最短行程确定后，根据parent的信息可以按图索骥找到完整的行程顶点信息。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_form_tour</span>(<span class="hljs-params">self</span>):</span></span><br><span class="line">	self.tour = [<span class="hljs-number">0</span>]</span><br><span class="line">	bit = <span class="hljs-number">0</span></span><br><span class="line">	v = <span class="hljs-number">0</span></span><br><span class="line">	<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num - <span class="hljs-number">1</span>):</span><br><span class="line">		v = self.parent[bit][v]</span><br><span class="line">		self.tour.append(v)</span><br><span class="line">		bit = bit | (<span class="hljs-number">1</span> &lt;&lt; v)</span><br><span class="line">	self.tour.append(<span class="hljs-number">0</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>需要注意的是，有可能存在多个最短行程，它们的距离值是一致的。这种情况下，代码输出的最短路径可能和数据集output后行程路径不一致，但是的两者的总距离是一致的。下面的代码验证了这一点。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tsp: TSPSolver = TSPSolver(g)</span><br><span class="line">tsp.solve()</span><br><span class="line"></span><br><span class="line">output_dist: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span></span><br><span class="line">output_tour = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x) - <span class="hljs-number">1</span>, output.split(<span class="hljs-string">' '</span>)))</span><br><span class="line"><span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(output_tour)):</span><br><span class="line">	pre_v = output_tour[v-<span class="hljs-number">1</span>]</span><br><span class="line">	curr_v = output_tour[v]</span><br><span class="line">	diff_x = coordinates[pre_v][<span class="hljs-number">0</span>] - coordinates[curr_v][<span class="hljs-number">0</span>]</span><br><span class="line">	diff_y = coordinates[pre_v][<span class="hljs-number">1</span>] - coordinates[curr_v][<span class="hljs-number">1</span>]</span><br><span class="line">	dist: <span class="hljs-built_in">float</span> = math.sqrt(diff_x * diff_x + diff_y * diff_y)</span><br><span class="line">	output_dist += dist</span><br><span class="line"></span><br><span class="line">	passed = <span class="hljs-built_in">abs</span>(tsp.dist - output_dist) &lt; <span class="hljs-number">10e-5</span></span><br><span class="line">	<span class="hljs-keyword">if</span> passed:</span><br><span class="line">		<span class="hljs-built_in">print</span>(<span class="hljs-string">f'passed dist=<span class="hljs-subst">{tsp.tour}</span>'</span>)</span><br><span class="line">	<span class="hljs-keyword">else</span>:</span><br><span class="line">		<span class="hljs-built_in">print</span>(<span class="hljs-string">f'Min Tour Distance = <span class="hljs-subst">{output_dist}</span>, Computed Tour Distance = <span class="hljs-subst">{tsp.dist}</span>, Expected Tour = <span class="hljs-subst">{output_tour}</span>, Result = <span class="hljs-subst">{tsp.tour}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>本文所有代码在 github/MyEncyclopedia tsp/alg_plane 中。</p>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/tsp-1-dp-alg/" itemprop="url">TSP问题从DP算法到深度学习1： 递归DP方法 AC AIZU TSP问题</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-08-29T18:45:01.000Z" itemprop="datePublished">8月 30 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 分钟 读完 (约 2013 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">旅行商问题（TSP）</a>是计算机算法中经典的NP
hard 问题。 在本系列文章中，我们将首先使用动态规划 AC
aizu中的TSP问题，然后再利用深度学习求大规模下的近似解。深度学习应用解决问题时先以PyTorch实现监督学习算法
Pointer Network，进而结合强化学习来无监督学习，提高数据使用效率。
本系列完整列表如下：</p>
<ul>
<li><p><strong><a href="/zh/2020/tsp-1-dp-alg/!--swig￼6--">第一篇: 递归DP方法 AC AIZU
TSP问题</a></strong></p></li>
<li><p>第二篇: 二维空间TSP数据集及其DP解法</p></li>
<li><p>第三篇: 深度学习 Pointer Networks 的 Pytorch实现</p></li>
<li><p>第四篇: 搜寻最有可能路径：Viterbi算法和其他</p></li>
<li><p>第五篇: 深度强化学习无监督算法的 Pytorch实现</p></li>
</ul>
<h2 id="tsp-问题回顾">TSP 问题回顾</h2>
<p>TSP可以用图模型来表达，无论有向图或无向图，无论全连通图或者部分连通的图都可以作为TSP问题。
<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Wikipedia
TSP</a>
中举了一个无向全连通的TSP例子。如下图所示，四个顶点A，B，C，D构成无向全连通图。TSP问题要求在所有遍历所有点后返回初始点的回路中找到最短的回路。例如，<span class="math inline">\(A \rightarrow B \rightarrow C \rightarrow D
\rightarrow A\)</span> 和 <span class="math inline">\(A \rightarrow C
\rightarrow B \rightarrow D \rightarrow A\)</span>
都是有效的回路，但是TSP需要返回这些回路中的最短回路（注意，最短回路可能会有多条）。</p>
<figure>
<img src="/zh/2020/tsp-1-dp-alg/wiki_k4.png">
<figcaption>
Wikipedia 4个顶点组成的图
</figcaption>
</figure>
<p>无论是哪种类型的图，我们都能用邻接矩阵表示出一个图。上面的Wikipedia中的图可以用下面的矩阵来描述。</p>
<p><span class="math display">\[
\begin{matrix}
&amp; \begin{matrix}A&amp;B&amp;C&amp;D\end{matrix} \\\\
\begin{matrix}A\\\\B\\\\C\\\\D\end{matrix} &amp;
  \begin{bmatrix}-&amp;20&amp;42&amp;35\\\\20&amp;-&amp;30&amp;34\\\\42&amp;30&amp;-&amp;12\\\\35&amp;34&amp;12&amp;-\end{bmatrix}\\\\
\end{matrix}
\]</span></p>
<p>当然，大多数情况下，TSP问题会被限定在欧氏空间，即二维地图中的全连通无向图。因为，如果将顶点表示一个地理位置，一般来说它可以和其他所有顶点连通，回来的距离相同，由此构成无向图。</p>
<p><img src="/zh/2020/tsp-1-dp-alg/5-simplex_graph.svg" title="全连通无向图例子"></p>
<h2 id="aizu-tsp-问题">AIZU TSP 问题</h2>
<p><a target="_blank" rel="noopener" href="http://judge.u-aizu.ac.jp/onlinejudge/description.jsp?id=DPL_2_A">AIZU在线题库</a>
有一道有向不完全连通图的TSP问题。给定V个顶点和E条边，输出最小回路值。例如，题目里的例子如下所示，由4个顶点和6条单向边构成。</p>
<p><img src="/zh/2020/tsp-1-dp-alg/vertex4-problem.svg" title="AIZU TSP 题目例子"></p>
<p>这个示例的答案是16，对应的回路是 <span class="math inline">\(0\rightarrow1\rightarrow3\rightarrow2\rightarrow0\)</span>，由下图的红色边构成。注意，这个题目可能不存在合法解，原因是无回路存在，此时返回-1，可以合理地理解成无穷大。</p>
<p><img src="/zh/2020/tsp-1-dp-alg/vertex4-sol.svg" title="AIZU TSP 题目答案对应回路"></p>
<h3 id="暴力解法">暴力解法</h3>
<p>一种暴力方法是枚举所有可能的从某一顶点的回路，取其中的最小值即可。下面的
Python 示例如何枚举4个顶点构成的图中从顶点0出发的所有回路。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> permutations</span><br><span class="line">v = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]</span><br><span class="line">p = permutations(v)</span><br><span class="line"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(p):</span><br><span class="line">  <span class="hljs-built_in">print</span>([<span class="hljs-number">0</span>] + <span class="hljs-built_in">list</span>(t) + [<span class="hljs-number">0</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>所有从顶点0出发的回路如下：</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>]</span><br><span class="line">[<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]</span><br></pre></td></tr></tbody></table></figure>
<p>很显然，这种方式的时间复杂度是 O(<span class="math inline">\(n!\)</span>)，无法通过AIZU。</p>
<p><img src="/zh/2020/tsp-1-dp-alg/factorial_paths.svg" title="阶乘级的时间复杂度"></p>
<h3 id="动态规划求解">动态规划求解</h3>
<p>我们可以使用位状态压缩的动态规划来AC这道题。
首先，需要将回路过程中的状态编码成二进制的表示。例如，在四顶点的例子中，如果顶点2和1都被访问过，并且此时停留在顶点1。将已经访问的顶点对应的位置1，那么编码成<strong>0110</strong>，此外，还需要保存当前顶点的位置，因此我们将代表状态的数组扩展成二维，第一维是位状态，第二维是顶点所在位置，即
<span class="math inline">\(dp[bitstate][v]\)</span>。这个例子的状态表示就是
<span class="math inline">\(dp["0110"][1]\)</span>。</p>
<p>状态转移方程如下： <span class="math display">\[
dp[bitstate][v] = \min ( dp[bitstate \cup \{u\}][u] + dist(v,u) \mid u
\notin bitstate )
\]</span> 这种方法对应的时间复杂度是 O(<span class="math inline">\(n^2*2^n\)</span> )，因为总共有 <span class="math inline">\(2^n * n\)</span>
个状态，而每个状态又需要一次遍历。虽然都是指数级复杂度，但是它们的巨大区别由下面可以看出区别。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(n!\)</span></th>
<th><span class="math inline">\(n^2*2^n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n=8</td>
<td>40320</td>
<td>16384</td>
</tr>
<tr class="even">
<td>n=10</td>
<td>3628800</td>
<td>102400</td>
</tr>
<tr class="odd">
<td>n=12</td>
<td>479001600</td>
<td>589824</td>
</tr>
<tr class="even">
<td>n=14</td>
<td>87178291200</td>
<td>3211264</td>
</tr>
</tbody>
</table>
<p>暂停思考一下为什么状态压缩DP能工作。注意到之前暴力解法中其实是有很多重复计算，下面红圈表示重复的计算节点。</p>
<p><img src="/zh/2020/tsp-1-dp-alg/dp_paths.svg" title="重复的计算节点"></p>
<p>在本篇中，我们将会用Python 3和Java 8 实现自顶向下的DP
缓存版本。这种方式比较符合直觉，因为我们不需要预先考虑计算节点的依赖关系。在Java中我们使用了一个小技巧，dp数组初始化成Integer.MAX_VALUE，如此只需要一条语句就能完成更新dp值。</p>
<figure class="highlight java hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = Math.min(res, s + g.edges[v][u]);</span><br></pre></td></tr></tbody></table></figure>
<p>当然，为了AC 这道题，我们需要区分出真正无法到达的情况并返回-1。
在Python实现中，也可以使用同样的技巧，但是这次示例一般的实现方法：将dp数组初始化成-1并通过
if-else 来区分不同情况。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INT_INF = -<span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> s != INT_INF <span class="hljs-keyword">and</span> edges[v][u] != INT_INF:</span><br><span class="line">    <span class="hljs-keyword">if</span> ret == INT_INF:</span><br><span class="line">        ret = s + edges[v][u]</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        ret = <span class="hljs-built_in">min</span>(ret, s + edges[v][u])</span><br></pre></td></tr></tbody></table></figure>
<p>下面附完整的Python 3和Java 8的AC代码，同步在 <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/blog/tree/master/tsp/alg_aizu">github</a>。</p>
<h3 id="aizu-java-8-递归dp版本">AIZU Java 8 递归DP版本</h3>
<figure class="highlight java hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">// passed http://judge.u-aizu.ac.jp/onlinejudge/description.jsp?id=DPL_2_A</span></span><br><span class="line"><span class="hljs-keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="hljs-keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Main</span> </span>{</span><br><span class="line">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Graph</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> V_NUM;</span><br><span class="line">        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span>[][] edges;</span><br><span class="line"></span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Graph</span><span class="hljs-params">(<span class="hljs-keyword">int</span> V_NUM)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">this</span>.V_NUM = V_NUM;</span><br><span class="line">            <span class="hljs-keyword">this</span>.edges = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[V_NUM][V_NUM];</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; V_NUM; i++) {</span><br><span class="line">                Arrays.fill(<span class="hljs-keyword">this</span>.edges[i], Integer.MAX_VALUE);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setDist</span><span class="hljs-params">(<span class="hljs-keyword">int</span> src, <span class="hljs-keyword">int</span> dest, <span class="hljs-keyword">int</span> dist)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">this</span>.edges[src][dest] = dist;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSP</span> </span>{</span><br><span class="line">        <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> Graph g;</span><br><span class="line">        <span class="hljs-keyword">long</span>[][] dp;</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">TSP</span><span class="hljs-params">(Graph g)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">this</span>.g = g;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">int</span> N = g.V_NUM;</span><br><span class="line">            dp = <span class="hljs-keyword">new</span> <span class="hljs-keyword">long</span>[<span class="hljs-number">1</span> &lt;&lt; N][N];</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; dp.length; i++) {</span><br><span class="line">                Arrays.fill(dp[i], -<span class="hljs-number">1</span>);</span><br><span class="line">            }</span><br><span class="line">    </span><br><span class="line">            <span class="hljs-keyword">long</span> ret = recurse(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);</span><br><span class="line">            <span class="hljs-keyword">return</span> ret == Integer.MAX_VALUE ? -<span class="hljs-number">1</span> : ret;</span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> <span class="hljs-title">recurse</span><span class="hljs-params">(<span class="hljs-keyword">int</span> state, <span class="hljs-keyword">int</span> v)</span> </span>{</span><br><span class="line">            <span class="hljs-keyword">int</span> ALL = (<span class="hljs-number">1</span> &lt;&lt; g.V_NUM) - <span class="hljs-number">1</span>;</span><br><span class="line">            <span class="hljs-keyword">if</span> (dp[state][v] &gt;= <span class="hljs-number">0</span>) {</span><br><span class="line">                <span class="hljs-keyword">return</span> dp[state][v];</span><br><span class="line">            }</span><br><span class="line">            <span class="hljs-keyword">if</span> (state == ALL &amp;&amp; v == <span class="hljs-number">0</span>) {</span><br><span class="line">                dp[state][v] = <span class="hljs-number">0</span>;</span><br><span class="line">                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;</span><br><span class="line">            }</span><br><span class="line">            <span class="hljs-keyword">long</span> res = Integer.MAX_VALUE;</span><br><span class="line">            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> u = <span class="hljs-number">0</span>; u &lt; g.V_NUM; u++) {</span><br><span class="line">                <span class="hljs-keyword">if</span> ((state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>) {</span><br><span class="line">                    <span class="hljs-keyword">long</span> s = recurse(state | <span class="hljs-number">1</span> &lt;&lt; u, u);</span><br><span class="line">                    res = Math.min(res, s + g.edges[v][u]);</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            dp[state][v] = res;</span><br><span class="line">            <span class="hljs-keyword">return</span> res;</span><br><span class="line">    </span><br><span class="line">        }</span><br><span class="line">    </span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{</span><br><span class="line">    </span><br><span class="line">        Scanner in = <span class="hljs-keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="hljs-keyword">int</span> V = in.nextInt();</span><br><span class="line">        <span class="hljs-keyword">int</span> E = in.nextInt();</span><br><span class="line">        Graph g = <span class="hljs-keyword">new</span> Graph(V);</span><br><span class="line">        <span class="hljs-keyword">while</span> (E &gt; <span class="hljs-number">0</span>) {</span><br><span class="line">            <span class="hljs-keyword">int</span> src = in.nextInt();</span><br><span class="line">            <span class="hljs-keyword">int</span> dest = in.nextInt();</span><br><span class="line">            <span class="hljs-keyword">int</span> dist = in.nextInt();</span><br><span class="line">            g.setDist(src, dest, dist);</span><br><span class="line">            E--;</span><br><span class="line">        }</span><br><span class="line">        System.out.println(<span class="hljs-keyword">new</span> TSP(g).solve());</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="aizu-python-3-递归dp版本">AIZU Python 3 递归DP版本</h3>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span></span><br><span class="line"></span><br><span class="line">INT_INF = -<span class="hljs-number">1</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Graph</span>:</span></span><br><span class="line">    v_num: <span class="hljs-built_in">int</span></span><br><span class="line">    edges: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, v_num: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">        self.v_num = v_num</span><br><span class="line">        self.edges = [[INT_INF <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(v_num)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(v_num)]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setDist</span>(<span class="hljs-params">self, src: <span class="hljs-built_in">int</span>, dest: <span class="hljs-built_in">int</span>, dist: <span class="hljs-built_in">int</span></span>):</span></span><br><span class="line">        self.edges[src][dest] = dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TSPSolver</span>:</span></span><br><span class="line">    g: Graph</span><br><span class="line">    dp: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, g: Graph</span>):</span></span><br><span class="line">        self.g = g</span><br><span class="line">        self.dp = [[<span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(g.v_num)] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span> &lt;&lt; g.v_num)]</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self._recurse(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_recurse</span>(<span class="hljs-params">self, v: <span class="hljs-built_in">int</span>, state: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    </span></span><br><span class="line"><span class="hljs-string">        :param v:</span></span><br><span class="line"><span class="hljs-string">        :param state:</span></span><br><span class="line"><span class="hljs-string">        :return: -1 means INF</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        dp = self.dp</span><br><span class="line">        edges = self.g.edges</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-keyword">if</span> dp[state][v] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</span><br><span class="line">            <span class="hljs-keyword">return</span> dp[state][v]</span><br><span class="line">    </span><br><span class="line">        <span class="hljs-keyword">if</span> (state == (<span class="hljs-number">1</span> &lt;&lt; self.g.v_num) - <span class="hljs-number">1</span>) <span class="hljs-keyword">and</span> (v == <span class="hljs-number">0</span>):</span><br><span class="line">            dp[state][v] = <span class="hljs-number">0</span></span><br><span class="line">            <span class="hljs-keyword">return</span> dp[state][v]</span><br><span class="line">    </span><br><span class="line">        ret: <span class="hljs-built_in">int</span> = INT_INF</span><br><span class="line">        <span class="hljs-keyword">for</span> u <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.g.v_num):</span><br><span class="line">            <span class="hljs-keyword">if</span> (state &amp; (<span class="hljs-number">1</span> &lt;&lt; u)) == <span class="hljs-number">0</span>:</span><br><span class="line">                s: <span class="hljs-built_in">int</span> = self._recurse(u, state | <span class="hljs-number">1</span> &lt;&lt; u)</span><br><span class="line">                <span class="hljs-keyword">if</span> s != INT_INF <span class="hljs-keyword">and</span> edges[v][u] != INT_INF:</span><br><span class="line">                    <span class="hljs-keyword">if</span> ret == INT_INF:</span><br><span class="line">                        ret = s + edges[v][u]</span><br><span class="line">                    <span class="hljs-keyword">else</span>:</span><br><span class="line">                        ret = <span class="hljs-built_in">min</span>(ret, s + edges[v][u])</span><br><span class="line">        dp[state][v] = ret</span><br><span class="line">        <span class="hljs-keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span></span><br><span class="line">    V, E = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())</span><br><span class="line">    g: Graph = Graph(V)</span><br><span class="line">    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(E):</span><br><span class="line">        src, dest, dist = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())</span><br><span class="line">        g.setDist(src, dest, dist)</span><br><span class="line"></span><br><span class="line">    tsp: TSPSolver = TSPSolver(g)</span><br><span class="line">    <span class="hljs-built_in">print</span>(tsp.solve())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/" itemprop="url">组合游戏系列5: 井字棋、五子棋AlphaGo Zero 算法实战</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-08-21T18:45:01.000Z" itemprop="datePublished">8月 22 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            23 分钟 读完 (约 3517 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>上一篇我们从原理层面解析了AlphaGo
Zero如何改进MCTS算法，通过不断自我对弈，最终实现从零棋力开始训练直至能够打败任何高手。在本篇中，我们在已有的N子棋OpenAI
Gym 环境中用Pytorch实现一个简化版的AlphaGo Zero算法。本篇所有代码在 <a target="_blank" rel="noopener" href="https://github.com/MyEncyclopedia/ConnectNGym">github
MyEncyclopedia/ConnectNGym</a> 中，其中部分参考了SongXiaoJun 的 <a target="_blank" rel="noopener" href="https://github.com/junxiaosong/AlphaZero_Gomoku">AlphaZero_Gomoku</a>。</p>
<ul>
<li><p><a href="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/zh/combinatorial-game-1-minimax.md">第一篇:
Leetcode中的Minimax 和 Alpha Beta剪枝</a></p></li>
<li><p><a href="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/zh/combinatorial-game-2-tictactoe.md">第二篇:
井字棋Leetcode系列题解和Minimax最佳策略实现</a></p></li>
<li><p><a href="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/zh/combinatorial-game-3-openai-gym-pygame.md">第三篇:
井字棋、五子棋的OpenAI Gym GUI环境</a></p></li>
<li><p><a href="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/zh/combinatorial-game-4-alphago-zero-theory/index.md">第四篇:
AlphaGo Zero 强化学习算法原理深度分析</a></p></li>
<li><p><strong><a href="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/zh/combinatorial-game-5-alphago-zero-connect-n/index.md">第五篇:
井字棋、五子棋AlphaGo Zero 算法实战</a></strong></p></li>
</ul>
<h2 id="alphago-zero-mcts-树节点">AlphaGo Zero MCTS 树节点</h2>
<p>上一篇中，我们知道AlphaGo Zero 的MCTS树搜索是基于传统MCTS 的UCT （UCB
for Tree）的改进版PUCT（Polynomial Upper Confidence
Trees）。局面节点的PUCT值由两部分组成，分别是代表Exploitation的action
value Q值，和代表Exploration的U值。 <span class="math display">\[
PUCT(s, a) =Q(s,a) + U(s,a)
\]</span> U值计算由这些参数决定：系数<span class="math inline">\(c_{puct}\)</span>，节点先验概率P(s, a)
，父节点访问次数，本节点的访问次数。具体公式如下 <span class="math display">\[
U(s, a)=c_{p u c t} \cdot P(s, a) \cdot \frac{\sqrt{\Sigma_{b} N(s,
b)}}{1+N(s, a)}
\]</span></p>
<p>因此在实现过程中，对于一个树节点来说，需要保存其Q值、节点访问次数
_visit_num和先验概率 _prior。其中，_prior在节点初始化后不变，Q值和
<em>visit_num随着游戏MCTS模拟进程而改变。此外，节点保存了</em>
parent和_children变量，用于维护父子关系。c_puct为class
variable，作为全局参数。 </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TreeNode</span>:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    MCTS Tree Node</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line"></span><br><span class="line">    c_puct: ClassVar[<span class="hljs-built_in">int</span>] = <span class="hljs-number">5</span>  <span class="hljs-comment"># class-wise global param c_puct, exploration weight factor.</span></span><br><span class="line"></span><br><span class="line">    _parent: TreeNode</span><br><span class="line">    _children: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, TreeNode]  <span class="hljs-comment"># map from action to TreeNode</span></span><br><span class="line">    _visit_num: <span class="hljs-built_in">int</span></span><br><span class="line">    _Q: <span class="hljs-built_in">float</span>   <span class="hljs-comment"># Q value of the node, which is the mean action value.</span></span><br><span class="line">    _prior: <span class="hljs-built_in">float</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<p>和上面的计算公式相对应，下列代码根据节点状态计算PUCT(s, a)。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TreeNode</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_puct</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Computes AlphaGo Zero PUCT (polynomial upper confidence trees) of the node.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :return: Node PUCT value.</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        U = (TreeNode.c_puct * self._prior * np.sqrt(self._parent._visit_num) / (<span class="hljs-number">1</span> + self._visit_num))</span><br><span class="line">        <span class="hljs-keyword">return</span> self._Q + U</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>AlphaGo Zero
MCTS在playout时遇到已经被展开的节点，会根据selection规则选择子节点，该规则本质上是在所有子节点中选择最大的PUCT值的节点。</p>
<p><span class="math display">\[
a=\operatorname{argmax}_a(PUCT(s, a))=\operatorname{argmax}_a(Q(s,a) +
U(s,a))
\]</span></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TreeNode</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">select</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">Tuple</span>[Pos, TreeNode]:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Selects an action(Pos) having max UCB value.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :return: Action and corresponding node</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(self._children.items(), key=<span class="hljs-keyword">lambda</span> act_node: act_node[<span class="hljs-number">1</span>].get_puct())</span><br></pre></td></tr></tbody></table></figure>
<p>新的叶节点一旦在playout时产生，关联的 v
值会一路向上更新至根节点，具体新节点的v值将在下一节中解释。
</p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TreeNode</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">propagate_to_root</span>(<span class="hljs-params">self, leaf_value: <span class="hljs-built_in">float</span></span>):</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Updates current node with observed leaf_value and propagates to root node.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :param leaf_value:</span></span><br><span class="line"><span class="hljs-string">        :return:</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        <span class="hljs-keyword">if</span> self._parent:</span><br><span class="line">            self._parent.propagate_to_root(-leaf_value)</span><br><span class="line">        self._update(leaf_value)</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_update</span>(<span class="hljs-params">self, leaf_value: <span class="hljs-built_in">float</span></span>):</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Updates the node by newly observed leaf_value.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :param leaf_value:</span></span><br><span class="line"><span class="hljs-string">        :return:</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        self._visit_num += <span class="hljs-number">1</span></span><br><span class="line">        <span class="hljs-comment"># new Q is updated towards deviation from existing Q</span></span><br><span class="line">        self._Q += <span class="hljs-number">0.5</span> * (leaf_value - self._Q)</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="alphago-zero-mcts-player-实现">AlphaGo Zero MCTS Player
实现</h2>
<p>AlphaGo Zero MCTS
在训练阶段分为如下几个步骤。游戏初始局面下，整个局面树的建立由子节点的不断被探索而丰富起来。AlphaGo
Zero对弈一次即产生了一次完整的游戏开始到结束的动作系列。在对弈过程中的某一游戏局面，需要采样海量的playout，又称MCTS模拟，以此来决定此局面的下一步动作。一次playout可视为在真实游戏状态树的一种特定采样，playout可能会产生游戏结局，生成真实的v值；也可能explore
到新的叶子节点，此时v值依赖策略价值网络的输出，目的是利用训练的神经网络来产生高质量的游戏对战局面。每次playout会从当前给定局面递归向下，向下的过程中会遇到下面三种节点情况。</p>
<ul>
<li>若局面节点是游戏结局（叶子节点），可以得到游戏的真实价值
z。从底部节点带着z向上更新沿途节点的Q值，直至根节点（初始局面）。</li>
<li>若局面节点从未被扩展过（叶子节点），此时会将局面编码输入到策略价值双头网络，输出结果为网络预估的action分布和v值。Action分布作为节点先验概率P(s,
a)来初始化子节点，预估的v值和上面真实游戏价值z一样，从叶子节点向上沿途更新到根节点。</li>
<li>若局面节点已经被扩展过，则根据PUCT的select规则继续选择下一节点。</li>
</ul>
<p>海量的playout模拟后，建立了游戏状态树的节点信息。但至此，AI玩家只是收集了信息，还仍未给定局面落子，而落子的决定由Play规则产生。下图展示了给定局面（Current节点）下，MCST模拟进行的多次playout探索后生成的局面树，play规则根据这些节点信息，产生Current
节点的动作分布 <span class="math inline">\(\pi\)</span>
，确定下一步落子。</p>
<figure>
<img src="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/mcts_game_tree.png">
<figcaption>
MCTS Playout和Play关系
</figcaption>
</figure>
<h3 id="play-给定局面">Play 给定局面</h3>
<p>对于当前需要做落子决定的某游戏局面<span class="math inline">\(s_0\)</span>，根据如下play公式生成落子分布 $$
，子局面的落子概率正比于其访问次数的某次方。其中，某次方的倒数称为温度参数（Temperature）。</p>
<p><span class="math display">\[
\pi\left(a \mid s_{0}\right)=\frac{N\left(s_{0}, a\right)^{1 /
\tau}}{\sum_{b} N\left(s_{0}, b\right)^{1 / \tau}}
\]</span></p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MCTSAlphaGoZeroPlayer</span>(<span class="hljs-params">BaseAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_next_step_play_act_probs</span>(<span class="hljs-params">self, game: ConnectNGame</span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-type">List</span>[Pos], ActionProbs]:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        For the given game status, run playouts number of times specified by self._playout_num.</span></span><br><span class="line"><span class="hljs-string">        Returns the action distribution according to AlphaGo Zero MCTS play formula.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :param game:</span></span><br><span class="line"><span class="hljs-string">        :return: actions and their probability</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self._playout_num):</span><br><span class="line">            self._playout(copy.deepcopy(game))</span><br><span class="line"></span><br><span class="line">        act_visits = [(act, node._visit_num) <span class="hljs-keyword">for</span> act, node <span class="hljs-keyword">in</span> self._current_root._children.items()]</span><br><span class="line">        acts, visits = <span class="hljs-built_in">zip</span>(*act_visits)</span><br><span class="line">        act_probs = softmax(<span class="hljs-number">1.0</span> / MCTSAlphaGoZeroPlayer.temperature * np.log(np.array(visits) + <span class="hljs-number">1e-10</span>))</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> acts, act_probs</span><br></pre></td></tr></tbody></table></figure>
<p>在训练模式时，考虑到偏向exploration的目的，在<span class="math inline">\(\pi\)</span> 落子分布的基础上增加了 Dirichlet
分布。</p>
<p><span class="math display">\[
P(s,a) = (1-\epsilon)*\pi(a \mid s) + \epsilon * \boldsymbol{\eta} \quad
(\boldsymbol{\eta} \sim \operatorname{Dir}(0.3))
\]</span> </p><figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MCTSAlphaGoZeroPlayer</span>(<span class="hljs-params">BaseAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_action</span>(<span class="hljs-params">self, board: PyGameBoard</span>) -&gt; Pos:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        Method defined in BaseAgent.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :param board:</span></span><br><span class="line"><span class="hljs-string">        :return: next move for the given game board.</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        <span class="hljs-keyword">return</span> self._get_action(copy.deepcopy(board.connect_n_game))[<span class="hljs-number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_action</span>(<span class="hljs-params">self, game: ConnectNGame</span>) -&gt; <span class="hljs-type">Tuple</span>[MoveWithProb]:</span></span><br><span class="line">        epsilon = <span class="hljs-number">0.25</span></span><br><span class="line">        avail_pos = game.get_avail_pos()</span><br><span class="line">        move_probs: ActionProbs = np.zeros(game.board_size * game.board_size)</span><br><span class="line">        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(avail_pos) &gt; <span class="hljs-number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># the pi defined in AlphaGo Zero paper</span></span><br><span class="line">        acts, act_probs = self._next_step_play_act_probs(game)</span><br><span class="line">        move_probs[<span class="hljs-built_in">list</span>(acts)] = act_probs</span><br><span class="line">        <span class="hljs-keyword">if</span> self._is_training:</span><br><span class="line">            <span class="hljs-comment"># add Dirichlet Noise when training in favour of exploration</span></span><br><span class="line">            p_ = (<span class="hljs-number">1</span>-epsilon) * act_probs + epsilon * np.random.dirichlet(<span class="hljs-number">0.3</span> * np.ones(<span class="hljs-built_in">len</span>(act_probs)))</span><br><span class="line">            move = np.random.choice(acts, p=p_)</span><br><span class="line">            <span class="hljs-keyword">assert</span> move <span class="hljs-keyword">in</span> game.get_avail_pos()</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            move = np.random.choice(acts, p=act_probs)</span><br><span class="line"></span><br><span class="line">        self.reset()</span><br><span class="line">        <span class="hljs-keyword">return</span> move, move_probs</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="一次完整的对弈">一次完整的对弈</h3>
<p>一次完整的AI对弈就是从初始局面迭代play直至游戏结束，对弈生成的数据是一系列的
$(s, , z) $。</p>
<p>如下图 s0 到 s5
是某次井字棋的对弈。最终结局是先手黑棋玩家赢，即对于黑棋玩家 z =
+1。需要注意的是：z = +1 是对于所有黑棋面临的局面，即s0, s2,
s4，而对应的其余白棋玩家来说 z = -1。</p>
<figure>
<img src="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/self_play.png">
<figcaption>
一局完整对弈
</figcaption>
</figure>
<div>
<p><span class="math display">\[
\begin{align*}
&amp;0: (s_0,  \vec{\pi_0}, +1)  \\
&amp;1: (s_1,  \vec{\pi_1}, -1) \\
&amp;2: (s_2,  \vec{\pi_2}, +1) \\
&amp;3: (s_3,  \vec{\pi_3}, -1) \\
&amp;4: (s_4,  \vec{\pi_4}, +1)
\end{align*}
\]</span></p>
</div>
<p>以下代码展示如何在AI对弈时收集数据 $(s, , z) $</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MCTSAlphaGoZeroPlayer</span>(<span class="hljs-params">BaseAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">self_play_one_game</span>(<span class="hljs-params">self, game: ConnectNGame</span>) \</span></span><br><span class="line"><span class="hljs-function">            -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[NetGameState, ActionProbs, NDArray[(<span class="hljs-type">Any</span>), np.<span class="hljs-built_in">float</span>]]]:</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :param game:</span></span><br><span class="line"><span class="hljs-string">        :return:</span></span><br><span class="line"><span class="hljs-string">            Sequence of (s, pi, z) of a complete game play. The number of list is the game play length.</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line"></span><br><span class="line">        states: <span class="hljs-type">List</span>[NetGameState] = []</span><br><span class="line">        probs: <span class="hljs-type">List</span>[ActionProbs] = []</span><br><span class="line">        current_players: <span class="hljs-type">List</span>[np.<span class="hljs-built_in">float</span>] = []</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> game.game_over:</span><br><span class="line">            move, move_probs = self._get_action(game)</span><br><span class="line">            states.append(convert_game_state(game))</span><br><span class="line">            probs.append(move_probs)</span><br><span class="line">            current_players.append(game.current_player)</span><br><span class="line">            game.move(move)</span><br><span class="line"></span><br><span class="line">        current_player_z = np.zeros(<span class="hljs-built_in">len</span>(current_players))</span><br><span class="line">        current_player_z[np.array(current_players) == game.game_result] = <span class="hljs-number">1.0</span></span><br><span class="line">        current_player_z[np.array(current_players) == -game.game_result] = -<span class="hljs-number">1.0</span></span><br><span class="line">        self.reset()</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(states, probs, current_player_z))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="playout-代码实现">Playout 代码实现</h3>
<p>一次playout会从当前局面根据PUCT
selection规则下沉到叶子节点，如果此叶子节点非游戏终结点，则会扩展当前节点生成下一层新节点，其先验分布由策略价值网络输出的action分布决定。一次playout最终会得到叶子节点的
v 值，并沿着MCTS树向上更新沿途的所有父节点 Q值。
从上一篇文章已知，游戏节点的数量随着参数而指数级增长，举例来说，井字棋（k=3，m=n=3）的状态数量是5478，k=3，m=n=4时是6035992
，k=m=n=4时是9722011
。如果我们将初始局面节点作为根节点，同时保存海量playout探索得到的局面节点，实现时会发现我们无法将所有探索到的局面节点都保存在内存中。这里的一种解决方法是在一次self
play中每轮playout之后，将根节点重置成落子的节点，从而有效控制整颗局面树中的节点数量。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MCTSAlphaGoZeroPlayer</span>(<span class="hljs-params">BaseAgent</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_playout</span>(<span class="hljs-params">self, game: ConnectNGame</span>):</span></span><br><span class="line">        <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">        From current game status, run a sequence down to a leaf node, either because game ends or unexplored node.</span></span><br><span class="line"><span class="hljs-string">        Get the leaf value of the leaf node, either the actual reward of game or action value returned by policy net.</span></span><br><span class="line"><span class="hljs-string">        And propagate upwards to root node.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">        :param game:</span></span><br><span class="line"><span class="hljs-string">        """</span></span><br><span class="line">        player_id = game.current_player</span><br><span class="line"></span><br><span class="line">        node = self._current_root</span><br><span class="line">        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:</span><br><span class="line">            <span class="hljs-keyword">if</span> node.is_leaf():</span><br><span class="line">                <span class="hljs-keyword">break</span></span><br><span class="line">            act, node = node.select()</span><br><span class="line">            game.move(act)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># now game state is a leaf node in the tree, either a terminal node or an unexplored node</span></span><br><span class="line">        act_and_probs: Iterator[MoveWithProb]</span><br><span class="line">        act_and_probs, leaf_value = self._policy_value_net.policy_value_fn(game)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> game.game_over:</span><br><span class="line">            <span class="hljs-comment"># case where encountering an unexplored leaf node, update leaf_value estimated by policy net to root</span></span><br><span class="line">            <span class="hljs-keyword">for</span> act, prob <span class="hljs-keyword">in</span> act_and_probs:</span><br><span class="line">                game.move(act)</span><br><span class="line">                child_node = node.expand(act, prob)</span><br><span class="line">                game.undo()</span><br><span class="line">        <span class="hljs-keyword">else</span>:</span><br><span class="line">            <span class="hljs-comment"># case where game ends, update actual leaf_value to root</span></span><br><span class="line">            <span class="hljs-keyword">if</span> game.game_result == ConnectNGame.RESULT_TIE:</span><br><span class="line">                leaf_value = ConnectNGame.RESULT_TIE</span><br><span class="line">            <span class="hljs-keyword">else</span>:</span><br><span class="line">                leaf_value = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> game.game_result == player_id <span class="hljs-keyword">else</span> -<span class="hljs-number">1</span></span><br><span class="line">            leaf_value = <span class="hljs-built_in">float</span>(leaf_value)</span><br><span class="line"></span><br><span class="line">        <span class="hljs-comment"># Update leaf_value and propagate up to root node</span></span><br><span class="line">        node.propagate_to_root(-leaf_value)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="编码游戏局面">编码游戏局面</h2>
<p>为了将信息有效的传递给策略神经网络，必须从当前玩家的角度编码游戏局面。局面不仅要反映棋盘上黑白棋子的位置，也需要考虑最后一个落子的位置以及是否为当前玩家棋局。因此，我们将某局面按照当前玩家来编码，返回类型为4个棋盘大小组成的ndarray，即shape
[4, board_size, board_size]，其中</p>
<ol type="1">
<li>第一个数组编码当前玩家的棋子位置</li>
<li>第二个数组编码对手玩家棋子位置</li>
<li>第三个表示最后落子位置</li>
<li>第四个全1表示此局面为先手（黑棋）局面，全0表示白棋局面</li>
</ol>
<p>例如之前游戏对弈中的前四步：</p>
<figure>
<img src="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/self_play_first_3.jpg">
<figcaption>
</figcaption>
</figure>
<p>s1-&gt;s2 后局面s2的编码：当前玩家为黑棋玩家，编码局面s2
返回如下ndarray，数组[0]
为s2黑子位置，[1]为白子位置，[2]表示最后一个落子(1, 1) ，[3]
全1表示当前是黑棋落子的局面。</p>
<figure>
<img src="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/s2_state.jpg">
<figcaption>
编码黑棋玩家局面 s2
</figcaption>
</figure>
s2-&gt;s3 后局面s3的编码：当前玩家为白棋玩家，编码返回如下，数组[0]
为s3白子位置，[1]为黑子位置，[2]表示最后一个落子(1, 0) ，[3]
全0表示当前是白棋落子的局面。
<figure>
<img src="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/s3_state.jpg">
<figcaption>
编码白棋玩家局面 s3
</figcaption>
</figure>
<p>具体代码实现如下。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">NetGameState = NDArray[(<span class="hljs-number">4</span>, <span class="hljs-type">Any</span>, <span class="hljs-type">Any</span>), np.<span class="hljs-built_in">int</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">convert_game_state</span>(<span class="hljs-params">game: ConnectNGame</span>) -&gt; NetGameState:</span></span><br><span class="line">    <span class="hljs-string">"""</span></span><br><span class="line"><span class="hljs-string">    Converts game state to type NetGameState as ndarray.</span></span><br><span class="line"><span class="hljs-string"></span></span><br><span class="line"><span class="hljs-string">    :param game:</span></span><br><span class="line"><span class="hljs-string">    :return:</span></span><br><span class="line"><span class="hljs-string">        Of shape 4 * board_size * board_size.</span></span><br><span class="line"><span class="hljs-string">        [0] is current player positions.</span></span><br><span class="line"><span class="hljs-string">        [1] is opponent positions.</span></span><br><span class="line"><span class="hljs-string">        [2] is last move location.</span></span><br><span class="line"><span class="hljs-string">        [3] all 1 meaning move by black player, all 0 meaning move by white.</span></span><br><span class="line"><span class="hljs-string">    """</span></span><br><span class="line">    state_matrix = np.zeros((<span class="hljs-number">4</span>, game.board_size, game.board_size))</span><br><span class="line"></span><br><span class="line">    <span class="hljs-keyword">if</span> game.action_stack:</span><br><span class="line">        actions = np.array(game.action_stack)</span><br><span class="line">        move_curr = actions[::<span class="hljs-number">2</span>]</span><br><span class="line">        move_oppo = actions[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>]</span><br><span class="line">        <span class="hljs-keyword">for</span> move <span class="hljs-keyword">in</span> move_curr:</span><br><span class="line">            state_matrix[<span class="hljs-number">0</span>][move] = <span class="hljs-number">1.0</span></span><br><span class="line">        <span class="hljs-keyword">for</span> move <span class="hljs-keyword">in</span> move_oppo:</span><br><span class="line">            state_matrix[<span class="hljs-number">1</span>][move] = <span class="hljs-number">1.0</span></span><br><span class="line">        <span class="hljs-comment"># indicate the last move location</span></span><br><span class="line">        state_matrix[<span class="hljs-number">2</span>][actions[-<span class="hljs-number">1</span>]] = <span class="hljs-number">1.0</span></span><br><span class="line">    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(game.action_stack) % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:</span><br><span class="line">        state_matrix[<span class="hljs-number">3</span>][:, :] = <span class="hljs-number">1.0</span>  <span class="hljs-comment"># indicate the colour to play</span></span><br><span class="line">    <span class="hljs-keyword">return</span> state_matrix[:, ::-<span class="hljs-number">1</span>, :]</span><br></pre></td></tr></tbody></table></figure>
<h2 id="策略价值网络训练">策略价值网络训练</h2>
<p>策略价值网络是一个共享参数 <span class="math inline">\(\theta\)</span>
的双头网络，给定上面的游戏局面编码会产生预估的p和v。</p>
<figure>
<img src="/zh/2020/combinatorial-game-5-alphago-zero-connect-n/policy_value_net.png">
</figure>
<p><span class="math display">\[
\vec{p_{\theta}}, v_{\theta}=f_{\theta}(s)
\]</span> 结合真实游戏对弈后产生三元组数据 $(s, , z) $
，按照论文中的loss 来训练神经网络。 <span class="math display">\[
l=\sum_{t}\left(v_{\theta}\left(s_{t}\right)-z_{t}\right)^{2}-\vec{\pi_{t}}
\cdot \log \left(\vec{p_{\theta}}\left(s_{t}\right)\right) + c {\lVert
\theta \rVert}^2
\]</span></p>
<p>下面代码为Pytorch backward部分。</p>
<figure class="highlight python hljs"><figcaption><span>{linenos</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward_step</span>(<span class="hljs-params">self, state_batch: <span class="hljs-type">List</span>[NetGameState], probs_batch: <span class="hljs-type">List</span>[ActionProbs],</span></span></span><br><span class="line"><span class="hljs-params"><span class="hljs-function">               value_batch: <span class="hljs-type">List</span>[NDArray[(<span class="hljs-params"><span class="hljs-type">Any</span></span>), np.<span class="hljs-built_in">float</span>]], lr</span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">float</span>, <span class="hljs-built_in">float</span>]:</span></span><br><span class="line">    <span class="hljs-keyword">if</span> self.use_gpu:</span><br><span class="line">        state_batch = Variable(torch.FloatTensor(state_batch).cuda())</span><br><span class="line">        probs_batch = Variable(torch.FloatTensor(probs_batch).cuda())</span><br><span class="line">        value_batch = Variable(torch.FloatTensor(value_batch).cuda())</span><br><span class="line">    <span class="hljs-keyword">else</span>:</span><br><span class="line">        state_batch = Variable(torch.FloatTensor(state_batch))</span><br><span class="line">        probs_batch = Variable(torch.FloatTensor(probs_batch))</span><br><span class="line">        value_batch = Variable(torch.FloatTensor(value_batch))</span><br><span class="line"></span><br><span class="line">    self.optimizer.zero_grad()</span><br><span class="line">    <span class="hljs-keyword">for</span> param_group <span class="hljs-keyword">in</span> self.optimizer.param_groups:</span><br><span class="line">        param_group[<span class="hljs-string">'lr'</span>] = lr</span><br><span class="line"></span><br><span class="line">    log_act_probs, value = self.policy_value_net(state_batch)</span><br><span class="line">    <span class="hljs-comment"># loss = (z - v)^2 - pi*T * log(p) + c||theta||^2</span></span><br><span class="line">    value_loss = F.mse_loss(value.view(-<span class="hljs-number">1</span>), value_batch)</span><br><span class="line">    policy_loss = -torch.mean(torch.<span class="hljs-built_in">sum</span>(probs_batch * log_act_probs, <span class="hljs-number">1</span>))</span><br><span class="line">    loss = value_loss + policy_loss</span><br><span class="line">    loss.backward()</span><br><span class="line">    self.optimizer.step()</span><br><span class="line">    entropy = -torch.mean(torch.<span class="hljs-built_in">sum</span>(torch.exp(log_act_probs) * log_act_probs, <span class="hljs-number">1</span>))</span><br><span class="line">    <span class="hljs-keyword">return</span> loss.item(), entropy.item()</span><br></pre></td></tr></tbody></table></figure>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Wujy7OzvdJk&amp;t=358s">Youtube,
Deepmind AlphaZero - Mastering Games Without Human Knowledge, David
Silver</a></p></li>
<li><p>Mastering the game of Go with deep neural networks and tree
search</p></li>
<li><p>Mastering Chess and Shogi by Self-Play with a General
Reinforcement Learning Algorithm</p></li>
<li><p><a target="_blank" rel="noopener" href="http://xtf615.com/2018/02/12/AlphaGo-Zero/">AlphaGo
Zero论文解析</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32089487">AlphaZero实战：从零学下五子棋（附代码）</a></p></li>
</ul>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2020/combinatorial-game-4-alphago-zero-theory/" itemprop="url">组合游戏系列4: AlphaGo Zero 强化学习算法原理深度分析</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2020-08-07T18:45:01.000Z" itemprop="datePublished">8月 8 2020</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            24 分钟 读完 (约 3527 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>AlphaGo Zero是Deepmind
最后一代AI围棋算法，因为已经达到了棋类游戏AI的终极目的：给定任何游戏规则，AI从零出发只通过自我对弈的方式提高，最终可以取得超越任何对手（包括顶级人类棋手和上一代AlphaGo）的能力。换种方式说，当给定足够多的时间和计算资源，可以取得无限逼近游戏真实解的能力。这一篇，我们深入分析AlphaGo
Zero的设计理念和关键组件的细节并解释组件之间的关联。下一篇中，我们将在已有的N子棋OpenAI
Gym 环境中用Pytorch实现一个简化版的AlphaGo Zero算法。</p>
<ul>
<li><p><a href="/zh/2020/combinatorial-game-4-alphago-zero-theory/zh/combinatorial-game-1-minimax.md">第一篇:
Leetcode中的Minimax 和 Alpha Beta剪枝</a></p></li>
<li><p><a href="/zh/2020/combinatorial-game-4-alphago-zero-theory/zh/combinatorial-game-2-tictactoe.md">第二篇:
井字棋Leetcode系列题解和Minimax最佳策略实现</a></p></li>
<li><p><a href="/zh/2020/combinatorial-game-4-alphago-zero-theory/zh/combinatorial-game-3-openai-gym-pygame.md">第三篇:
井字棋、五子棋的OpenAI Gym GUI环境</a></p></li>
<li><p><strong><a href="/zh/2020/combinatorial-game-4-alphago-zero-theory/zh/combinatorial-game-4-alphago-zero-theory/index.md">第四篇:
AlphaGo Zero 强化学习算法原理深度分析</a></strong></p></li>
<li><p><a href="/zh/2020/combinatorial-game-4-alphago-zero-theory/zh/combinatorial-game-5-alphago-zero-connect-n/index.md">第五篇:
井字棋、五子棋AlphaGo Zero 算法实战</a></p></li>
</ul>
<h2 id="alphago-zero-综述">AlphaGo Zero 综述</h2>
<p>AlphaGo Zero 作为Deepmind在围棋领域的最后一代AI
Agent，已经可以达到棋类游戏的终极目标：在只给定游戏规则的情况下，AI
棋手从最初始的随机状态开始，通过不断的自我对弈的强化学习来实现超越以往任何人类棋手和上一代Alpha的能力，并且同样的算法和模型应用到了其他棋类也得出相同的效果。这一篇，从原理上来解析AlphaGo
Zero的运行方式。</p>
<p>AlphaGo Zero
算法由三种元素构成：强化学习（RL）、深度学习（DL）和蒙特卡洛树搜索（MCTS，Monte
Carlo Tree Search）。核心思想是基于神经网络的Policy
Iteration强化学习，即最终学的是一个深度学习的policy
network，输入是某棋盘局面 s，输出是此局面下可走位的概率分布：<span class="math inline">\(p(a|s)\)</span>。</p>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/policy_net.png">
</figure>
<p>在第一代AlphaGo算法中，这个初始policy
network通过收集专业人类棋手的海量棋局训练得来，再采用传统RL 的Monte
Carlo Tree Search Rollout 技术来强化现有的AI对于局面落子（Policy
Network）的判断。Monte Carlo Tree Search Rollout
简单说来就是海量棋局模拟，AI Agent在通过现有的Policy
Network策略完成一次从某局面节点到最终游戏胜负结束的对弈，这个完整的对弈叫做rollout，又称playout。完成一次rollout之后，通过局面树层层回溯到初始局面节点，并在回溯过程中同步修订所有经过的局面节点的统计指标，修正原先policy
network对于落子导致输赢的判断。通过海量并发的棋局模拟来提升基准policy
network，即在各种局面下提高好的落子的<span class="math inline">\(p(a_{win}|s)\)</span>，降低坏的落子的<span class="math inline">\(p(a_{lose}|s)\)</span></p>
举例如下井字棋局面：
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/pos.png">
<figcaption>
局面s
</figcaption>
</figure>
<p>基准policy network返回 p(s) 如下 <span class="math display">\[
p(a|s) =  
\begin{align*}
  \left\lbrace
  \begin{array}{r@{}l}
    0.1, &amp; &amp; a = (0,2) \\
    0.05, &amp; &amp; a = (1,0) \\
     0.5, &amp; &amp; a = (1,1) \\
     0.05, &amp; &amp; a = (1,2)\\
     0.2, &amp; &amp; a = (2,0) \\
    0.05, &amp; &amp; a = (2,1) \\
    0.05, &amp; &amp; a = (2,2)
  \end{array}
  \right.
\end{align*}
\]</span> 通过海量并发模拟后，修订成如下的action概率分布，然后通过policy
iteration迭代新的网络来逼近 <span class="math inline">\(p'\)</span>
就提高了棋力。 <span class="math display">\[
p'(a|s) =  
\begin{align*}
  \left\lbrace
  \begin{array}{r@{}l}
   0, &amp; &amp; a = (0,2) \\
    0, &amp; &amp; a = (1,0) \\
     0.9, &amp; &amp; a = (1,1) \\
     0, &amp; &amp; a = (1,2)\\
     0, &amp; &amp; a = (2,0) \\
    0, &amp; &amp; a = (2,1) \\
    0.1, &amp; &amp; a = (2,2)
  \end{array}
  \right.
\end{align*}
\]</span></p>
<h2 id="蒙特卡洛树搜索mcts概述">蒙特卡洛树搜索（MCTS）概述</h2>
<p>Monte Carlo Tree Search 是Monte Carlo
在棋类游戏中的变种，棋类游戏的一大特点是可以用动作(move)联系的决策树来表示，树的节点数量取决于分支的数量和树的深度。MCTS的目的是在树节点非常多的情况下，通过实验模拟（rollout,
playout）的方式来收集尽可能多的局面输赢情况，并基于这些统计信息，将搜索资源的重点均衡地放在未被探索的节点和值得探索的节点上，减少在大概率输的节点上的模拟资源投入。传统MCTS有四个过程：Selection,
Expansion, Simulation 和Backpropagation。下图是<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search">Wikipedia</a>
的例子：</p>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/MCTS_selection.png">
</figure>
<ul>
<li>Selection：从根节点出发，根据现有统计的信息和selection规则，选择子节点递归向下做决定，后面我们会详细介绍AlphaGo的UCB规则。图中节点的数字，例如根节点11/21，分别代表赢的次数和总模拟次数。从根节点一路向下分别选择节点
7/10, 1/6直到叶子节点3/3，叶子节点表示它未被探索过。</li>
</ul>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/MCTS_expansion.png">
</figure>
<ul>
<li>Expansion：由于3/3节点未被探索过，初始化其所有子节点为0/0，图中3/3只有一个子节点。后面我们会看到神经网络在初始化子节点的时候起到的指导作用，即所有子节点初始权重并非相同，而是由神经网络给出估计。</li>
</ul>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/MCTS_simulation.png">
</figure>
<ul>
<li>Simulation：重复selection和expansion，根据游戏规则递归向下直至游戏结束。</li>
</ul>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/MCTS_backprop.png">
</figure>
<ul>
<li>Backpropagation：游戏结束在终点节点产生游戏真实的价值，回溯向上调整所有父节点的统计状态。</li>
</ul>
<h3 id="权衡-exploration-和-exploitation">权衡 Exploration 和
Exploitation</h3>
<p>在不断扩张决策树并收集节点统计信息的同时，MCTS根据规则来权衡探索目的（采样不足）或利用目的来做决策，这个权衡规则叫做Upper
Confidence
Bound（UCB）。典型的UCB公式如下：w表示通过节点的赢的次数，n表示通过节点的总次数，N是父节点的访问次数，c是调节Exploration
和 Exploitation权重的超参。</p>
<p><span class="math display">\[
{\frac{w_i}{n_i}} + c \sqrt{\frac{\ln N_i}{n_i}}
\]</span></p>
<p>假设某节点有两个子节点s1, s2，它们的统计指标为 s1: w/n = 3/4，s2: w/n
=
6/8，由于两者输赢比率一样，因此根据公式，访问次数少的节点出于Exploration的目的胜出，MCTS最终决定从s局面走向s1。</p>
<h2 id="从第一性原理来理解alphago-zero">从第一性原理来理解AlphaGo
Zero</h2>
<p>前一代的AlphaGo已经战胜了世界冠军，取得了空前的成就，AlphaGo Zero
的设计目标变得更加General，去除围棋相关的处理和知识，用统一的框架和算法来解决棋类问题。
1. 无人工先验数据</p>
<p>改进之前需要专家棋手对弈数据来冷启动初始棋力</p>
<ol start="2" type="1">
<li><p>无特定游戏特征工程</p>
<p>无需围棋特定技巧，只包含下棋规则，可以适用到所有棋类游戏</p></li>
<li><p>单一神经网络</p>
<p>统一Policy Network和Value
Network，使用一个共享参数的双头神经网络</p></li>
<li><p>简单树搜索</p>
<p>去除传统MCTS的Rollout
方式，用神经网络来指导MCTS更有效产生搜索策略</p></li>
</ol>
<h3 id="搜索空间的两个优化原则">搜索空间的两个优化原则</h3>
尽管理论上围棋是有解的，即先手必赢、被逼平或必输，通过遍历所有可能局面可以求得解。同理，通过海量模拟所有可能游戏局面，也可以无限逼近所有局面下的真实输赢概率，直至收敛于局面落子的确切最佳结果。但由于围棋棋局的数目远远大于宇宙原子数目，3^361
&gt;&gt;
10^80，因此需要将计算资源有效的去模拟值得探索的局面，例如对于显然的被动局面减小模拟次数，所以如何有效地减小搜索空间是AlphaGo
Zero 需要解决的重大问题。David Silver 在<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Wujy7OzvdJk&amp;t=358s">Deepmind
AlphaZero - Mastering Games Without Human Knowledge</a>中提到AlphaGo
Zero 采用两个原则来有效减小搜索空间。
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/exhaustive_search.png">
</figure>
<h4 id="原则1-通过value-network减少搜索的深度">原则1: 通过Value
Network减少搜索的深度</h4>
Value Network
通过预测给定局面的value来直接预测最终结果，思想和上一期Minimax DP
策略中直接缓存当前局面的胜负状态一样，减少每次必须靠模拟到最后才能知道当前局面的输赢概率，或者需要多层树搜索才能知道输赢概率。
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/value_net.png">
</figure>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/reduce_depth.png">
</figure>
<h4 id="原则2-通过policy-network减少搜索的宽度">原则2: 通过Policy
Network减少搜索的宽度</h4>
搜索广度的减少是由Policy
Network预估来达成的，将下一步搜索局限在高概率的动作上，大幅度提升原先MCTS新节点生成后冷启动的搜索宽度。
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/reduce_breadth.png">
</figure>
<h3 id="神经网络结构">神经网络结构</h3>
<p>AlphaGo Zero 使用一个单一的深度神经网络来完成policy
和value的预测。具体实现方式是将policy network和value
network合并成一个共享参数 $ $
的双头网络。其中z是真实游戏结局的效用，范围为[-1, 1] 。</p>
<p><span class="math display">\[
(p, v)=f_{\theta}(s)
\]</span> <span class="math display">\[
p_{a}=\operatorname{Pr}(a \mid s)
\]</span> <span class="math display">\[
v =  \mathop{\mathbb{E}}[z|s]
\]</span></p>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/policy_value_net.png">
</figure>
<p>Monte Carlo Tree Search (MCTS)
建立了棋局搜索树，节点的初始状态由神经网络输出的p和v值来估计，由此初始的动作策略和价值预判就会建立在高手的水平之上。模拟一局游戏之后向上回溯，会同步更新路径上节点的统计数值并生成更好的MCTS搜索策略
<span class="math inline">\(\vec{\pi}\)</span>。进一步来看，MCTS和神经网络互相形成了正循环。神经网络指导了未知节点的MCTS初始搜索策略，产生自我对弈游戏结局后，通过减小
<span class="math inline">\(\vec{p}\)</span> 和<span class="math inline">\(\vec{\pi}\)</span>的 Loss
，最终又提高了神经网络对于局面的估计能力。神经网络value
network的提升也是通过不断减小网络预测的结果和最终结果的差异来提升。
因此，具体神经网络的Loss函数由三部分组成，value network的损失，policy
network的损失以及正则项。 <span class="math display">\[
l=\sum_{t}\left(v_{\theta}\left(s_{t}\right)-z_{t}\right)^{2}-\vec{\pi}_{t}
\cdot \log \left(\vec{p}_{\theta}\left(s_{t}\right)\right) + c {\lVert
\theta \rVert}^2
\]</span></p>
<h3 id="alphago-zero-mcts-具体过程">AlphaGo Zero MCTS 具体过程</h3>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/self-play.png">
<figcaption>
AlphaGo Plays Games Against Itself
</figcaption>
</figure>
<p>AlphaGo Zero的MCTS和传统MCTS都有相似的四个过程，但AlphaGo
Zero的MCTS步骤相对更复杂。 首先，除了W/N统计指标之外，AlphaGo
Zero的MCTS保存了决策边 a|s 的Q(s,a)：Action
Value，也就是Q-Learning中的Q值，其初始值由神经网络给出。此外，Q
值也用于串联自底向上更新节点的Value值。具体说来，当某个新节点被Explore后，会将网络给出的Q值向上传递，并逐层更新父节点的Q值。当游戏结局产生时，也会向上更新所有父节点的Q值。
此外对于某一游戏局面s进行多次模拟，每次在局面s出发向下探索，每次探索在已知节点按Selection规则深入一步，直至达到未探索的局面或者游戏结束，产生Q值后向上回溯到最初局面s，回溯过程中更新路径上的局面的统计值或者Q值。在多次模拟结束后根据Play的算法，决定局面s的下一步行动。尽管每次模拟探索可能会深入多层，但最终play阶段的算法规则仅决定给定局面s的下一层落子动作。多次向下探索的优势在于：</p>
<ol type="1">
<li><p>探索和采样更多的叶子节点，在更多信息下做决策。</p></li>
<li><p>通过average
out多次模拟下一层落子决定，尽可能提升MCTS策略的下一步判断能力，提高
<span class="math inline">\(\pi\)</span>
能力，更有效指导神经网络，提高其学习效率。</p></li>
</ol>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/MCTS_alphago.png">
<figcaption>
New Policy Network V' is Trained to Predict Winner
</figcaption>
</figure>
<ol type="1">
<li>Selection:</li>
</ol>
<p>从游戏局面s开始，选择a向下递归，直至未展开的节点（搜索树中的叶子节点）或者游戏结局。具体在局面s下选择a的规则由以下UCB(Upper
Confidence Bound)决定<br>
<span class="math display">\[
a=\operatorname{argmax}_a(Q(s,a) + u(s,a))
\]</span></p>
<p>其中，Q(s,a) 和u(s,a) 项分别代表Exploitation
和Exploration。两项相加来均衡Exploitation和Exploration，保证初始时每个节点被explore，在有足够多的信息时逐渐偏向exploitation。</p>
<p><span class="math display">\[
u(s, a)=c_{p u c t} \cdot P(s, a) \cdot \frac{\sqrt{\Sigma_{b} N(s,
b)}}{1+N(s, a)}
\]</span></p>
<ol start="2" type="1">
<li>Expand</li>
</ol>
<p>当遇到一个未展开的节点（搜索树中的叶子节点）时，对其每个子节点使用现有网络进行预估，即</p>
<p><span class="math display">\[
(p(s), v(s))=f_{\theta}(s)
\]</span></p>
<ol start="3" type="1">
<li>Backup</li>
</ol>
<p>当新的叶子节点展开时或者到达终点局面时，向上更新父节点的Q值，具体公式为
<span class="math display">\[
Q(s, a)=\frac{1}{N(s, a)} \sum_{s^{\prime} \mid s, a \rightarrow
s^{\prime}} V\left(s^{\prime}\right)
\]</span></p>
<ol start="4" type="1">
<li>Play</li>
</ol>
<p>多次模拟结束后，使用得到搜索概率分布 $<em>{a}
$来确定最终的落子动作。正比于访问次数的某次方 $ </em>{a} N(s, a)^{1 /
}<span class="math inline">\(，其中\)</span>$为温度参数（temperature
parameter）。</p>
<figure>
<img src="/zh/2020/combinatorial-game-4-alphago-zero-theory/net_training.png">
<figcaption>
New Policy Network V' is Trained to Predict Winner
</figcaption>
</figure>
<h2 id="参考资料">参考资料</h2>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Wujy7OzvdJk&amp;t=358s">Youtube,
Deepmind AlphaZero - Mastering Games Without Human Knowledge, David
Silver</a></p></li>
<li><p>Mastering the game of Go with deep neural networks and tree
search</p></li>
<li><p>Mastering Chess and Shogi by Self-Play with a General
Reinforcement Learning Algorithm</p></li>
<li><p><a target="_blank" rel="noopener" href="http://xtf615.com/2018/02/12/AlphaGo-Zero/">AlphaGo
Zero论文解析</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32089487">AlphaZero实战：从零学下五子棋（附代码）</a></p></li>
</ul>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
    
        
<nav class="pagination is-centered is-rounded" role="navigation" aria-label="pagination">
    <div class="pagination-previous">
        <a href="/tags/Deep-Learning/">上一页</a>
    </div>
    <div class="pagination-next is-invisible is-hidden-mobile">
        <a href="/tags/Deep-Learning/page/3/">下一页</a>
    </div>
    <ul class="pagination-list is-hidden-mobile">
        
        <li><a class="pagination-link" href="/tags/Deep-Learning/">1</a></li>
        
        <li><a class="pagination-link is-current" href="/tags/Deep-Learning/page/2/">2</a></li>
        
    </ul>
</nav>
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 MyEncyclopedia&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true" aria-controls="dropdown-menu7">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>简体中文</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu">
            <div class="dropdown-content">
            
                <a href="/tags/Deep-Learning/page/2/" class="dropdown-item">
                    简体中文
                </a>
            
                <a href="/en/tags/Deep-Learning/page/2/" class="dropdown-item">
                    English
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("zh-CN");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<style>
 .katex-display {
    overflow-x: auto;
    overflow-y: hidden;
    height: 100%;
  }
</style>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="站内搜索" />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>