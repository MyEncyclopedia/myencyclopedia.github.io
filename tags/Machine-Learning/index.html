<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>标签: Machine Learning - MyEncyclopedia</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">


<link href="/en/tags/Machine-Learning/" rel="alternate" hreflang="en" />
    


<meta name="description" content="">





    <meta property="og:type" content="website">
<meta property="og:title" content="MyEncyclopedia">
<meta property="og:url" content="https://myencyclopedia.github.io/tags/Machine-Learning/">
<meta property="og:site_name" content="MyEncyclopedia">
<meta property="og:locale">
<meta property="article:author" content="MyEncyclopedia">
<meta name="twitter:card" content="summary">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/about">About</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="搜索" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://myencyclopedia.github.io">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#Machine Learning</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope itemprop="blogPost">
    <aside id='article-toc' role="navigation" class='fixed'>
        <div id='article-toc-inner'>
            
        </div>
        
        </aside>
                <style>
            #article-toc-inner:after,#article-toc-inner:before,.inner:after,.inner:before {
                content: "";
                display: table
            }
            
            #article-toc-inner:after,.inner:after {
                clear: both
            }
            @media screen {
                #article-toc-inner,.inner {
                    padding: 0 20px
                }
            }
            #article-toc {
                display: none;
                float: left;
                width: 25%;
                margin-left: -220px;
                opacity: .8
            }
            @media screen and (min-width:769px) {
                #article-toc {
                    display: block
                }
            }
 
           #article-toc.fixed {
                position: absolute;
                top: 0;
                bottom: 0;
                left: 10 px;
                padding-top: 55px;
            }
            .fixed #article-toc-inner {
                position: fixed;
                width: 220px;
                top: 0;
                bottom: 0;
                padding-top: 55px;
            }
            </style>
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/zh/2021/stat-ml-mle-1/" itemprop="url">深入形象地理解极大似然估计(MLE) 1: 引入问题</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            
                <time datetime="2021-04-03T18:45:01.000Z" itemprop="datePublished">4月 4 2021</time>
            
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Tech-Blog/">Tech Blog</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            19 分钟 读完 (约 2816 字)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>导读：极大似然估计(MLE)
是统计机器学习中最基本的概念，但是能真正全面深入地理解它的性质和背后和其他基本理论的关系不是件容易的事情。极大似然估计和以下概念都有着紧密的联系：随机变量，无偏性质（unbiasedness），一致估计（consistent），asymptotic
normality，最优化（optimization），Fisher
Information，MAP（最大后验估计），KL-Divergence，sufficient
statistics等。在众多阐述 MLE
的文章或者课程中，总体来说都比较抽象，注重公式推导。本系列文章受3blue1brown
可视化教学的启发，坚持从第一性原理出发，通过数学原理结合模拟和动画，深入浅出地让读者理解极大似然估计。</p>
<p>相关链接</p>
<h2 id="抛硬币问题">抛硬币问题</h2>
<p>我们来思考这个老套问题，考虑手上有一枚硬币，旋转（抛）硬币得到正反面的概率固定（令正面概率为<span class="math inline">\(\theta^{\star}\)</span>）但未知，我们如何能通过实验推测出
<span class="math inline">\(\theta^{\star}\)</span></p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/toss.gif">
<figcaption>
</figcaption>
</figure>
<p>朴素的想法是，不断尝试抛硬币，随着次数 n 的增多，正面的比例会趋近于
<span class="math inline">\(\theta^{\star}\)</span></p>
<p>对应到数学形式上，令我们对于 <span class="math inline">\(\theta^{\star}\)</span> 的估计为 <span class="math inline">\(\hat{\theta}_{n}\)</span>，则希望 <span class="math display">\[
\hat{\theta}_n = {n_{head} \over n} \to \theta^{\star} \text{  as n }
\to \infty
\]</span></p>
<h2 id="模拟试验代码">模拟试验代码</h2>
<p>假设我们尝试了n次，每次的结果为 <span class="math inline">\(x_i\)</span>，<span class="math inline">\(x_i\)</span>为1（正面） 或
0（反面）。比如试了三次的结果是 [1, 0, 1]，则 <span class="math inline">\(x_1=1, x_2=0,
x_3=1\)</span>。一般，我们将观察到的数据写成向量形式</p>
<p><span class="math display">\[X=[x_1, x_2, x_3]^T=[1, 0,
1]^{T}\]</span></p>
<p>我们知道硬币的正反结果符合伯努利分布，也就是 <span class="math display">\[
\begin{align*}
P_{ber}(x;\theta) =
\left\lbrace
  \begin{array}{r@{}l}
   \theta &amp;\text{  if x=1} \\
   1-\theta &amp;\text{  if x=0}
\end{array}
\right.
\end{align*}
\]</span></p>
<p>因为 x
只有0，1两种取值，因此上式也可以写成等价如下的不含条件分支的形式 <span class="math display">\[
P_{ber} = \theta^x \cdot (1-\theta)^x
\]</span></p>
<p>假设 <span class="math inline">\(\theta^{\star} =
0.7\)</span>，如果做 n=10 次试验，结果应该比较接近7个1，3个0。</p>
<p>下面我们来模拟一下 n=10，看看结果如何。</p>
<p>下面代码的实现上我们直接使用了pytorch 内置的 bernoulli 函数生成 n
个随机变量实例 </p><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_coins</span>(<span class="hljs-params">theta, n=<span class="hljs-number">1</span></span>):</span></span><br><span class="line">    <span class="hljs-keyword">import</span> torch</span><br><span class="line">    theta_vec = torch.tensor(n*[theta])</span><br><span class="line">    random_values = torch.bernoulli(theta_vec)</span><br><span class="line">    <span class="hljs-keyword">return</span> random_values</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>让我们来做三次 n=10 的试验</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):</span><br><span class="line">    coins = gen_coins(theta=<span class="hljs-number">0.7</span>, n=<span class="hljs-number">10</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'trial <span class="hljs-subst">{i}</span>'</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'head #: <span class="hljs-subst">{<span class="hljs-built_in">sum</span>(coins)}</span>'</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'tail #: <span class="hljs-subst">{<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>-coins)}</span>'</span>)</span><br><span class="line">    <span class="hljs-built_in">print</span>()</span><br></pre></td></tr></tbody></table></figure>
<p>能发现 7个1，3个0 确实是比较可能的结果。 </p><figure class="highlight bash hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">trial 0</span><br><span class="line">head <span class="hljs-comment">#: 7.0</span></span><br><span class="line">tail <span class="hljs-comment">#: 3.0</span></span><br><span class="line"></span><br><span class="line">trial 1</span><br><span class="line">head <span class="hljs-comment">#: 9.0</span></span><br><span class="line">tail <span class="hljs-comment">#: 1.0</span></span><br><span class="line"></span><br><span class="line">trial 2</span><br><span class="line">head <span class="hljs-comment">#: 7.0</span></span><br><span class="line">tail <span class="hljs-comment">#: 3.0</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="生成概率">生成概率</h2>
<p>直觉告诉我们，当 <span class="math inline">\(\theta^{\star}=0.7\)</span> 时，根据 $P_{ber}(x;)
$，7个1，3个0 出现的概率应该是最大，6个1，4个0 或者 8个1，2个0
这两种情况出现概率稍小，其他的情况概率更小。通过基本概率和伯努利公式，重复
n 次试验
1和0出现的概率可以由下面公式算出。（注：7个1，3个0不是单一事件，需要乘以组合数算出实际概率）</p>
<p><span class="math display">\[
P_{X} = \theta^{heads} \cdot (1-\theta)^{tails} \cdot {n \choose heads}
\]</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>P(X)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>head=0</td>
<td>0.000006</td>
</tr>
<tr class="even">
<td>head=1</td>
<td>0.000138</td>
</tr>
<tr class="odd">
<td>head=2</td>
<td>0.000032</td>
</tr>
<tr class="even">
<td>head=3</td>
<td>0.001447</td>
</tr>
<tr class="odd">
<td>head=4</td>
<td>0.036757</td>
</tr>
<tr class="even">
<td>head=5</td>
<td>0.102919</td>
</tr>
<tr class="odd">
<td>head=6</td>
<td>0.200121</td>
</tr>
<tr class="even">
<td>head=7</td>
<td>0.266828</td>
</tr>
<tr class="odd">
<td>head=8</td>
<td>0.233474</td>
</tr>
<tr class="even">
<td>head=9</td>
<td>0.121061</td>
</tr>
<tr class="odd">
<td>head=10</td>
<td>0.028248</td>
</tr>
</tbody>
</table>
<p>画出图看的很明显，1出现7次的概率确实最大。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/joint_prob.png">
<figcaption>
</figcaption>
</figure>
<p>回到我们的问题，我们先假定 <span class="math inline">\(\theta^{\star}
= 0.7\)</span> 的硬币做 n=10 次试验的结果就是 7个1，3个0，或者具体序列为
[1, 0, 0, 1, 0, 1, 1, 1, 1, 1]。那么我们希望按照某种方法推测的估计值
<span class="math inline">\(\hat\theta\)</span> 也为 0.7。</p>
<p>若将这个方法也记做 <span class="math inline">\(\hat\theta\)</span>，它是<span class="math inline">\(X\)</span> 的函数，即 <span class="math inline">\(\hat\theta(X=[1, 0, 0, 1, 0, 1, 1, 1, 1,
1]^T)=0.7\)</span></p>
<p>我们如何构建这个方法呢？很显然，<span class="math inline">\(X\)</span> 中 1 的个数就可以胜任，<span class="math inline">\(\hat\theta=\bar
X\)</span>。这个方式确实是正确的，后面的文章我们也会证明它是MLE在伯努利分布参数估计时的计算方法。</p>
<p>但是伯努利分布参数估计的问题中是最简单的情况，背后对应的更一般的问题是：假设我们知道某个过程或者实验生成了某种分布
P，但是不知道它的参数 <span class="math inline">\(\theta\)</span>，如何能通过反复的试验来推断 <span class="math inline">\(\theta\)</span>，同时，我们希望随着试验次数的增多，<span class="math inline">\(\hat\theta\)</span> 能逼近 <span class="math inline">\(\theta\)</span>。</p>
<p>由于过程是有随机性，试验结果 <span class="math inline">\(X\)</span>
并不能确定一定是从 <span class="math inline">\(\hat\theta\)</span>
生成的，因此我们需要对所有 <span class="math inline">\(\theta\)</span>
打分。对于抛硬币试验来说，我们穷举所有在 [0, 1] 范围内的 <span class="math inline">\(\theta\)</span>，定义它的打分函数 <span class="math inline">\(f(\theta)\)</span>，并且希望我们定义的 <span class="math inline">\(f(\theta;X=[1, 0, 0, 1, 0, 1, 1, 1, 1,
1]^T)\)</span> 在 <span class="math inline">\(\theta=0.7\)</span>
时得分最高。推广到一般场景，有如下性质 <span class="math display">\[
f(\theta^\star;X) &gt;= f(\theta;X)
\]</span></p>
<p>如此，我们将推测参数问题转换成了优化问题 <span class="math display">\[
\hat\theta = \theta^{\star} = \operatorname{argmax}_{\theta} f(\theta;
X) = 0.7
\]</span></p>
<h2 id="朴素方法">朴素方法</h2>
<p>一种朴素的想法是，由于 <span class="math inline">\(\theta^\star=0.7\)</span>，因此我们每次的结果应该稍微偏向
1，如果出现了
1，就记0.7分，出现了0，记0.3分，那么我们可以用10个结果的总分来定义总得分，即最大化函数</p>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
&amp;\operatorname{argmax}_{\theta} f(\theta) \\
=&amp; \operatorname{argmax}_{\theta} P(x_1) + P(x_2) + ... + P(x_n) \\
=&amp; \operatorname{argmax}_{\theta} P(x_1|\theta) + P(x_2|\theta) +
... + P(x_n|\theta) \\
=&amp; \operatorname{argmax}_{\theta} \sum P(x_i|\theta) \\
\end{aligned}
\end{equation*}
\]</span></p>
<p>很可惜，我们定义的 f 并不符合 <span class="math inline">\(\theta=0.7\)</span> 时取到最大的原则。下面画出了
<span class="math inline">\(\theta\)</span> 在 [0, 1] 范围内 f 值，X
固定为 [1, 0, 0, 1, 0, 1, 1, 1, 1, 1]。显然，极值在 0.5 左右。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/sum-likelihood_w.gif">
<figcaption>
</figcaption>
</figure>
<p>这种对于观察到的变量实例在整个参数空间打分的方法是最大似然方法的雏形。我们将每次试验结果对于不同
<span class="math inline">\(\theta\)</span>
的打分就是似然函数的概念。</p>
<h2 id="伯努利似然函数likelihood">伯努利似然函数（Likelihood)</h2>
<p>伯努利单个结果的似然函数 <span class="math inline">\(l(\theta)\)</span> 视为 <span class="math inline">\(\theta\)</span>
的函数，x视为给定值，它等价于概率质量函数 PMF</p>
<p><span class="math display">\[
l(\theta|x) = \theta^x \cdot (1-\theta)^x
\]</span></p>
<h2 id="极大似然估计mle">极大似然估计(MLE)</h2>
<p>有了单个结果的似然函数，我们如何定义 <span class="math inline">\(f(\theta)\)</span> 呢？我们定义的 <span class="math inline">\(f(\theta)\)</span> 需要满足，在 <span class="math inline">\(\theta^\star=0.7\)</span> ，<span class="math inline">\(n=10\)</span> 的情况下，试验最有可能的结果是 7
个1，3个0，此时 f 需要在 <span class="math inline">\(\theta=0.7\)</span>
时取到最大值。</p>
<p>极大似然估计(MLE) 为我们定义了合理的 <span class="math inline">\(f(\theta)\)</span>
，和朴素的想法类似，但是这次用单个结果的似然函数连乘而非连加 <span class="math display">\[
L(\theta|X) = l(\theta|x_1) \cdot l(\theta|x_2) \cdot ...l(\theta|x_n) =
\prod l(\theta|x_i)
\]</span></p>
<p>我们再来看一下当 $X=[1, 0, 0, 1, 0, 1, 1, 1, 1, 1] $ 时 <span class="math inline">\(L\)</span> 在 <span class="math inline">\(\theta\)</span> 空间的取值情况，果然，MLE 能在
0.7时取到最大值。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/prod_likelihood_w.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="对数似然函数">对数似然函数</h2>
<p>最大似然函数 $_{} L() $ 能让我们找到最可能的 <span class="math inline">\(\theta\)</span>，但现实中，我们一般采用最大其 log
的形式。</p>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
&amp;\operatorname{argmax}_{\theta} \log L(\theta|X) \\
=&amp; \operatorname{argmax}_{\theta} \log [l(\theta|x_1) \cdot
l(\theta|x_2) \cdot ... \cdot l(\theta|x_n)]   \\
=&amp; \operatorname{argmax}_{\theta} \log l(\theta|x_1) + \log
l(\theta|x_2) \cdot ... + \log l(\theta|x_n)
\end{aligned}
\end{equation*}
\]</span></p>
<p>理论能证明，最大对数似然函数得到的极值等价于最大似然函数。但这么做有什么额外好处呢？</p>
<p>我们先将对数似然函数画出来</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/prod_log_likelihood_w.gif">
<figcaption>
</figcaption>
</figure>
<p>它的极大值也在 0.7，但是我们发现对数似然函数是个 concave
函数。在优化领域，最大化 concave 函数或者最小化 convex
函数可以有非常高效的解法。再仔细看之前的似然函数，它并不是一个 concave
函数。另一个非常重要的好处是，随着 n 的增大，连乘会导致浮点数
underflow，而单个点的对数似然函数的和的形式就不会有这个问题。</p>
<h2 id="pytorch-mle-代码">Pytorch MLE 代码</h2>
<p>就让我们来实践一下，通过 pytorch 梯度上升来找到极值点。</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> stats.coin <span class="hljs-keyword">import</span> gen_coins</span><br><span class="line"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">num_head: <span class="hljs-built_in">int</span>, num_tail: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span></span><br><span class="line">    <span class="hljs-keyword">import</span> torch</span><br><span class="line">    theta = torch.tensor(<span class="hljs-number">0.5</span>, requires_grad=<span class="hljs-literal">True</span>)</span><br><span class="line"></span><br><span class="line">    recent = deque(<span class="hljs-number">3</span>*[<span class="hljs-number">100</span>], maxlen=<span class="hljs-number">3</span>)</span><br><span class="line"></span><br><span class="line">    lr = <span class="hljs-number">0.00001</span></span><br><span class="line">    <span class="hljs-keyword">for</span> <span class="hljs-built_in">iter</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span>):</span><br><span class="line">        loss = -(num_head * torch.log(theta) + num_tail * torch.log(<span class="hljs-number">1</span> - theta))</span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="hljs-keyword">with</span> torch.no_grad():</span><br><span class="line">            theta -= lr * theta.grad</span><br><span class="line">            <span class="hljs-comment"># print(f'{iter}: {theta}, {theta.grad}')</span></span><br><span class="line">            recent.append(theta.grad.item())</span><br><span class="line">            <span class="hljs-keyword">if</span> <span class="hljs-built_in">all</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">abs</span>(x) &lt; <span class="hljs-number">1</span>, recent)):</span><br><span class="line">                <span class="hljs-keyword">break</span></span><br><span class="line">        theta.grad.zero_()</span><br><span class="line">    <span class="hljs-keyword">return</span> theta.item()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:</span><br><span class="line">    data = gen_coins(<span class="hljs-number">0.6</span>, n=<span class="hljs-number">200</span>)</span><br><span class="line"></span><br><span class="line">    num_head = (data.detach() == <span class="hljs-number">1</span>).<span class="hljs-built_in">sum</span>().item()</span><br><span class="line">    num_tail = (data.detach() == <span class="hljs-number">0</span>).<span class="hljs-built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    <span class="hljs-built_in">print</span>(num_head, num_tail)</span><br><span class="line">    <span class="hljs-built_in">print</span>(train(num_head, num_tail))</span><br></pre></td></tr></tbody></table></figure>
<p>一点需要说明的是，在迭代过程中，我们保存最后三个导数的值，当最新的三个导数都很小时就退出迭代。</p>
<figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if all(map(lambda x: abs(x) &lt; 1, recent))</span><br></pre></td></tr></tbody></table></figure>
<p>运行代码，能发现最大化对数似然函数能很稳定的找到 <span class="math inline">\(\theta\)</span>。</p>
<p>现在大家对于伯努利MLE有了一定了解，接着，我们来思考一下最大化似然函数方法是否随着观察次数的增多能不断逼近真实的
<span class="math inline">\(\theta^\star\)</span>呢？</p>
<h2 id="mle-theta-估计的收敛性">MLE <span class="math inline">\(\theta\)</span> 估计的收敛性</h2>
<p><span class="math inline">\(\theta^\star=0.7\)</span>
的情况下，我们来这样做试验，第一次做 n=1生成观察数据 <span class="math inline">\(X_{1}\)</span>，第二次做 n=2生成观察数据 <span class="math inline">\(X_{2}\)</span> <span class="math display">\[
X_1,X_2, X_3, ..., X_N
\]</span> 对于每个数据集 <span class="math inline">\(X_i\)</span>
通过最大似然方法求得估计的 <span class="math inline">\(\hat\theta\)</span> <span class="math display">\[
\hat\theta_1=MLE(X_1), \hat\theta_2=MLE(X_2), ..., \hat\theta_N=MLE(X_N)
\]</span> 将这些 <span class="math inline">\(\hat\theta_i\)</span>
画出来，可以看到，随着 <span class="math inline">\(n \to
\infty\)</span>，<span class="math inline">\(\hat\theta_i \to
\theta^\star=0.7\)</span></p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/bias_w.gif">
<figcaption>
</figcaption>
</figure>
<p>换一个角度来看一下，我们将 <span class="math inline">\(\hat\theta_i\)</span>
数列按照顺序，离散化后再归一化比例，如下图画出来，红色的柱代表了最新的值
<span class="math inline">\(\hat\theta\)</span>。可以发现，初始时候，<span class="math inline">\(\hat\theta\)</span> 在较远离 0.7 的地方出现，随着
n 的增大，出现的位置比较接近 0.7。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/converge_w.gif">
<figcaption>
</figcaption>
</figure>
<h2 id="mle-theta-估计的偏差和方差">MLE <span class="math inline">\(\theta\)</span> 估计的偏差和方差</h2>
<p>我们已经知道 MLE 方法可以通过观察数据推测出最有可能的 <span class="math inline">\(\hat\theta\)</span>，由于观察数据 <span class="math inline">\(X\)</span> 是伯努利过程产生的，具有随机性，那么
<span class="math inline">\(\hat\theta\)</span> 可以看成是 <span class="math inline">\(\theta^\star\)</span>
的随机变量。我们已经通过上面的试验知道随着试验次数的增大，我们的估计会越来越逼近真实值，现在的问题是对于<strong>固定的n</strong>，<span class="math inline">\(\hat\theta\)</span>
的方差是多少，它的均值是否是无偏的呢？</p>
<p>带着这样的疑问，我们现在做如下试验：</p>
<p>固定 n=10，重复做实验，画出随着次数增多 <span class="math inline">\(\hat\theta\)</span>
的分布，见图中绿色部分。同样的，红色是 n=80 不断试验的分布变换。</p>
<figure>
<img src="/zh/2021/stat-ml-mle-1/theta_variance_w.gif">
<figcaption>
</figcaption>
</figure>
<p>看的出来，随着试验次数的增多 - <span class="math inline">\(\hat\theta_{10}, \hat\theta_{80}\)</span>
都趋近于正态分布</p>
<ul>
<li><p><span class="math inline">\(\hat\theta_{10}\)</span> 的分散度比 $
_{80}$ 要大，即方差要大</p></li>
<li><p><span class="math inline">\(\hat\theta_{10},
\hat\theta_{80}\)</span> 的均值都在 0.7</p></li>
</ul>
<link rel="stylesheet" href="/css/bilicard.css" type="text/css"></body></html>
    
    </div>
    
    
</article>








    
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2023 MyEncyclopedia&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
<div class="column is-narrow has-text-centered">
    <div class="dropdown is-up is-right is-hoverable" style="margin-top: -0.2em;">
        <div class="dropdown-trigger">
            <button class="button is-small" aria-haspopup="true" aria-controls="dropdown-menu7">
                <span class="icon">
                    <i class="fas fa-globe"></i>
                </span>
                <span>简体中文</span>
                <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
            </button>
        </div>
        <div class="dropdown-menu has-text-left" role="menu">
            <div class="dropdown-content">
            
                <a href="/tags/Machine-Learning/" class="dropdown-item">
                    简体中文
                </a>
            
                <a href="/en/tags/Machine-Learning/" class="dropdown-item">
                    English
                </a>
            
            </div>
        </div>
    </div>
</div>

        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("zh-CN");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<style>
 .katex-display {
    overflow-x: auto;
    overflow-y: hidden;
    height: 100%;
  }
</style>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        // ...options...
    });
});
</script>

    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="站内搜索" />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(无标题)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>